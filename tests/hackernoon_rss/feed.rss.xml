<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:media="http://search.yahoo.com/mrss/" xmlns:snf="http://www.smartnews.be/snf">
    <channel>
        <title><![CDATA[HackerNoon]]></title>
        <description><![CDATA[How hackers start their afternoons.]]></description>
        <link>https://hackernoon.com</link>
        <image>
            <url>https://hackernoon.com/hn-icon.png</url>
            <title>HackerNoon</title>
            <link>https://hackernoon.com</link>
        </image>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 13 Apr 2025 10:00:15 GMT</lastBuildDate>
        <atom:link href="https://hackernoon.com/feed" rel="self" type="application/rss+xml"/>
        <pubDate>Sun, 13 Apr 2025 10:00:14 GMT</pubDate>
        <snf:logo>https://hackernoon.com/hn-logo.png</snf:logo>
        <item>
            <title><![CDATA[Modern Engineering Tools Are Designed to Punish System Thinkers]]></title>
            <description><![CDATA[This article explores how modern tech companies systematically filter out high-agency, systems-level thinkers by design. Through tools like LeetCode, Go, and React, the industry scales control and predictabilityâ€”at the cost of judgment, abstraction, and architectural insight. If you're the kind of mind that sees the whole, you're not a fit by accidentâ€”youâ€™re filtered out on purpose.]]></description>
            <link>https://hackernoon.com/modern-engineering-tools-are-designed-to-punish-system-thinkers?source=rss</link>
            <guid isPermaLink="true">https://hackernoon.com/modern-engineering-tools-are-designed-to-punish-system-thinkers?source=rss</guid>
            <category><![CDATA[software-engineering]]></category>
            <category><![CDATA[systems-thinking]]></category>
            <category><![CDATA[high-agency]]></category>
            <category><![CDATA[tech-culture]]></category>
            <category><![CDATA[programming-languages]]></category>
            <category><![CDATA[tech-hiring-culture]]></category>
            <category><![CDATA[software-architecture]]></category>
            <category><![CDATA[developer-experience]]></category>
            <dc:creator><![CDATA[blueanarchy]]></dc:creator>
            <pubDate>Sun, 13 Apr 2025 09:22:10 GMT</pubDate>
            <image/>
            <content:encoded><![CDATA[<p>\</p>
<h2 id="themoderntechstackisntdysfunctional">The modern tech stack isnâ€™t dysfunctional.</h2>
<p>Itâ€™s highly functional â€” at suppressing a specific kind of mind. Not the underperformer. Not the amateur. But the one who sees through it.</p>
<p>\
The system doesnâ€™t fail to reward brilliance. It intentionally penalizes uncontainable intelligence: The kind of intelligence thatâ€™s recursive, systemic, deeply causal, structurally non-compliant â€” and unable to participate in incoherent systems without first reorganizing them. If you think like this â€” if you recognize yourself in what follows â€” you were never supposed to succeed in the current system. Because the system wasnâ€™t built for you. It was built to route around you.</p>
<p>\</p>
<ul>
<li>System Thinkers: You donâ€™t just code features. You map flows, lifecycles, dependencies. You treat a bug not as a symptom but a systemic pattern leak. You refuse to solve subproblems in isolation.</li>
<li>Recursive Analysts: You think in feedback loops. You rewrite models mid-process. Youâ€™re not interested in solving the problem â€” you're interested in reshaping the problem-space itself.</li>
<li>Abstraction Seekers: You see repeated logic and collapse it. You hate boilerplate. You crave clean interfaces, minimum moving parts. You don't memorize patterns â€” you extract invariants.</li>
<li>High-Agency Actors: You donâ€™t wait for permission. You spot leverage. You restructure workflows. You walk away if systems donâ€™t deserve your effort. Youâ€™re not rebellious â€” youâ€™re simply uncorralable.</li>
<li>Causal Reasoners: You donâ€™t care what â€œeveryone does.â€ You want to know why they do it, what incentive made them do it, and what contradiction it hides. You are immune to cargo cults.</li>
<li>Cognitively Independent: You donâ€™t absorb systems. You interrogate them. You donâ€™t mimic successful behavior. You question whether the success is real.</li>
</ul>
<p>\</p>
<h2 id="whythesystemfiltersyououtbydesign">Why the System Filters You Out (By Design)</h2>
<p>Companies arenâ€™t trying to identify brilliance. Theyâ€™re optimizing for predictability, alignment, and throughput. To do that, they must minimize variance, flatten decision-making. They must delegate without overhead, and hire at scale without dependence on judgment.</p>
<p>\
So what do they optimize?</p>
<h2 id="leetcoderitualizedsubmissiondisguisedasmerit">LeetCode: Ritualized Submission Disguised as Merit</h2>
<p>LeetCode is marketed as a meritocratic filter â€” a way to surface the best minds through standardized technical challenges. But in practice, it is a system that rewards submission to artificial constraint.</p>
<p>\
For the system thinker, LeetCode presents two core contradictions: It simulates problem-solving without real-world context. It rewards speed under pressure over clarity under ambiguity.</p>
<p>\
You probably have already seen through this, and know that real engineering is not about racing through permutations of trees in 30 minutes. Itâ€™s about managing tradeoffs, designing across failure domains, and balancing time, complexity, and impact.</p>
<p>\
But have you wondered what the real incentive behind LeetCode is, assuming it is not a failure at recruitment, but doing exactly what itâ€™s designed to do?</p>
<p>\
It selects for engineers who can train themselves to succeed inside arbitrary constraints â€” without questioning them. In other words: LeetCode really tests your adaptability to systems that make no sense. Those who pass are less likely to resist incoherent specs, irrational deadlines, or vacuous rituals â€” because theyâ€™ve already proven they can grind through them. For recursive minds who seek structure behind structure, LeetCode is alien. Itâ€™s noise â€” not signal. And thatâ€™s exactly what makes it effective as a gatekeeping mechanism against systems-level thinkers.</p>
<h2 id="gotheintentionalerasureofexpressiveness">Go: The Intentional Erasure of Expressiveness</h2>
<p>Go is not just a programming language. It is a philosophy of engineering designed around a very specific organizational need: safe, uniform output from large teams of interchangeable engineers.</p>
<p>\
Go is famous for rejecting complexity â€” but complexity is not the enemy of thought. Unnecessary complexity is. What Go removes is not noise â€” it removes expressive leverage: It discouraged generics for a decade not because it was impossible â€” but because it would allow nonstandard abstraction. It removes metaprogramming and macro facilities that allow pattern collapse. It relies on boilerplate repetition instead of structural generalization.</p>
<p>\
For a system thinker, these limitations are not just inconvenient. Theyâ€™re epistemologically offensive, and intellectually oppressive.</p>
<p>\
System thinkers donâ€™t write code linearly â€” they design from concept down to implementation. They look for hidden structures, repeating patterns, and abstractions that encode thought once, correctly. Go doesnâ€™t allow that. Go forces you to repeat yourself until everyone can read your mind without learning how you think.</p>
<p>\
The real incentive behind Go, lies in flattening the distribution of engineering output. Making codebases legible to managers and junior engineers without context, and ensuring no one engineer becomes a point of architectural leverage. Go treats intellectual depth as a maintenance risk. So it encodes compliance directly into the language. You cannot express your full mind.</p>
<p>\
Thatâ€™s not a limitation â€” itâ€™s the goal.</p>
<h2 id="reactfragmentationasorganizationalcontrol">React: Fragmentation as Organizational Control</h2>
<p>React solved a genuine problem â€” UI state and reactivity â€” but its adoption pattern reveals something deeper: It aligns perfectly with the organizational desire to decompose cognition into ticketable fragments.</p>
<p>\
Reactâ€™s component model is seductive: Break everything into small reusable pieces. Prop-drill and compose until the UI renders. Add hooks, contexts, portals â€” abstract all flow into 10-liner microstates.</p>
<p>\
But from a systems perspective, React isnâ€™t UI engineering â€” itâ€™s cognitive disintegration.</p>
<p>\
You no longer own flows, nor understand user journeys. You see cross-screen state transitions and think in terms of coherence. You think in <Card />, <Decks />, and a dozen invisible context providers routing stale props through five layers of indirection. Anyone who wants to build systems (state management, rendering efficiency, UX flow) gets buried under 200 files named CardContainer.tsx. The real incentive behind React, lies in decomposing engineering work so it can be distributed across teams without requiring architectural ownership. It makes hiring easier by turning front-end development into UI assembly, this eliminating the need for holistic design thinking. React isnâ€™t popular because it empowers engineers. Itâ€™s popular because it lets companies hire 50 people to build 500 components without any of them needing to understand the system.</p>
<p>\
It makes true system thinkers irrelevant. And to the system, thatâ€™s not a feature like they wished â€” itâ€™s a bug.</p>
<h2 id="themodernstackscalableyesbutalsocontrollable">The Modern Stack: Scalable, Yes â€” But Also Controllable</h2>
<p>React, Go, and LeetCode are only the most visible mechanisms in a broader architecture of suppression. Linter rules and opinionated formatters like Prettier or ESLint encode arbitrary style mandates into tooling â€” not to improve correctness, but to enforce uniformity and eliminate expressive variance. Scrum rituals and Agile ceremonies fragment work into abstractions of progress â€” story points, sprint velocity, Jira tickets â€” converting strategy into measurable compliance theater. Even "move fast" culture and tech debt shaming are not about iteration; theyâ€™re about suppressing dissent: anyone who pushes for deeper design is labeled a blocker.</p>
<p>\
AI mandates take this even further, shifting evaluation away from judgment and insight toward how efficiently you align with tooling. The modern stack isnâ€™t just built to scale systems â€” itâ€™s built to scale obedience, and to quietly filter out any mind that insists on understanding the whole.</p>
<h2 id="thecommonpatternsuppressjudgmentpromoteinterchangeability">The Common Pattern: Suppress Judgment, Promote Interchangeability</h2>
<p>None of these are accidents. They are architectural choices that reflect what tech companies value:</p>
<p>\
Alignment over truth. Compliance over elegance. Subtask completion over holistic design. Legibility over leverage.</p>
<p>\
Because to the average tech org, judgment is a liability. If one person has too much insight, they might challenge the roadmap; they might reject the ticket scope; they might change the system. But changing the system takes time. Insight isnâ€™t linear. Brilliance isnâ€™t measurable. So the system is designed to prevent it before it starts.</p>
<h2 id="whatitfeelslikeifyourethiskindofmind">What It Feels Like if Youâ€™re This Kind of Mind</h2>
<p>You feel underutilized â€” not because you lack skill, but because the system lacks depth. You feel exhausted â€” not by the work, but by the low leverage of everything youâ€™re allowed to do. You feel detached â€” because the tools fight your thinking style at every turn. You feel silenced â€” not by anyone directly, but by a structure that absorbs insight like noise. And eventually, you ask: â€œIs it me?â€</p>
<p>\
No. Itâ€™s not you. Itâ€™s the design â€” and you werenâ€™t part of the requirements.</p>
<h2 id="thewayforward">The Way Forward</h2>
<p>If this describes you, the only rational path is strategic. You can learn the system well enough to navigate it. Leverage it when it suits you, resist internalizing it when it doesnâ€™t. Avoid environments where youâ€™re structurally disarmed. Or, step outside entirely â€” and design something better.</p>
<p>\
But above all: donâ€™t let a scaled systemâ€™s resistance to thought convince you that thinking is wrong. You were never too much. You were just never intended to be scalable.</p>]]></content:encoded>
            <media:thumbnail url="https://hackernoon.com/https://cdn.hackernoon.com/images/wLwuv2Czj7cCSq3SjIEWdOZPqdD3-u50367n.png"/>
        </item>
        <item>
            <title><![CDATA[Tired of Digging Through Long PDFs? You Can Build a Bot That Can Quickly Answer Questions for You]]></title>
            <description><![CDATA[Tired of digging through long PDFs? This guide walks you through building a basic "Ask My Book" bot using a RAG pipeline â€” where your questions are answered based on actual book content, not guesswork. Youâ€™ll learn how to chunk your book, embed it with Cohere, store it in Pinecone, and generate accurate responses with Gemini. Beginner-friendly and powerful!]]></description>
            <link>https://hackernoon.com/tired-of-digging-through-long-pdfs-you-can-build-a-bot-that-can-quickly-answer-questions-for-you?source=rss</link>
            <guid isPermaLink="true">https://hackernoon.com/tired-of-digging-through-long-pdfs-you-can-build-a-bot-that-can-quickly-answer-questions-for-you?source=rss</guid>
            <category><![CDATA[retrieval-augmented-generation]]></category>
            <category><![CDATA[gemini]]></category>
            <category><![CDATA[rag-pipeline]]></category>
            <category><![CDATA[nlp]]></category>
            <category><![CDATA[qna-bot]]></category>
            <category><![CDATA[askmybook]]></category>
            <category><![CDATA[hands-on-ai-tuorial]]></category>
            <category><![CDATA[build-chatbot-with-gemini]]></category>
            <dc:creator><![CDATA[Aleeza Adnan]]></dc:creator>
            <pubDate>Sun, 13 Apr 2025 09:18:58 GMT</pubDate>
            <image/>
            <content:encoded><![CDATA[<p>Like many students, I <em>do not</em> enjoy scrolling through endless PDFs. I would if I could skip reading and just ask my textbook questions. So, naturally, I did what any lazy-but-resourceful person would do: I dumped the entire PDF into an LLM and started asking questions, praying to God that the answers were accurate.</p>
<p>\
Spoiler alert: they werenâ€™t.</p>
<p>\
The answers were either vague, wrong, or just plain confusing. Thatâ€™s when I realized â€” large language models arenâ€™t magic (shocking, I know). They have <strong>context limits</strong>, and stuffing a whole book into one prompt is like trying to fit a watermelon into a ziplock bag.</p>
<p>\
So I started digging, and thatâ€™s when I found the real MVP: <strong>RAG (Retrieval-Augmented Generation)</strong>. With RAG, instead of force-feeding the model everything, you teach it <em>where</em> to look â€” and suddenly, answers start making sense</p>
<h2 id="whylargecontextwindowsdontreallyhelpmuch"><strong>Why Large Context Windows Donâ€™t Really Help (Much)</strong></h2>
<p>You might think, â€œWaitâ€¦ but newer models have massive context windows, right? Shouldnâ€™t that fix the problem?â€</p>
<p>\
In theory? Yes.</p>
<p>\
In practice? Meh.</p>
<p>\
Even with context windows stretching up to 100k tokens (which sounds huge), you're still working with trade-offs:</p>
<ul>
<li><p>Theyâ€™re expensive to use.</p></li>
<li><p>They often truncate or compress information.</p></li>
<li><p>And unless your prompt is perfectly structured (which is rarely the case), the model still ends up hallucinating or giving generic responses. </p>
<p>\</p></li>
</ul>
<p>Itâ€™s like asking your friend to remember every word of a 300-page book and hoping they donâ€™t mess up the details. Not ideal.</p>
<h2 id="ragtotherescue"><strong>RAG to the Rescue</strong></h2>
<p><strong>RAG â€” Retrieval-Augmented Generation â€” is like giving your LLM a cheat sheetâ€¦ but a really smart, targeted one.</strong></p>
<p>\
<strong>Hereâ€™s the flow:</strong></p>
<ul>
<li>You split your book into smaller chunks</li>
<li>You store these chunks in a vector DB.</li>
<li>When a user asks a question, you donâ€™t give the model the <em>entire</em> book â€” just the <em>most relevant parts</em>.</li>
<li>Then the LLM crafts a solid, informed answer using <em>only</em>those parts.</li>
</ul>
<p>\
Less noise. More signal. Way better answers.</p>
<h2 id="whatdoestheragpipelinelooklike"><strong>What Does the RAG Pipeline Look Like?</strong></h2>
<p>Imagine youâ€™re the middleman between your textbook and your model.</p>
<p><img src="https://cdn.hackernoon.com/images/mM0I6NciNefSjw4NPEgAf8S8Hjl2-0n132rx.jpeg" alt="" /></p>
<p><strong>Your job is to:</strong></p>
<ol>
<li><p>Split the content â†’ Break the book into readable chunks</p></li>
<li><p>Convert them into vectors â†’ Using an embedding model (Cohere)</p></li>
<li><p>Save those vectors â†’ In a vector database (Pinecone)</p></li>
<li><p>When a question is asked:</p>
<p>\</p></li>
</ol>
<ul>
<li>Convert the question into a vector</li>
<li>Search the database for chunks that are most similar (using cosine distance metric)</li>
<li>Send the best matches + the question to a language model (I used Gemini)</li>
<li>Boom â€” you get a clear, helpful answer \n </li>
</ul>
<p>And thatâ€™s the heart of it. Youâ€™re not replacing the modelâ€™s brain â€” just giving it better memory.</p>
<h2 id="mystacksimplepowerfulbeginnerfriendly"><strong>My Stack: Simple, Powerful, Beginner-Friendly</strong></h2>
<p>Hereâ€™s what I used:</p>
<p>\</p>
<ul>
<li><strong>ðŸ§  Cohere â€“</strong> To turn both book content and questions into vectors (aka embeddings)</li>
<li><strong>ðŸ“¦ Pinecone â€“</strong> To store and search those vectors super efficiently</li>
<li><strong>ðŸ’¬ Gemini â€“</strong> To generate the final, natural-language response</li>
</ul>
<p>\
You donâ€™t <em>have</em> to use these, but this combo is beginner-friendly, well-documented, and plays nicely together.</p>
<h2 id="stepbystepbuildyourownaskmybookbot"><strong>Step-by-Step: Build Your Own AskMyBook Bot</strong></h2>
<p><strong>Okay, letâ€™s actually build the thing now. I used Google Colab (because free GPU and easy sharing), but this should work in any Python environment.</strong></p>
<h3 id="step1loadandchunkyourbook"><strong>Step 1: Load and Chunk Your Book</strong></h3>
<p><strong>I used the PyMuPDF library to extract text.</strong></p>
<pre><code class="python language-python">!pip install pymupdf
</code></pre>
<p>\
<strong>Now, letâ€™s extract the text:</strong></p>
<pre><code class="python language-python">import fitz&amp;nbsp; # PyMuPDF

def extract_text_from_pdf(pdf_path):

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;doc = fitz.open(pdf_path)

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;text = ""

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;for page in doc:

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;text += page.get_text()

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;return text

book_path = 'enter the path here'

book_text = extract_text_from_pdf(book_path)
</code></pre>
<p>\
Now, weâ€™ll split the book into chunks, making it more digestible.</p>
<pre><code class="python language-python">import re

def chunk_text(text, chunk_size=300, overlap=50):

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;words = re.findall(r'\S+', text)

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;chunks = []

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;for i in range(0, len(words), chunk_size - overlap):

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;chunk = ' '.join(words[i:i + chunk_size])

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;chunks.append(chunk)

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;return chunks

chunks = chunk_text(book_text)

print(f"Total Chunks: {len(chunks)}")

print("Sample chunk:\n", chunks[0])
</code></pre>
<p>\
Here, each chunk has 300 words, with a 50-word overlap for context continuity. Think of it as giving the model a smooth flow between paragraphs.</p>
<h3 id="step2createembeddingswithcohere">Step 2: Create Embeddings with Cohere</h3>
<p>Embeddings = turning text into numbers that reflect meaning. Weâ€™ll use Cohere's embed-english-v3.0 model for this.</p>
<p>\</p>
<pre><code class="python language-python">!pip install cohere

import cohere

co = cohere.Client("YOUR-API-KEY")&amp;nbsp; # Replace with your actual key

def get_embeddings(texts):

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;response = co.embed(

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;texts=texts,

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;model="embed-english-v3.0",

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;input_type="search_document"

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;)

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;return response.embeddings
</code></pre>
<h3 id="step3storechunksinpinecone">Step 3: Store Chunks in Pinecone</h3>
<p>Now we store the embeddings in Pinecone â€” a vector database that helps us search similar chunks later.</p>
<p>\</p>
<pre><code class="python language-python">!pip install pinecone

import pinecone

pinecone = pinecone.Pinecone(api_key="YOUR-API-KEY")

index_name = "ask-my-book"

if index_name not in pinecone.list_indexes().names():

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;pinecone.create_index(

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;index_name,

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;spec={

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;"pod": {

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;"pod_type": "p1",

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;"replicas": 1,

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;"metric": "cosine",

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;"environment": "aws-us-east1"

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;}

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;},

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;dimension=1024

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;)

index = pinecone.Index(index_name)
</code></pre>
<p>\
Now, batch upload the chunks</p>
<pre><code class="python language-python">import uuid

import time

batch_size = 96&amp;nbsp;

for i in range(0, len(chunks), batch_size):

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;batch_chunks = chunks[i:i+batch_size]

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;batch_embeds = get_embeddings(batch_chunks)

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;ids = [str(uuid.uuid4()) for _ in batch_chunks]

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;vectors = list(zip(ids, batch_embeds, [{"text": t} for t in batch_chunks]))

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;index.upsert(vectors=vectors)

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;time.sleep(60)&amp;nbsp; # avoid hitting rate limits
</code></pre>
<p>\
Boom! Your book is now smartly stored in vector format.</p>
<h3 id="step4askquestionsgetanswerswithgemini">Step 4: Ask Questions + Get Answers with Gemini</h3>
<p>Weâ€™ll search for relevant chunks using your query, and then pass those to Gemini for generating an answer.</p>
<p>\
First, get the query embedding:</p>
<pre><code class="python language-python">def get_query_embedding(query):

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;response = co.embed(

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;texts=[query],

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;model="embed-english-v3.0",

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;input_type="search_query"

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;)

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;return response.embeddings[0]
</code></pre>
<p>\
Now, search Pinecone:</p>
<p>\</p>
<pre><code class="python language-python">def search_similar_chunks(query, top_k=5):

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;query_embedding = get_query_embedding(query)

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;result = index.query(vector=query_embedding, top_k=top_k, include_metadata=True)

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;return [match['metadata']['text'] for match in result['matches']]
</code></pre>
<p>\
Then plug the top chunks into Gemini:</p>
<pre><code class="python language-python">import google.generativeai as genai

genai.configure(api_key="YOUR-GEMINI-API-KEY")

model = genai.GenerativeModel("gemini-1.5-flash")

def generate_answer(query):

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;context_chunks = search_similar_chunks(query)

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;context = "\n\n".join(context_chunks)

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;prompt = f"""

You are an assistant bot trained on the following book content. Use only the info provided to answer the user's question.

Book Context:

{context}

Question:

{query}

If the question is not relevant to the context, respond with:

'I am a bot trained to answer questions based on the book content. This question is out of scope.'

"""

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;response = model.generate_content(prompt)

&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;return response.text
</code></pre>
<p>\
Try it out!</p>
<pre><code class="python language-python">question = "Whatâ€™s does the author say in Module 1 of the book?"

print(generate_answer(question))
</code></pre>
<h2 id="thatsityounowhaveanaskmybookbot">Thatâ€™s It â€” You Now Have an Ask-My-Book Bot!</h2>
<p>You built a bot that:</p>
<ul>
<li>Understands your textbook</li>
<li>Finds the right part when asked</li>
<li>Gives meaningful answers using that part only \n </li>
</ul>
<p>No more endless skimming. Just type and ask.</p>
<h2 id="whatnextlevelupyourbookbot">What Next? Level Up Your Book-Bot</h2>
<p>What weâ€™ve built is a basic but powerful Question-and-Answer system. Think of it as the MVP (Minimum Viable Product) of your personal study assistant.</p>
<p>\
But once youâ€™re comfortable, thereâ€™s so much more you can add:</p>
<ul>
<li>Citations â€“ Show which chunk or page the answer came from, so you can verify the source.</li>
<li>Multi-turn Conversations â€“ Let the bot remember previous questions and give more intelligent answers over time.</li>
<li>Multi-step Reasoning â€“ Chain thoughts together to answer complex questions.</li>
<li>Custom Memory â€“ Let your bot hold on to important facts you highlight for future queries.</li>
<li>UI Upgrade â€“ Hook this into a Streamlit or React frontend for a polished, user-friendly experience. \n </li>
</ul>
<p>With these, your bot goes from â€œsmart textbookâ€ to â€œAI study buddy.â€</p>
<p>\
If youâ€™ve ever stared at a textbook, praying it would just <em>talk back</em> and tell you what matters â€” well, now it can.</p>
<p>\
This was my little experiment in turning boring PDFs into interactive conversations. Hope it inspires you to build your own and maybe even customize it for friends or classes.</p>
<p>\
Got stuck somewhere? Want help with adding a UI or citations next? Drop a comment or ping me â€” always happy to chat.</p>]]></content:encoded>
            <media:thumbnail url="https://hackernoon.com/https://cdn.hackernoon.com/images/mM0I6NciNefSjw4NPEgAf8S8Hjl2-ih032z8.png"/>
        </item>
        <item>
            <title><![CDATA[Confession: I Used to Think Specs Were Everything. Agile Broke Me (and Made Me Better)]]></title>
            <description><![CDATA[When I started out as a BA, we were taught to treat documentation like gospel. But in an Agile world, usefulness doesnâ€™t come from a polished doc. What they needed was me, in the room, talking with them.]]></description>
            <link>https://hackernoon.com/confession-i-used-to-think-specs-were-everything-agile-broke-me-and-made-me-better?source=rss</link>
            <guid isPermaLink="true">https://hackernoon.com/confession-i-used-to-think-specs-were-everything-agile-broke-me-and-made-me-better?source=rss</guid>
            <category><![CDATA[agile]]></category>
            <category><![CDATA[business-analysis]]></category>
            <category><![CDATA[collaboration]]></category>
            <category><![CDATA[product-management]]></category>
            <category><![CDATA[agile-mindset]]></category>
            <category><![CDATA[documenting-everything]]></category>
            <category><![CDATA[agile-tips]]></category>
            <category><![CDATA[agile-for-startups]]></category>
            <dc:creator><![CDATA[Sanjay Mood]]></dc:creator>
            <pubDate>Sun, 13 Apr 2025 09:10:31 GMT</pubDate>
            <image/>
            <content:encoded><![CDATA[<p>There was a time I believed that if I just wrote a perfect specâ€”everything would go smoothly.</p>
<p>\
The devs would build exactly what I envisioned.</p>
<p>\
QA wouldnâ€™t miss a thing.</p>
<p>\
The product owner would nod in agreement, and weâ€™d launch on time.</p>
<p>\
That fantasy lasted about two sprints.</p>
<h2 id="iwastrainedtobelievespecsweresacred"><strong>I Was Trained to Believe Specs Were Sacred</strong></h2>
<p>Back when I started out as a BA, we were taught to treat documentation like gospel.</p>
<p>\
You wrote it all downâ€”<em>every scenario, exception, flow, dropdown option, tooltip</em>. The longer the spec, the more â€œcompleteâ€ it was. If it made it to 20 pages? Even better.</p>
<p>\
I once spent three weeks writing a spec for a search filter. No one questioned it. That was just the norm.</p>
<h2 id="thenagilehappenedandmyconfidencecracked"><strong>Then Agile Happenedâ€”And My Confidence Cracked</strong></h2>
<p>Agile hit like a cold shower.</p>
<p>\
Suddenly we were in sprint planning talking about â€œjust enoughâ€ documentation. Stories were short. Acceptance criteria were lean. My 20-page documents became the elephant in the room no one had time to read.</p>
<p>\
The first few sprints? Painful.</p>
<p>\
Dev asked me things that were<em>already in the spec</em>.</p>
<p>\
QA missed stuff because they were waiting for a walkthrough I didnâ€™t have time to give.</p>
<p>\
And I kept thinking:<em>â€œWhy is no one reading this?â€</em></p>
<p>\
The truth? They didnâ€™t need to.</p>
<p>\
What they needed was<em>me</em>, in the room, talking with themâ€”not hiding behind a Google Doc.</p>
<h2 id="mywakeupcallcameinaretro"><strong>My Wake-Up Call Came in a Retro</strong></h2>
<p>Iâ€™ll never forget this.</p>
<p>\
In a retro, one of the devs (very kindly) said:</p>
<p>\</p>
<blockquote>
  <p>â€œWe appreciate the effort, but the spec is too much. Weâ€™d rather walk through the story with you and get clarity directly.â€</p>
</blockquote>
<p>\
That one line shifted everything for me.</p>
<p>\
I realized I wasnâ€™t writing specs for <em>them</em>â€”I was writing them for <em>me</em>. To feel prepared. To feel useful. To prove I was doing my job.</p>
<p>\
But in an Agile world, usefulness doesnâ€™t come from a polished doc. It comes from <strong>creating shared understanding.</strong></p>
<h2 id="iburnedthespecandfoundsomethingbetter"><strong>I Burned the Specâ€”and Found Something Better</strong></h2>
<p>After that retro, I tried something radical.</p>
<p>\
I replaced a full-blown spec with:</p>
<ul>
<li>Three user stories</li>
<li>A sketchy whiteboard diagram</li>
<li>One 30-min conversation with the team</li>
</ul>
<p>\
That was it.</p>
<p>\
It felt risky. Like showing up underdressed to a formal party.</p>
<p>\
But the team got it. They asked questions. They suggested ideas. QA chimed in with edge cases I hadnâ€™t thought of.</p>
<p>\
And the feature shippedâ€”faster, better, and with less friction than ever before.</p>
<h2 id="whatiusenowinsteadofspecs"><strong>What I Use Now (Instead of Specs)</strong></h2>
<p>ðŸ§© <strong>User Story Mapping</strong>â€” For seeing the flow, not just the features \n ðŸ§ <strong>Personas</strong>â€” To anchor decisions in user goals \n âœ…<strong>Lean acceptance criteria</strong>â€” So â€œdoneâ€ is clear, but not rigid \n ðŸŽ¤<strong>Team conversations</strong> â€” Because no spec beats a 15-min talk</p>
<p>\
And sometimesâ€¦ \n </p>
<p>I still write things down. But not as a crutch. As a compass.</p>
<h2 id="thehardtruthspecsmademefeelincontrolbuttheywerentsavingme"><strong>The Hard Truth: Specs Made Me Feel in Control. But They Werenâ€™t Saving Me.</strong></h2>
<p>Specs gave me the illusion of safety.</p>
<p>\
I thought they would shield me from mistakes, misunderstandings, and scope changes. But all they really did was delay reality.</p>
<p>\
What works now is different:</p>
<ul>
<li>I talk more. I listen harder.</li>
<li>I stay involved through delivery, not just at kickoff.</li>
<li>I let go of perfect. I aim for progress.</li>
</ul>
<h2 id="finalthoughtsyoudontneedaspecyouneedaseatatthetable"><strong>Final Thoughts: You Donâ€™t Need a Spec. You Need a Seat at the Table.</strong></h2>
<p>If youâ€™re a BA struggling to let go of â€œthe way it used to be,â€ I get it. I was you.</p>
<p>\
But Agile doesnâ€™t need scribes. It needs connectors.</p>
<p>\
People who create alignment, not attachments.</p>
<p>\
People who know how to lead in a room full of change.</p>
<p>\
So write if you must. But donâ€™t hide behind it.</p>
<p>\
Be the reason the team builds the <em>right</em> thing.</p>]]></content:encoded>
            <media:thumbnail url="https://hackernoon.com/https://cdn.hackernoon.com/images/ozESALSPb9PWeM05VkWH911ADP92-zw036vz.jpeg"/>
        </item>
        <item>
            <title><![CDATA[Make Your Vaadin App Smarter, Prettier, and Faster With These Advanced Styling Hacks]]></title>
            <description><![CDATA[Styling in Vaadin goes beyond simple theme definitions.]]></description>
            <link>https://hackernoon.com/make-your-vaadin-app-smarter-prettier-and-faster-with-these-advanced-styling-hacks?source=rss</link>
            <guid isPermaLink="true">https://hackernoon.com/make-your-vaadin-app-smarter-prettier-and-faster-with-these-advanced-styling-hacks?source=rss</guid>
            <category><![CDATA[programming]]></category>
            <category><![CDATA[vaadin-grid-styling]]></category>
            <category><![CDATA[vaadin-dynamic-styles]]></category>
            <category><![CDATA[vaadin-@stylesheet]]></category>
            <category><![CDATA[vaadin-lazy-css-load]]></category>
            <category><![CDATA[vaadin-custom-fonts]]></category>
            <category><![CDATA[vaadin-font-override]]></category>
            <category><![CDATA[vaadin-grid-cell-theme]]></category>
            <dc:creator><![CDATA[Paulo B.A.]]></dc:creator>
            <pubDate>Sun, 13 Apr 2025 09:07:51 GMT</pubDate>
            <image/>
            <content:encoded><![CDATA[<p>This article is part of the series: 'Towards Vaadin Developer Certification,' which aims to explain the fundamentals of Vaadin while I study for this certification. The topics covered here are an integral part of the 'Vaadin Developer' Certification.</p>
<p>\
Styling in Vaadin goes beyond simple theme definitions. Some components, like <code>Grid</code>, require dynamic styling. Additionally, fonts and images must be properly managed within the theme folder. This article explores advanced styling techniques.</p>
<p>\</p>
<h4 id="1dynamicstylingingridcomponents"><strong>1. Dynamic Styling in Grid Components</strong></h4>
<p>Grids often need row- or cell-specific styles based on data. This can be achieved using part names:</p>
<p>\
 <img src="https://cdn.hackernoon.com/images/null-wb12vls.png" alt="" /></p>
<p>Then, define styles in <code>styles.css</code>:</p>
<p>\
 <img src="https://cdn.hackernoon.com/images/null-xd22vo8.png" alt="" /></p>
<p>\
<strong>2. Lazy Loading Stylesheets</strong></p>
<p>If a stylesheet is required only in certain views, it can be loaded dynamically using <code>@StyleSheet</code>:</p>
<p>\
 <img src="https://cdn.hackernoon.com/images/null-tu52vip.png" alt="" /></p>
<p><strong>3. Styling Using Custom Fonts</strong></p>
<p>In Vaadin, custom fonts are treated as static resources, just like images or other assets. While the recommended approach is to leverage Vaadinâ€™s built-in styling options, there are cases where overriding the default Lumo font style is necessary to achieve a unique look for your application.</p>
<p>\
 <img src="https://cdn.hackernoon.com/images/null-gd62vo8.png" alt="" /></p>
<p>Below, we will guide you through the process of integrating a custom font into your Vaadin theme.</p>
<h4 id="31stepstodefineacustomfont"><strong>3.1 Steps to Define a Custom Font</strong></h4>
<p><strong>a) Obtain the Font Files</strong></p>
<p>\
You have two options to acquire the necessary font files:</p>
<p>\</p>
<ul>
<li><strong>Google Fonts</strong>: Many fonts are freely available and can be used directly.</li>
<li><strong>Font Conversion Tools</strong>: If you have a <code>.TTF</code> or <code>.OTF</code> font file, use an online tool such as Webfont Generator to convert it into web-friendly formats.</li>
</ul>
<p>\
Once converted, the ZIP file will contain:</p>
<p>\</p>
<ul>
<li><code>.WOFF</code> â€“ Web Open Font Format (recommended for modern browsers)</li>
<li><code>.WOFF2</code> â€“ Optimized version of <code>.WOFF</code>, offering better compression</li>
<li><code>stylesheet.css</code> â€“ Defines <code>@font-face</code> rules for the font</li>
</ul>
<p>\
<strong>b) Add the Font to Your Theme</strong></p>
<p>Inside your projectâ€™s theme folder (<code>frontend/themes/your-theme</code>), create a new <code>fonts</code> directory and place the following files inside:</p>
<p>\
 <img src="https://cdn.hackernoon.com/images/null-x972viz.png" alt="" /></p>
<p><strong>c) Inject the Font into Your Stylesheet</strong></p>
<p>Inside your themeâ€™s global stylesheet (<code>styles.css</code>), import the font definitions:</p>
<p>\
 <img src="https://cdn.hackernoon.com/images/null-2o82vnm.png" alt="" /></p>
<p><strong>d) Override Lumoâ€™s Default Font</strong></p>
<p>To apply the custom font across your entire application, override the <code>--lumo-font-family</code> property:</p>
<p>\
 <img src="https://cdn.hackernoon.com/images/null-rs92vx6.png" alt="" /></p>
<p>\
<strong>Conclusion</strong></p>
<p>Advanced styling in Vaadin includes dynamic grid styling, lazy-loaded stylesheets, and custom fonts. Mastering these techniques ensures highly customizable and performant applications.</p>
<p>\
 <img src="https://cdn.hackernoon.com/images/null-kca2vk0.png" alt="" /></p>
<p>\
<strong>Disclaimer</strong></p>
<p>This content is drawn from studies and notes related to the Vaadin 24 certification. For deeper details, please consult the official documentation and learning materials for Vaadin certification. AI tools assisted in the structuring of this content; however, the writing and original content are solely done by the author.</p>
<p>\
<strong>Authors</strong></p>
<p>\
Paulo B. A. is an 'Oracle Certified Java Developer' and 'Spring Certified Professional' with a deep passion for Vaadin Flow. He crafts UIs with Vaadin and strives to make it the leading frontend framework for full-stack Java developers worldwide. He loves teaching, sharing knowledge, and creating content. While he enjoys learning theory through certifications, he always advocates for a practical approach.</p>
<p>\</p>
<ul>
<li>Linkedin.com/in/pbalves</li>
<li>X.com/p<em>b</em>alves</li>
<li>Mastodon.social/@pbalves</li>
</ul>
<p>\
<strong><em>Staff Writer:</em></strong> FÃ¡bio A. P. is a technology enthusiast, self-taught writer, and scholar of society's relationship with technology. Passionate about sharing insights, he provides reliable perspectives on how technology shapes our lives. With clear and precise writing, FÃ¡bio simplifies complex topics, empowering readers to navigate the digital age with confidence.</p>
<p>\</p>
<ul>
<li>Medium.com/@fabioape</li>
</ul>
<p>\</p>]]></content:encoded>
            <media:thumbnail url="https://hackernoon.com/https://cdn.hackernoon.com/images/2jqChkrv03exBUgkLrDzIbfM99q2-2y02ufl.jpeg"/>
        </item>
        <item>
            <title><![CDATA[Lumo Who? Build Your Own Theme in Vaadin and Rule the UI]]></title>
            <description><![CDATA[While Vaadin offers built-in themes like Lumo, customizing themes is often necessary to align the applicationâ€™s appearance with branding requirements.]]></description>
            <link>https://hackernoon.com/lumo-who-build-your-own-theme-in-vaadin-and-rule-the-ui?source=rss</link>
            <guid isPermaLink="true">https://hackernoon.com/lumo-who-build-your-own-theme-in-vaadin-and-rule-the-ui?source=rss</guid>
            <category><![CDATA[programming]]></category>
            <category><![CDATA[vaadin-custom-theme]]></category>
            <category><![CDATA[vaadin-css-tutorial]]></category>
            <category><![CDATA[vaadin-theme.json]]></category>
            <category><![CDATA[vaadin-theme-jar]]></category>
            <category><![CDATA[vaadin-styles.css]]></category>
            <category><![CDATA[vaadin-lumo-override]]></category>
            <category><![CDATA[vaadin-extend-theme]]></category>
            <dc:creator><![CDATA[Paulo B.A.]]></dc:creator>
            <pubDate>Sun, 13 Apr 2025 09:04:29 GMT</pubDate>
            <image/>
            <content:encoded><![CDATA[<p>This article is part of the series: 'Towards Vaadin Developer Certification,' which aims to explain the fundamentals of Vaadin while I study for this certification. The topics covered here are an integral part of the 'Vaadin Developer' Certification.</p>
<p>\
While Vaadin offers built-in themes like Lumo, customizing themes is often necessary to align the applicationâ€™s appearance with branding requirements. This article delves into creating custom themes and styling components using CSS.</p>
<p>\
<strong>1. Creating a Custom Theme</strong></p>
<p>\
A custom theme allows overriding Lumo styles or defining entirely new ones. The recommended approach is extending Lumo instead of starting from scratch.</p>
<p>\
<strong>Steps to create a custom theme:</strong></p>
<p>\</p>
<ol>
<li>Create a folder:</li>
</ol>
<p>\
 <img src="https://cdn.hackernoon.com/images/null-f812vyg.png" alt="" /></p>
<ol start="2">
<li>Inside this folder, define <code>theme.json</code>:</li>
</ol>
<p>\
 <img src="https://cdn.hackernoon.com/images/null-ps22vus.png" alt="" /></p>
<ol start="3">
<li>Create a styles.css file inside my-theme:</li>
</ol>
<p>\
 <img src="https://cdn.hackernoon.com/images/null-jt32v3k.png" alt="" /></p>
<p>Finally, apply the custom theme in Java:</p>
<p>\
 <img src="https://cdn.hackernoon.com/images/null-7042vnk.png" alt="" /></p>
<p>\
<strong>2. Organizing CSS Files for Maintainability</strong></p>
<p>\
Vaadin allows importing stylesheets within <code>styles.css</code>:</p>
<p>\
 <img src="https://cdn.hackernoon.com/images/null-hg62v0f.png" alt="" /></p>
<p>This keeps styles modular and easier to maintain.</p>
<p>\
 <img src="https://cdn.hackernoon.com/images/null-ey72vop.png" alt="" /></p>
<p>\
<strong>3. Packaging Custom Themes as JAR Files</strong></p>
<p>\
Themes can be distributed as dependencies by packaging them into a JAR file. The project consuming this theme needs to reference it via <code>@Theme("your-theme")</code>.</p>
<p>\
<strong>Conclusion</strong></p>
<p>\
Customizing Vaadin themes allows developers to tailor UI appearance while leveraging Lumoâ€™s structure. By organizing stylesheets and packaging themes efficiently, applications remain maintainable and scalable.</p>
<p>\
<strong>Disclaimer</strong></p>
<p>This content is drawn from studies and notes related to the Vaadin 24 certification. For deeper details, please consult the official documentation and learning materials for Vaadin certification. AI tools assisted in the structuring of this content; however, the writing and original content are solely done by the author.</p>
<p>\
<strong>Authors</strong></p>
<p>\
Paulo B. A. is an 'Oracle Certified Java Developer' and 'Spring Certified Professional' with a deep passion for Vaadin Flow. He crafts UIs with Vaadin and strives to make it the leading frontend framework for full-stack Java developers worldwide. He loves teaching, sharing knowledge, and creating content. While he enjoys learning theory through certifications, he always advocates for a practical approach.</p>
<p>\</p>
<ul>
<li>Linkedin.com/in/pbalves</li>
<li>X.com/p<em>b</em>alves</li>
<li>Mastodon.social/@pbalves</li>
</ul>
<p>\
<strong><em>Staff Writer:</em></strong> FÃ¡bio A. P. is a technology enthusiast, self-taught writer, and scholar of society's relationship with technology. Passionate about sharing insights, he provides reliable perspectives on how technology shapes our lives. With clear and precise writing, FÃ¡bio simplifies complex topics, empowering readers to navigate the digital age with confidence.</p>
<p>\</p>
<ul>
<li>Medium.com/@fabioape</li>
</ul>
<p>\</p>]]></content:encoded>
            <media:thumbnail url="https://hackernoon.com/https://cdn.hackernoon.com/images/2jqChkrv03exBUgkLrDzIbfM99q2-u602uci.jpeg"/>
        </item>
        <item>
            <title><![CDATA[This One Line of Code Can Change Your Entire Vaadin Appâ€™s Look]]></title>
            <description><![CDATA[Theming is a fundamental aspect of any Vaadin application, allowing developers to define the look and feel of their UI.]]></description>
            <link>https://hackernoon.com/this-one-line-of-code-can-change-your-entire-vaadin-apps-look?source=rss</link>
            <guid isPermaLink="true">https://hackernoon.com/this-one-line-of-code-can-change-your-entire-vaadin-apps-look?source=rss</guid>
            <category><![CDATA[programming]]></category>
            <category><![CDATA[vaadin-theme-tutorial]]></category>
            <category><![CDATA[vaadin-@theme-example]]></category>
            <category><![CDATA[vaadin-custom-theme]]></category>
            <category><![CDATA[vaadin-lumo-dark-mode]]></category>
            <category><![CDATA[vaadin-no-theme]]></category>
            <category><![CDATA[how-to-theme-vaadin-app]]></category>
            <category><![CDATA[vaadin-ui-customization]]></category>
            <dc:creator><![CDATA[Paulo B.A.]]></dc:creator>
            <pubDate>Sun, 13 Apr 2025 09:00:21 GMT</pubDate>
            <image/>
            <content:encoded><![CDATA[<p>This article is part of the series: 'Towards Vaadin Developer Certification,' which aims to explain the fundamentals of Vaadin while I study for this certification. The topics covered here are an integral part of the 'Vaadin Developer' Certification.</p>
<p>\
Theming is a fundamental aspect of any Vaadin application, allowing developers to define the look and feel of their UI.</p>
<p>\
In Vaadin, themes are applied using the <code>@Theme</code>  annotation, which provides flexibility to choose between predefined themes like Lumo or create fully customized ones. This article explores how <code>@Theme</code> works and its variations.</p>
<p>\
<strong>1. Applying a Theme with @Theme</strong></p>
<p>\
The <code>@Theme</code> annotation is used to specify the theme for a Vaadin application. By default, if no theme is set, the application uses Lumo. However, we can explicitly declare it:</p>
<p>\
 <img src="https://cdn.hackernoon.com/images/mQASO0gEh1UdjIgDqdAaAWkjxkp2-gg02vug.png" alt="" /></p>
<p>Additionally, we can define theme variants like <code>Lumo.DARK</code>:</p>
<p>\
 <img src="https://cdn.hackernoon.com/images/mQASO0gEh1UdjIgDqdAaAWkjxkp2-zo12v5i.png" alt="" /></p>
<p>\
<strong>2. Disabling Themes with @NoTheme</strong></p>
<p>\
Sometimes, a specific view might need to be rendered without any theme, even the default Lumo theme. This is where <code>@NoTheme</code> comes into play:</p>
<p>\
 <img src="https://cdn.hackernoon.com/images/mQASO0gEh1UdjIgDqdAaAWkjxkp2-iy22vng.png" alt="" /></p>
<p>However, disabling themes entirely is not recommended unless absolutely necessary. Instead, extending and modifying Lumo is the preferred approach.</p>
<p>\
<strong>Conclusion</strong></p>
<p>\
The <code>@Theme</code> annotation provides a structured way to apply theming in Vaadin applications. Whether using predefined themes like Lumo or creating custom themes, understanding how to manage them effectively ensures a consistent user experience while maintaining flexibility in UI design.</p>
<p>\
<strong>Disclaimer</strong></p>
<p>This content is drawn from studies and notes related to the Vaadin 24 certification. For deeper details, please consult the official documentation and learning materials for Vaadin certification. AI tools assisted in the structuring of this content; however, the writing and original content are solely done by the author.</p>
<p>\
<strong>Authors</strong></p>
<p>\
Paulo B. A. is an 'Oracle Certified Java Developer' and 'Spring Certified Professional' with a deep passion for Vaadin Flow. He crafts UIs with Vaadin and strives to make it the leading frontend framework for full-stack Java developers worldwide. He loves teaching, sharing knowledge, and creating content. While he enjoys learning theory through certifications, he always advocates for a practical approach.</p>
<p>\</p>
<ul>
<li>Linkedin.com/in/pbalves</li>
<li>X.com/p<em>b</em>alves</li>
<li>Mastodon.social/@pbalves</li>
</ul>
<p>\
<strong><em>Staff Writer:</em></strong> FÃ¡bio A. P. is a technology enthusiast, self-taught writer, and scholar of society's relationship with technology. Passionate about sharing insights, he provides reliable perspectives on how technology shapes our lives. With clear and precise writing, FÃ¡bio simplifies complex topics, empowering readers to navigate the digital age with confidence.</p>
<p>\</p>
<ul>
<li>Medium.com/@fabioape</li>
</ul>
<p>\</p>]]></content:encoded>
            <media:thumbnail url="https://hackernoon.com/https://cdn.hackernoon.com/images/2jqChkrv03exBUgkLrDzIbfM99q2-gu02ud4.jpeg"/>
        </item>
        <item>
            <title><![CDATA[Before You Burn Millions on Ads, Try Talking to People]]></title>
            <description><![CDATA[Business development can be used as a blueprint for market validation. Instead of asking, â€œHow can we sell here?â€™ â€” we asked, â€˜What can we learn here?' The KPIs werenâ€™t revenue. They were qualitative conversations with ICPs.]]></description>
            <link>https://hackernoon.com/before-you-burn-millions-on-ads-try-talking-to-people?source=rss</link>
            <guid isPermaLink="true">https://hackernoon.com/before-you-burn-millions-on-ads-try-talking-to-people?source=rss</guid>
            <category><![CDATA[startups]]></category>
            <category><![CDATA[business-growth]]></category>
            <category><![CDATA[b2b-sales]]></category>
            <category><![CDATA[market-expansion-strategy]]></category>
            <category><![CDATA[gtm-fit-evaluation]]></category>
            <category><![CDATA[customer-discovery-method]]></category>
            <category><![CDATA[b2b-market-discovery]]></category>
            <category><![CDATA[market-entry-framework]]></category>
            <dc:creator><![CDATA[Evgeniia Megrian]]></dc:creator>
            <pubDate>Sun, 13 Apr 2025 08:53:40 GMT</pubDate>
            <image/>
            <content:encoded><![CDATA[<p>When most companies talk about expanding into new markets, the first instinct is to crank up performance marketing, localize the website, or spin up a regional sales team. But hereâ€™s the truth: <strong>you canâ€™t scale what you donâ€™t understand.</strong></p>
<p>\
In one of my most pivotal roles, we were tasked with launching into two new regions â€” without wasting months (or millions) on unvalidated assumptions. The twist? We didn't lead with marketing. We turned <strong>business development</strong> into our <strong>market discovery engine</strong> â€” and it changed how we scale <strong>forever</strong>.</p>
<p>\
This article is about how we used BD to <strong>explore</strong>, <strong>test</strong>, and <strong>adapt</strong> before making any big bets. Think of it as a blueprint for market validation â€” one conversation, signal, and small partnership at a time.</p>
<h2 id="step1redefinetheroleofbdfromsellertoscout">Step 1: Redefine the Role of BD â€” From Seller to Scout</h2>
<p>In most orgs, business development is tasked with creating pipeline or closing partnerships. But in an expansion scenario, we flipped the script. Instead of asking, â€œHow can we sell here?â€ â€” we asked, <strong>â€œWhat can we learn here?â€</strong></p>
<p>\
We created a temporary role called <strong>Market Discovery BD</strong>. The KPIs werenâ€™t revenue. They were:</p>
<ul>
<li>Number of qualitative conversations with ICPs</li>
<li>Signals about market pain, behavior, and maturity</li>
<li>Evidence of potential GTM fit (tools, processes, budget owners)</li>
</ul>
<p>\
Our BD lead wasnâ€™t armed with a pitch deck. They were armed with a <strong>discovery script</strong>, focused on learning:</p>
<ul>
<li>What local alternatives are already dominant?</li>
<li>How are buying decisions made?</li>
<li>What are the most urgent problems no one's solving?</li>
</ul>
<p>\
Within three weeks, we had 42 interviews across 3 verticals â€” and some assumptions completely unraveled.</p>
<h2 id="step2prototypeoffersthroughconversationalgtm">Step 2: Prototype Offers Through Conversational GTM</h2>
<p>Rather than launching a new pricing page or funnel, we started by <strong>prototyping offers</strong> directly through conversations.</p>
<p>\
Hereâ€™s how it worked:In week 4, we began proposing <strong>lightweight pilots</strong> to high-signal accounts. Not via campaigns â€” via BD calls.</p>
<p>\
Weâ€™d say:</p>
<p>\</p>
<blockquote>
  <p>â€œBased on what you shared, we can spin up a pilot focused just on [pain point X], using [feature Y]. Would you be open to trying that over 2 weeks?â€</p>
</blockquote>
<p>\
The response rate? 60%+ interest. Why? Because the offer came after deep understanding â€” not before.</p>
<p>\
This helped us answer:</p>
<ul>
<li>What positioning resonates most?</li>
<li>What objections are we hearing early?</li>
<li>What kind of results move the needle for these customers?</li>
</ul>
<p>\
Instead of writing case studies months later, we were generating <strong>real outcomes</strong> during discovery â€” and feeding those insights into product and marketing in real time.</p>
<h2 id="step3usebdfeedbackloopstodesignscalablegtm">Step 3: Use BD Feedback Loops to Design Scalable GTM</h2>
<p>By week 6, we had real traction. A handful of customers had completed fast pilots, shared testimonials, and even introduced us to other local players.</p>
<p>\
But more importantly, our BD team had collected <strong>first-hand, structured intelligence</strong> that shaped everything:</p>
<ul>
<li>Messaging â†’ We dropped â€œefficiencyâ€ in favor of â€œspeed to ROIâ€</li>
<li>Objections â†’ We created specific assets to answer local procurement issues</li>
<li>Ideal Customer Profile â†’ We narrowed our focus to mid-sized tech teams with internal tooling challenges</li>
</ul>
<p>\
We fed all of this into a <strong>GTM readiness doc</strong>, co-created by BD, marketing, and product. It was clear:</p>
<ol>
<li>Where to focus</li>
<li>How to position</li>
<li>What was still missing</li>
</ol>
<p>\
Only then did we greenlight regional ad spend, build local landing pages, and begin hiring.</p>
<h2 id="conclusion">Conclusion</h2>
<p><img src="https://cdn.hackernoon.com/images/null-84239mu.gif.webp" alt="" /></p>
<p>\
Using BD as a <strong>market exploration tool</strong> â€” not just a channel â€” helped us move faster, de-risk expansion, and build real conviction before we scaled. In a world obsessed with automation and dashboards, itâ€™s easy to forget the power of high-signal, human conversations. But if you treat business development as a learning engine, you get more than leads. You get clarity.</p>
<p>\
So before you launch your next region, ask yourself: <strong>Are you ready to sell â€” or do you still need to listen?</strong></p>]]></content:encoded>
            <media:thumbnail url="https://hackernoon.com/https://cdn.hackernoon.com/images/2jqChkrv03exBUgkLrDzIbfM99q2-as02ukw.webp"/>
        </item>
        <item>
            <title><![CDATA[Your Marketing Team Doesnâ€™t Need Another Meetingâ€”It Needs a Better Data Stack]]></title>
            <description><![CDATA[In fast-scaling tech companies, misalignment between product, sales, and marketing isnâ€™t just inconvenient â€” itâ€™s expensive. Teams operate on different metrics, tools, and timelines. Disconnected strategies, delayed feedback loops, and missed revenue opportunities.]]></description>
            <link>https://hackernoon.com/your-marketing-team-doesnt-need-another-meetingit-needs-a-better-data-stack?source=rss</link>
            <guid isPermaLink="true">https://hackernoon.com/your-marketing-team-doesnt-need-another-meetingit-needs-a-better-data-stack?source=rss</guid>
            <category><![CDATA[business-growth]]></category>
            <category><![CDATA[sales]]></category>
            <category><![CDATA[ai-growth]]></category>
            <category><![CDATA[startups]]></category>
            <category><![CDATA[marketing]]></category>
            <category><![CDATA[startups-data-stack]]></category>
            <category><![CDATA[startup-advice]]></category>
            <category><![CDATA[scaling-companies]]></category>
            <dc:creator><![CDATA[Evgeniia Megrian]]></dc:creator>
            <pubDate>Sun, 13 Apr 2025 08:48:47 GMT</pubDate>
            <image/>
            <content:encoded><![CDATA[<p>Hallo my gals and boys!! Letâ€™s talk alignment. In fast-scaling tech companies, misalignment between product, sales, and marketing isnâ€™t just inconvenient â€” itâ€™s expensive. Teams operate on different metrics, tools, and timelines. <strong>The result? Disconnected strategies, delayed feedback loops, and missed revenue opportunities.</strong> </p>
<p>\
But alignment isnâ€™t about more meetings â€” itâ€™s about <strong>building the right data infrastructure</strong>.</p>
<p>\
In this article, Iâ€™ll walk you through how we approached cross-functional GTM alignment by connecting product analytics, marketing attribution, and sales behavior into one growth engine â€” with practical examples of tools, architecture, and decision-making that drove measurable business impact.</p>
<h2 id="startwiththerightquestionsanddatasources">Start With the Right Questions (and Data Sources)</h2>
<p><strong>We began by identifying the key friction points between teams:</strong></p>
<ul>
<li>Marketing wanted to know which campaigns led to product-qualified leads (PQLs), not just MQLs.</li>
<li>Sales needed context: â€œWhat features has this user tried? Are they stuck in onboarding?â€</li>
<li>Product wanted visibility into which features actually influenced deal velocity or expansion.</li>
</ul>
<p>\
<strong>To solve this, we mapped 3 core data sources:</strong></p>
<ul>
<li><strong>Amplitude</strong> for product analytics</li>
<li><strong>HubSpot CRM</strong> for sales + lead data</li>
<li><strong>Segment + Google Analytics</strong> for marketing attribution</li>
</ul>
<p>\
But plugging in these tools wasnâ€™t enough. The real challenge was <strong>connecting them meaningfully.</strong></p>
<h2 id="buildtheunifiedgrowthdatalayer">Build the Unified Growth Data Layer</h2>
<p>We introduced Segment CDP as the core customer data platform. Every event â€” from a button click in the product to a LinkedIn ad interaction â€” was funneled into Segment and tagged with a unified user ID across platforms.</p>
<p>\
Then we pushed this data downstream:</p>
<ul>
<li>Into Amplitude to enrich product dashboards with marketing source + sales status</li>
<li>Into HubSpot to give sales reps real-time visibility into user behavior (â€œTrial user added 3 teammates yesterdayâ€)</li>
<li>Into a custom Metabase dashboard, which blended marketing source â†’ product usage â†’ sales outcome</li>
</ul>
<p>\
<strong>This gave all teams a shared source of truth:</strong></p>
<p>â†’ Marketing could optimize campaigns toward feature activations, not just form fills</p>
<p>â†’ Sales could prioritize outreach based on product intent</p>
<p>â†’ Product could see what GTM levers accelerated usage</p>
<h2 id="automatethefeedbackloops">Automate the Feedback Loops</h2>
<p>Once this infrastructure was live, we automated the key workflows that previously relied on manual handovers or Slack messages.</p>
<p>:::tip
For example:</p>
<ul>
<li>When a trial user reached a key milestone (e.g., activated core feature), a HubSpot workflow alerted their assigned rep.</li>
<li>When a high-spend customer downgraded usage, Amplitude triggered a Slack alert to the Customer Success Manager with context.</li>
<li>When a lead converted to a customer, the original UTM parameters and campaign IDs were logged automatically in our analytics schema for revenue attribution.</li>
</ul>
<p>:::</p>
<p>This reduced lag time in handoffs by over 70% and directly contributed to a 22% increase in conversion from trial to paid over three quarters.</p>
<h2 id="makeitactionablenotjustvisual">Make It Actionable, Not Just Visual</h2>
<p>Dashboards alone arenâ€™t enough. One of our key learnings was: Data must drive action. So we trained each team on how to actually use these insights. Marketing reviewed campaign-driven feature usage weekly, not just CPL. Sales used product activity as part of their deal scoring logic. Product started prioritizing onboarding tweaks based on drop-offs visible in multi-touch funnel analysis.</p>
<p>\
We also created <strong>"Growth Syncs" â€” biweekly sessions with one rep from each GTM team to review data anomalies, test hypotheses, and launch small experiments based on shared insights.</strong></p>
<h2 id="conclusion">Conclusion</h2>
<p>True GTM alignment doesnâ€™t happen in a slide deck â€” itâ€™s built in your infrastructure. When product, sales, and marketing share a connected data foundation, they stop competing for credit and start collaborating toward growth.</p>
<p>\
This approach helped us scale from siloed departments to a cohesive revenue engine, grounded in real-time insight and proactive decision-making.</p>
<p>\
For anyone building or refining a GTM strategy in a digital company, donâ€™t ask how your teams can align. Ask: What data do they need to think like one team?</p>
<p><img src="https://cdn.hackernoon.com/images/null-rs039sn.webp" alt="" /></p>]]></content:encoded>
            <media:thumbnail url="https://hackernoon.com/https://cdn.hackernoon.com/images/2jqChkrv03exBUgkLrDzIbfM99q2-qr02uo1.webp"/>
        </item>
        <item>
            <title><![CDATA[AI is Changing the DNA of Sales Enablement]]></title>
            <description><![CDATA[Sales enablement was synonymous with static PDFs, battlecards, and quarterly workshops. From hyper-personalized coaching to real-time intelligence, artificial intelligence is moving sales enablement from the realm of support to a true revenue-driving function.]]></description>
            <link>https://hackernoon.com/ai-is-changing-the-dna-of-sales-enablement?source=rss</link>
            <guid isPermaLink="true">https://hackernoon.com/ai-is-changing-the-dna-of-sales-enablement?source=rss</guid>
            <category><![CDATA[startups]]></category>
            <category><![CDATA[b2b-sales]]></category>
            <category><![CDATA[sales]]></category>
            <category><![CDATA[sales-enablement-tools]]></category>
            <category><![CDATA[sales-tech]]></category>
            <category><![CDATA[building-a-sales-team]]></category>
            <category><![CDATA[revenue-intelligence]]></category>
            <category><![CDATA[ai-sales-enablement]]></category>
            <dc:creator><![CDATA[Evgeniia Megrian]]></dc:creator>
            <pubDate>Sun, 13 Apr 2025 08:39:59 GMT</pubDate>
            <image/>
            <content:encoded><![CDATA[<p>Hey gals and boys! Letâ€™s talk facts. Not long ago, sales enablement was synonymous with static PDFs, battlecards, and quarterly workshops. Sales managers hoped reps remembered key phrases or used the right slide deck â€” but insights were limited, and training was often one-size-fits-all from startups with 5 people in sales teams to enterprises with 800 reps (crazy)</p>
<p>\
Fast forward to today: AI is fundamentally transforming the way companies equip their sales teams. From hyper-personalized coaching to real-time intelligence, artificial intelligence is moving sales enablement from the realm of support to a true revenue-driving function.</p>
<p>\
In this article, <strong>Iâ€™ll break down how AI is changing the DNA of sales enablement, with specific tools, frameworks, and real-world use cases that modern GTM teams are already implementing.</strong></p>
<h2 id="aipoweredcoachingturningeverycallintoalearningmoment">AI-Powered Coaching: Turning Every Call Into a Learning Moment</h2>
<p><img src="https://cdn.hackernoon.com/images/null-yv239ar.gif.webp" alt="" /></p>
<p>At a scaling SaaS company I worked with, one of the biggest challenges was ramp time. New reps took three to five months to reach full productivity, and traditional onboarding â€” a combination of slide decks, shadowing, and group sessions â€” wasnâ€™t cutting it. We introduced <strong>Gong</strong>, a conversation intelligence platform that records and transcribes sales calls. But we didnâ€™t stop at transcription.</p>
<p>\
Gongâ€™s AI began analyzing the talk-to-listen ratio, interruptions, filler words, and keyword frequency â€” automatically flagging coachable moments.</p>
<p>\
One week after rolling it out, we had an enablement dashboard showing:</p>
<ul>
<li>which reps were dominating conversations,</li>
<li>which ones avoided pricing discussions,</li>
<li>and who was actually using the objection-handling frameworks from training.</li>
</ul>
<p>\
Instead of reviewing hours of call recordings, managers focused on the top 3â€“5 moments per rep. ==Within a quarter, average ramp time dropped by 30%, and the team improved demo-to-close rates by 18%.==</p>
<h2 id="realtimeenablementfromstaticplaybookstoliveguidance">Real-Time Enablement: From Static Playbooks to Live Guidance</h2>
<p>Reps donâ€™t need more documents â€” they need <strong>real-time help</strong>. This is where AI assistants come in.</p>
<p>\
Imagine this: you're in a live discovery call with a VP of Marketing. The prospect says, "Weâ€™ve been trying to reduce our CAC, but our attribution is a mess." Instantly, your AI copilot (built using tools like <a href="http://Fireflies.ai">Fireflies.ai</a> or a ChatGPT API with custom instructions) pulls up a case study for a similar client, along with a one-liner pitch on how your product solves attribution issues. It even suggests a follow-up question to ask next.</p>
<p>\
In practice, we deployed a lightweight internal Chrome extension using OpenAIâ€™s API that linked our CRM (HubSpot) and shared knowledge base. It would trigger contextual prompts based on keywords during calls â€” offering content recommendations, relevant use cases, or counter-objection tips. Reps didnâ€™t have to alt-tab or search folders. They had the right intel, right when they needed it.</p>
<p>\
==Thatâ€™s not just enablement. Thatâ€™s real-time, AI-powered augmentation â€” a smarter way to scale knowledge across a growing team.==</p>
<h2 id="connectingenablementtorevenuetheroleofaiinforecasting">Connecting Enablement to Revenue: The Role of AI in Forecasting</h2>
<p>Most sales leaders rely on CRM hygiene and rep sentiment to forecast. But those are lagging signals. What if your forecast could consider <strong>enablement behavior</strong>?</p>
<p>\
At one point, we worked with <strong>Clari</strong>, a revenue intelligence tool that tracks not just deal progression, but rep activity, content usage, and historical coaching data. We discovered that reps who skipped onboarding quizzes or didnâ€™t engage with enablement tools were consistently below target. Clari flagged those deals as higher risk â€” not just because of pipeline signals, but because of how the rep was operating.</p>
<p>\
For example, one rep had several high-value opportunities stuck in negotiation. By layering Gong and Clari data, we found they hadnâ€™t used pricing calculators or ROI templates in a single deal. We re-engaged enablement content, coached the rep on ROI selling, and within two weeks, two of the deals closed.</p>
<p>\
==This kind of <strong>behavior-driven forecasting</strong> is only possible when enablement, sales ops, and AI-powered tools are tightly integrated.==</p>
<h2 id="buildingaculturearoundaidrivenenablement">Building a Culture Around AI-Driven Enablement</h2>
<p><img src="https://cdn.hackernoon.com/images/null-6i339xd.gif.webp" alt="" /></p>
<p>\
Tech is only half the story. The companies that succeed with AI in sales enablement do so by embedding it into their culture.</p>
<p>\
We established monthly â€œenablement insights reviews,â€ where the sales team would review anonymized call learnings, celebrate top improvements, and share AI-flagged success patterns. Reps were encouraged to challenge the AIâ€™s suggestions and propose better ones â€” which made adoption stick.</p>
<p>\
==One of the best moves was assigning <strong>AI champions</strong>== â€” usually top-performing AEs or SDRs â€” ==to test new tools and offer peer training.== When feedback came from peers instead of just enablement leaders, adoption and trust in the AI tools skyrocketed.</p>
<p>\
The result? AI was no longer viewed as surveillance or complexity. It became a trusted sidekick. Platforms like <strong>Clari</strong>, <strong>BoostUp</strong>, and <strong>Ebsta</strong> are bridging this gap. The result: <strong>tighter coaching, stronger pipeline hygiene, and fewer end-of-quarter surprises.</strong></p>
<h2 id="finalthoughts">Final Thoughts</h2>
<p>AI isnâ€™t replacing sales enablement â€” itâ€™s supercharging it. Weâ€™re moving from guesswork to precision, from static content to real-time coaching, from linear onboarding to continuous improvement loops.</p>
<p>\
For companies operating in competitive digital industries, adopting AI in sales enablement isnâ€™t a nice-to-have. Itâ€™s a <strong>strategic differentiator.</strong></p>
<p>\
The next generation of sales enablement will be defined by those who donâ€™t just train reps â€” but build intelligent systems around them.</p>
<p>\
And with AI, we finally have the tools to do it :)</p>]]></content:encoded>
            <media:thumbnail url="https://hackernoon.com/https://cdn.hackernoon.com/images/7EKh2ZN86ROaLmzd1pi8HpT4CML2-d5039jm.gif.webp"/>
        </item>
        <item>
            <title><![CDATA[Bitcoin Promised to Help Tonga After Disasterâ€”But the Blockchain Tells a Murkier Story]]></title>
            <description><![CDATA[What happened to Bitcoin donations sent to Tonga after the January 2022 Hunga Tongaâ€“Hunga HaÊ»apai volcanic eruption and tsunami?]]></description>
            <link>https://hackernoon.com/bitcoin-promised-to-help-tonga-after-disasterbut-the-blockchain-tells-a-murkier-story?source=rss</link>
            <guid isPermaLink="true">https://hackernoon.com/bitcoin-promised-to-help-tonga-after-disasterbut-the-blockchain-tells-a-murkier-story?source=rss</guid>
            <category><![CDATA[bitcoin]]></category>
            <category><![CDATA[disaster-relief]]></category>
            <category><![CDATA[bitcoin-donations]]></category>
            <category><![CDATA[tonga-volcano-eruption]]></category>
            <category><![CDATA[tonga's-crypto-relief]]></category>
            <category><![CDATA[btc-relief-mystery]]></category>
            <category><![CDATA[crypto-for-disaster]]></category>
            <category><![CDATA[crypto-mystery]]></category>
            <dc:creator><![CDATA[Edwin Liava'a]]></dc:creator>
            <pubDate>Sun, 13 Apr 2025 08:37:44 GMT</pubDate>
            <image/>
            <content:encoded><![CDATA[<h2 id="thedisasterthatdisconnectedanation">The Disaster That Disconnected a Nation</h2>
<p>In January 2022, the Kingdom of Tonga experienced a catastrophic event when the Hunga Tonga and Hunga Ha'apai underwater volcano erupted, triggering a tsunami with waves reaching up to 1.2 meters. This natural disaster not only caused immediate physical damage to homes and infrastructure but critically severed Tonga's submarine cable network effectively cutting the island nation off from the rest of the world.</p>
<p>\
As reported, the tsunami left citizens fleeing to higher ground, with immediate concerns focusing on air and water contamination. But beyond the physical damage, a critical problem emerged i.e. with traditional communication networks down, how could aid reach those affected?</p>
<h2 id="bitcoinandsatellitetechnologyduringthecrisis">Bitcoin and Satellite Technology During the Crisis</h2>
<p>In this moment of crisis, Lord Fusitu'a, a former Tongan lawmaker and Bitcoin advocate who has since passed away, established a Bitcoin wallet to receive donations for relief efforts.</p>
<p>\
During the disaster, Tonga had limited satellite connectivity through providers like Starlink, Kacific, and Intelsat systems, though these connections were constrained. The question of whether Bitcoin transactions could effectively reach the island during this communication blackout remained uncertain.</p>
<p>\
While some crypto advocates suggested that Bitcoin could function as an alternative financial channel when traditional systems failed, the practical implementation of this during the Tongan crisis lacks clear documentation.</p>
<p>\
As reported at the time, the underwater cable damage significantly impaired communications, with most connection lines potentially down for up to two weeks.</p>
<h2 id="thewalletthatreceiveddonations">The Wallet That Received Donations</h2>
<p>Following the disaster, Lord Fusitu'a (a former Tongan lawmaker who has since passed away) set up a Bitcoin wallet with the address bc1qmn6ddugyj853vgmcvljs5te6rl9teuhz6t5cun to receive donations for relief efforts.</p>
<p>\
According to blockchain data from BTCscan.org, "Address bc1qmn6ddugyj853vgmcvljs5te6rl9teuhz6t5cun has 421 transactions on the Bitcoin blockchain. Last balance change was 2022-11-26 17:21:17 GMT +13. It has received a total of 0.55640009 BTC and has sent a total of 0.55640009 BTC. The current balance of this address is 0 BTC."</p>
<p>\
This data is corroborated by Blockchain.com explorer which shows: "This address has transacted 421 times on the Bitcoin blockchain. It has received a total of 0.55640009 BTC ($47,380.32 USD) and has sent a total of 0.55640009 BTC ($47,380.32 USD). The current value of this address is 0.00000000 BTC ($0.00 USD)."</p>
<p>\
These blockchain records confirm that the wallet received exactly 0.55640009 BTC (equivalent to $47,380.32 USD at the time) through 421 separate transactions. The blockchain explorers also verify that all funds were eventually transferred out, as the wallet currently shows a zero balance, with the last transaction occurring on November 26, 2022 i.e. approximately 10 months after the disaster.</p>
<h2 id="followingthemoneyablockchaininvestigation">Following The Money - A Blockchain Investigation</h2>
<p>Using blockchain explorers to trace the Bitcoin donations, we can see exactly where the funds were transferred. The wallet address (bc1qmn6ddugyj853vgmcvljs5te6rl9teuhz6t5cun) received a total of 0.55640009 BTC (approximately $47,380.32 USD at the time) through 421 separate transactions, with the wallet now showing a zero balance as all funds were transferred out.</p>
<p>\
The transaction history reveals that the majority of the funds (0.53275717 BTC) were sent to another wallet address (0001c9d33d5392f5) in a single transaction on January 26, 2022. This transaction (a68820cdc4dedd18910aa36cd27c78766a2500e2b8acac3dcd2329fba04b2b99) represented approximately 96% of all the donations received.</p>
<p>\
Further investigation into this destination wallet shows that the funds remained there for approximately three months until April 18, 2022, by which time the wallet balance had grown to approximately 27.4 BTC through additional deposits. On that date, almost all funds (27.44593953 BTC) were withdrawn in a coordinated series of transactions, with the vast majority (27.44593153 BTC) going to yet another wallet address (ebe8bf9650aec2a2).</p>
<p>\
As of today, both Lord Fusitu'a's original donation wallet and the intermediary wallet show zero balances, with all funds having been transferred elsewhere. Without additional information about who controls these subsequent wallets, it remains impossible to determine if any of these funds ever reached the Tongan government treasury or were used for tsunami relief efforts.</p>
<p>\
Further investigation reveals additional insights into the destination wallet address ebe8bf9650aec2a2. This wallet is connected to Bitcoin Address bc1q0df9cftpteg497wlrnyvq7cydmvlkntqttwkfy, which has transacted 51 times on the Bitcoin blockchain. According to blockchain explorers, this address has:</p>
<ul>
<li>Received a total of 85.74384128 BTC ($7,322,850 USD)</li>
<li>Sent a total of 85.51491921 BTC ($7,303,299 USD)</li>
<li>Current balance of 0.22892207 BTC ($19,550.82 USD)</li>
</ul>
<h2 id="themysteryremainsunansweredquestions">The Mystery Remains - Unanswered Questions</h2>
<p>Despite being able to trace the movement of funds through the blockchain, critical questions remain unanswered. The primary question is i.e. Did any of these Bitcoin donations actually reach the Tongan Government Treasury? If they did, why was there no press release or public acknowledgment from the government at that time? The complete lack of official documentation regarding the receipt or distribution of these funds raises important transparency concerns.</p>
<p>\
While we can see that funds moved from Lord Fusitu'a's wallet to an intermediary wallet and then to another destination, I cannot determine who controls these subsequent wallets at this point in time without additional off-chain information. This creates a disconnect between on-chain transparency and real-world accountability, especially when used for disaster relief efforts where public trust is essential but the local government has not adopted the use of cryptocurrency as legal tender.</p>
<p>\
The current balance of both Lord Fusitu'a's donation wallet and the intermediary wallet is 0.00000000 BTC ($0.00 USD), with no activity in the original donation wallet since November 26, 2022.</p>
<h2 id="conclusiontheongoinginvestigation">Conclusion - The Ongoing Investigation</h2>
<p>The Tonga Bitcoin donation case presents a fascinating blockchain investigation that continues to unfold. The remarkable transparency of blockchain technology allows us to meticulously track every movement of funds from the initial donations to their subsequent transfers across multiple wallets.</p>
<p>\
We have precise records showing:</p>
<ul>
<li><p>Total donations received: 0.55640009 BTC ($47,380.32 USD)</p></li>
<li><p>Number of transactions: 421</p></li>
<li><p>A significant transfer of 27.44593153 BTC (approximately $2,336,418 USD at the time) to wallet address ebe8bf9650aec2a2</p>
<p>\</p></li>
</ul>
<p>Further investigation uncovered additional details about the destination wallet. The address ebe8bf9650aec2a2, connected to Bitcoin Address bc1q0df9cftpteg497wlrnyvq7cydmvlkntqttwkfy, shows:</p>
<ul>
<li><p>51 total blockchain transactions</p></li>
<li><p>Total received: 85.74384128 BTC ($7,322,850 USD)</p></li>
<li><p>Total sent: 85.51491921 BTC ($7,303,299 USD)</p></li>
<li><p>Current balance: 0.22892207 BTC ($19,550.82 USD)</p>
<p>\</p></li>
</ul>
<p>We can render this investigation as far from over. If our commitment is to continue tracing these funds, connecting on-chain transactions with real-world evidence. The potential of blockchain technology for transparent disaster relief remains significant, and we will persistently work to bridge the gap between digital transactions and their actual impact.</p>
<h2 id="sources">Sources</h2>
<p>This blog post is based on information from the following sources:</p>
<ol>
<li>Blockchain.com Explorer - Used to verify that the Bitcoin wallet address bc1qmn6ddugyj853vgmcvljs5te6rl9teuhz6t5cun had 421 transactions, received a total of 0.55640009 BTC ($47,380.32 USD), sent a total of 0.55640009 BTC ($47,380.32 USD), and currently has a balance of 0.00000000 BTC ($0.00 USD).</li>
<li>BTCscan.org - Used to confirm the wallet had 421 transactions on the Bitcoin blockchain, with the last balance change on 2022-11-26, received a total of 0.55640009 BTC, sent a total of 0.55640009 BTC, and has a current balance of 0 BTC.</li>
<li>Cointelegraph - January 17, 2022 article "Tonga accepts Bitcoin donations amid tsunami onslaught" which reported on Lord Fusitu'a establishing the Bitcoin wallet for donations.</li>
<li>Independent - January 18, 2022 article "Tonga receives hundreds of bitcoin donations after volcano devastation" which reported that more than $40,000 already raised by Tongan politician and crypto advocate Lord Fusituâ€™a.</li>
</ol>
<p>\</p>]]></content:encoded>
            <media:thumbnail url="https://hackernoon.com/https://cdn.hackernoon.com/images/2jqChkrv03exBUgkLrDzIbfM99q2-c002uua.jpeg"/>
        </item>
        <item>
            <title><![CDATA[Keep Your Happy Path Flowing, Not Nesting]]></title>
            <description><![CDATA[Arrange your code so the main logic flows along the left margin, handling edge cases early with guard clauses.]]></description>
            <link>https://hackernoon.com/keep-your-happy-path-flowing-not-nesting?source=rss</link>
            <guid isPermaLink="true">https://hackernoon.com/keep-your-happy-path-flowing-not-nesting?source=rss</guid>
            <category><![CDATA[programming]]></category>
            <category><![CDATA[refactoring]]></category>
            <category><![CDATA[code-smells]]></category>
            <category><![CDATA[software-development]]></category>
            <category><![CDATA[technology]]></category>
            <category><![CDATA[clean-code]]></category>
            <category><![CDATA[common-code-smells]]></category>
            <category><![CDATA[maximiliano-contieri]]></category>
            <dc:creator><![CDATA[Maximiliano Contieri]]></dc:creator>
            <pubDate>Sun, 13 Apr 2025 08:30:39 GMT</pubDate>
            <image/>
            <content:encoded><![CDATA[<p><em>Keep your happy path flowing, not nesting</em></p>
<blockquote>
  <p>TL;DR: Arrange your code so the main logic flows along the left margin, handling edge cases early with guard clauses.</p>
</blockquote>
<h1 id="problems">Problems ðŸ˜”</h1>
<ul>
<li>Cognitive overhead</li>
<li>Readability</li>
<li>Excessive <a href="https://hackernoon.com/how-to-find-the-stinky-parts-of-your-code-part-xxxiii">indentation</a></li>
<li>Maintainability</li>
<li>Control flow confusion</li>
<li><a href="https://hackernoon.com/how-to-find-the-stinky-parts-of-your-code-part-xxiv">Stairs Code</a></li>
</ul>
<h1 id="solutions">Solutions ðŸ˜ƒ</h1>
<ol>
<li>Use early returns</li>
<li>Apply guard clauses</li>
<li>Handle errors first</li>
<li>Keep the main flow to the left</li>
<li>Minimize nesting depth</li>
</ol>
<h1 id="context">Context ðŸ’¬</h1>
<p>When you write code with deeply nested conditional structures, you create "<a href="https://hackernoon.com/how-to-find-the-stinky-parts-of-your-code-part-xxi">arrow code</a>" or "pyramid of doom."</p>
<p>\
This makes your program's primary flow hard to follow as it zigzags deeper into indentation levels.</p>
<p>\
Your main logic (the "happy path") gets buried under layers of <a href="https://hackernoon.com/how-to-find-the-stinky-parts-of-your-code-part-xxxvii">conditions</a>, making the code harder to read, understand, and maintain.</p>
<p>\
This becomes even more problematic when dealing with internationalization and localization.</p>
<p>\
Nested conditionals often create fragmented contexts for strings, making accurate translations difficult because translators lose the surrounding context needed for proper translation.</p>
<h1 id="samplecode">Sample Code ðŸ“–</h1>
<h2 id="wrong">Wrong âŒ</h2>
<pre><code class="javascript language-javascript">function processUserOrder(user, items) {
  if (user) {
    if (user.isActive()) {
      if (items.length &gt; 0) {
        if (user.hasEnoughCredit()) {
          // The actual business logic is buried 4 levels deep
          let order = createOrder(user, items);
          notifyUser(user,
            `Your order has been processed`);
          return order;
        } else {
          throw new Error("Insufficient credit");
        }
      } else {
        throw new Error("No items in cart");
      }
    } else {
      throw new Error("Your account is inactive");
    }
  } else {
    throw new Error("No user provided");
  }
}
</code></pre>
<h2 id="right">Right ðŸ‘‰</h2>
<pre><code class="javascript language-javascript">function processUserOrder(user, items) {
  if (!user) throw new Error("No user provided");
  if (!user.isActive()) throw new Error("Your account is inactive");
  if (items.length === 0) throw new Error("No items in cart");
  if (!user.hasEnoughCredit()) throw new Error("Insufficient credit");

  const order = createOrder(user, items);
  notifyUser(user,
    `Your order has been processed`);
  return order;
}

// This is even more readable

function assertValidOrder(user, items) {
  if (!user) throw new Error("No user provided");
  if (!user.isActive()) throw new Error("Your account is inactive");
  if (items.length === 0) throw new Error("No items in cart");
  if (!user.hasEnoughCredit()) throw new Error("Insufficient credit");
}

function processUserOrder(user, items) {
  assertValidOrder(user, items);
  const order = createOrder(user, items);
  notifyUser(user,
    `Your order has been processed`);
  return order;
}
</code></pre>
<h1 id="detection">Detection ðŸ”</h1>
<ul>
<li>Semi-Automatic</li>
</ul>
<p>\
You can detect this smell by looking for multiple indentation levels (more than 2 or 3).</p>
<p>\
You can also analyse ASTs with advanced linters.</p>
<h1 id="tags">Tags ðŸ·ï¸</h1>
<ul>
<li>IFs</li>
</ul>
<h1 id="level">Level ðŸ”‹</h1>
<ul>
<li>Beginner</li>
</ul>
<h1 id="whythebijectionisimportant">Why the Bijection Is Important ðŸ—ºï¸</h1>
<p>When you write code with deep nesting, you break the clean <a href="https://hackernoon.com/the-one-and-only-software-design-principle-1x983ylp">Bijection</a> between the logical flow of your business rules and their representation in code.</p>
<p>\
The real-world business process likely follows a series of validations followed by a main action, but deeply nested code obscures this natural sequence.</p>
<p>\
This one-to-one correspondence breaks down because the primary operation (what the function is supposed to do) gets buried deep in indentation layers.</p>
<p>\
The logical sequence of validations isn't separated from the main action.</p>
<p>\
By keeping your happy path to the left, you create a natural bijection between the actual process flow and the code structure, making it easier to reason about and modify in the future.</p>
<h1 id="aigeneration">AI Generation ðŸ¤–</h1>
<p>AI code generators often create nested conditional structures, especially when generating code from prompts that don't explicitly request early returns or guard clauses.</p>
<p>\
Many AI systems mimic common patterns they observe in training data, where deeply nested conditions are unfortunately prevalent.</p>
<h1 id="aidetection">AI Detection ðŸ¥ƒ</h1>
<p>Most AI code assistants can identify and fix this code smell with proper instructions.</p>
<p>\
If you ask an AI to refactor code to "use early returns" or "apply guard clauses" or "keep the happy path to the left," it can typically transform nested conditionals into flatter structures.</p>
<p>\
You can also prompt the AI to "reduce nesting in this function" or "refactor this code to avoid deep indentation," and set it as a meta-prompt following your style preferences.</p>
<h2 id="trythem">Try Them! ðŸ› </h2>
<p><em>Remember: AI Assistants make lots of mistakes</em></p>
<p>\</p>
<blockquote>
  <p>Suggested Prompt: Remove the deep nesting</p>
</blockquote>
<p>\</p>
<p>| Without Proper Instructions | With Specific Instructions |
|----|----|
| <a href="https://chat.openai.com/?q=Correct+and+explain+this+code%3A+%60%60%60javascript%0Afunction+processUserOrder%28user%2C+items%29+%7B%0A++if+%28user%29+%7B%0A++++if+%28user.isActive%28%29%29+%7B%0A++++++if+%28items.length+%3E+0%29+%7B%0A++++++++if+%28user.hasEnoughCredit%28%29%29+%7B%0A++++++++++%2F%2F+The+actual+business+logic+is+buried+4+levels+deep%0A++++++++++let+order+%3D+createOrder%28user%2C+items%29%3B%0A++++++++++notifyUser%28user%2C+%0A++++++++++++%60Your+order+has+been+processed%60%29%3B%0A++++++++++return+order%3B%0A++++++++%7D+else+%7B%0A++++++++++throw+new+Error%28%22Insufficient+credit%22%29%3B%0A++++++++%7D%0A++++++%7D+else+%7B%0A++++++++throw+new+Error%28%22No+items+in+cart%22%29%3B%0A++++++%7D%0A++++%7D+else+%7B%0A++++++throw+new+Error%28%22Your+account+is+inactive%22%29%3B%0A++++%7D%0A++%7D+else+%7B%0A++++throw+new+Error%28%22No+user+provided%22%29%3B%0A++%7D%0A%7D%0A%60%60%60">ChatGPT</a> | <a href="https://chat.openai.com/?q=Remove+the+deep+nesting%3A+%60%60%60javascript%0Afunction+processUserOrder%28user%2C+items%29+%7B%0A++if+%28user%29+%7B%0A++++if+%28user.isActive%28%29%29+%7B%0A++++++if+%28items.length+%3E+0%29+%7B%0A++++++++if+%28user.hasEnoughCredit%28%29%29+%7B%0A++++++++++%2F%2F+The+actual+business+logic+is+buried+4+levels+deep%0A++++++++++let+order+%3D+createOrder%28user%2C+items%29%3B%0A++++++++++notifyUser%28user%2C+%0A++++++++++++%60Your+order+has+been+processed%60%29%3B%0A++++++++++return+order%3B%0A++++++++%7D+else+%7B%0A++++++++++throw+new+Error%28%22Insufficient+credit%22%29%3B%0A++++++++%7D%0A++++++%7D+else+%7B%0A++++++++throw+new+Error%28%22No+items+in+cart%22%29%3B%0A++++++%7D%0A++++%7D+else+%7B%0A++++++throw+new+Error%28%22Your+account+is+inactive%22%29%3B%0A++++%7D%0A++%7D+else+%7B%0A++++throw+new+Error%28%22No+user+provided%22%29%3B%0A++%7D%0A%7D%0A%60%60%60">ChatGPT</a> |
| <a href="https://claude.ai/new?q=Correct+and+explain+this+code%3A+%60%60%60javascript%0Afunction+processUserOrder%28user%2C+items%29+%7B%0A++if+%28user%29+%7B%0A++++if+%28user.isActive%28%29%29+%7B%0A++++++if+%28items.length+%3E+0%29+%7B%0A++++++++if+%28user.hasEnoughCredit%28%29%29+%7B%0A++++++++++%2F%2F+The+actual+business+logic+is+buried+4+levels+deep%0A++++++++++let+order+%3D+createOrder%28user%2C+items%29%3B%0A++++++++++notifyUser%28user%2C+%0A++++++++++++%60Your+order+has+been+processed%60%29%3B%0A++++++++++return+order%3B%0A++++++++%7D+else+%7B%0A++++++++++throw+new+Error%28%22Insufficient+credit%22%29%3B%0A++++++++%7D%0A++++++%7D+else+%7B%0A++++++++throw+new+Error%28%22No+items+in+cart%22%29%3B%0A++++++%7D%0A++++%7D+else+%7B%0A++++++throw+new+Error%28%22Your+account+is+inactive%22%29%3B%0A++++%7D%0A++%7D+else+%7B%0A++++throw+new+Error%28%22No+user+provided%22%29%3B%0A++%7D%0A%7D%0A%60%60%60">Claude</a> | <a href="https://claude.ai/new?q=Remove+the+deep+nesting%3A+%60%60%60javascript%0Afunction+processUserOrder%28user%2C+items%29+%7B%0A++if+%28user%29+%7B%0A++++if+%28user.isActive%28%29%29+%7B%0A++++++if+%28items.length+%3E+0%29+%7B%0A++++++++if+%28user.hasEnoughCredit%28%29%29+%7B%0A++++++++++%2F%2F+The+actual+business+logic+is+buried+4+levels+deep%0A++++++++++let+order+%3D+createOrder%28user%2C+items%29%3B%0A++++++++++notifyUser%28user%2C+%0A++++++++++++%60Your+order+has+been+processed%60%29%3B%0A++++++++++return+order%3B%0A++++++++%7D+else+%7B%0A++++++++++throw+new+Error%28%22Insufficient+credit%22%29%3B%0A++++++++%7D%0A++++++%7D+else+%7B%0A++++++++throw+new+Error%28%22No+items+in+cart%22%29%3B%0A++++++%7D%0A++++%7D+else+%7B%0A++++++throw+new+Error%28%22Your+account+is+inactive%22%29%3B%0A++++%7D%0A++%7D+else+%7B%0A++++throw+new+Error%28%22No+user+provided%22%29%3B%0A++%7D%0A%7D%0A%60%60%60">Claude</a> |
| <a href="https://www.perplexity.ai/?q=Correct+and+explain+this+code%3A+%60%60%60javascript%0Afunction+processUserOrder%28user%2C+items%29+%7B%0A++if+%28user%29+%7B%0A++++if+%28user.isActive%28%29%29+%7B%0A++++++if+%28items.length+%3E+0%29+%7B%0A++++++++if+%28user.hasEnoughCredit%28%29%29+%7B%0A++++++++++%2F%2F+The+actual+business+logic+is+buried+4+levels+deep%0A++++++++++let+order+%3D+createOrder%28user%2C+items%29%3B%0A++++++++++notifyUser%28user%2C+%0A++++++++++++%60Your+order+has+been+processed%60%29%3B%0A++++++++++return+order%3B%0A++++++++%7D+else+%7B%0A++++++++++throw+new+Error%28%22Insufficient+credit%22%29%3B%0A++++++++%7D%0A++++++%7D+else+%7B%0A++++++++throw+new+Error%28%22No+items+in+cart%22%29%3B%0A++++++%7D%0A++++%7D+else+%7B%0A++++++throw+new+Error%28%22Your+account+is+inactive%22%29%3B%0A++++%7D%0A++%7D+else+%7B%0A++++throw+new+Error%28%22No+user+provided%22%29%3B%0A++%7D%0A%7D%0A%60%60%60">Perplexity</a> | <a href="https://www.perplexity.ai/?q=Remove+the+deep+nesting%3A+%60%60%60javascript%0Afunction+processUserOrder%28user%2C+items%29+%7B%0A++if+%28user%29+%7B%0A++++if+%28user.isActive%28%29%29+%7B%0A++++++if+%28items.length+%3E+0%29+%7B%0A++++++++if+%28user.hasEnoughCredit%28%29%29+%7B%0A++++++++++%2F%2F+The+actual+business+logic+is+buried+4+levels+deep%0A++++++++++let+order+%3D+createOrder%28user%2C+items%29%3B%0A++++++++++notifyUser%28user%2C+%0A++++++++++++%60Your+order+has+been+processed%60%29%3B%0A++++++++++return+order%3B%0A++++++++%7D+else+%7B%0A++++++++++throw+new+Error%28%22Insufficient+credit%22%29%3B%0A++++++++%7D%0A++++++%7D+else+%7B%0A++++++++throw+new+Error%28%22No+items+in+cart%22%29%3B%0A++++++%7D%0A++++%7D+else+%7B%0A++++++throw+new+Error%28%22Your+account+is+inactive%22%29%3B%0A++++%7D%0A++%7D+else+%7B%0A++++throw+new+Error%28%22No+user+provided%22%29%3B%0A++%7D%0A%7D%0A%60%60%60">Perplexity</a> |
| <a href="https://www.bing.com/chat?showconv=1&sendquery=1&q=Correct+and+explain+this+code%3A+%60%60%60javascript%0Afunction+processUserOrder%28user%2C+items%29+%7B%0A++if+%28user%29+%7B%0A++++if+%28user.isActive%28%29%29+%7B%0A++++++if+%28items.length+%3E+0%29+%7B%0A++++++++if+%28user.hasEnoughCredit%28%29%29+%7B%0A++++++++++%2F%2F+The+actual+business+logic+is+buried+4+levels+deep%0A++++++++++let+order+%3D+createOrder%28user%2C+items%29%3B%0A++++++++++notifyUser%28user%2C+%0A++++++++++++%60Your+order+has+been+processed%60%29%3B%0A++++++++++return+order%3B%0A++++++++%7D+else+%7B%0A++++++++++throw+new+Error%28%22Insufficient+credit%22%29%3B%0A++++++++%7D%0A++++++%7D+else+%7B%0A++++++++throw+new+Error%28%22No+items+in+cart%22%29%3B%0A++++++%7D%0A++++%7D+else+%7B%0A++++++throw+new+Error%28%22Your+account+is+inactive%22%29%3B%0A++++%7D%0A++%7D+else+%7B%0A++++throw+new+Error%28%22No+user+provided%22%29%3B%0A++%7D%0A%7D%0A%60%60%60">Copilot</a> | <a href="https://www.bing.com/chat?showconv=1&sendquery=1&q=Remove+the+deep+nesting%3A+%60%60%60javascript%0Afunction+processUserOrder%28user%2C+items%29+%7B%0A++if+%28user%29+%7B%0A++++if+%28user.isActive%28%29%29+%7B%0A++++++if+%28items.length+%3E+0%29+%7B%0A++++++++if+%28user.hasEnoughCredit%28%29%29+%7B%0A++++++++++%2F%2F+The+actual+business+logic+is+buried+4+levels+deep%0A++++++++++let+order+%3D+createOrder%28user%2C+items%29%3B%0A++++++++++notifyUser%28user%2C+%0A++++++++++++%60Your+order+has+been+processed%60%29%3B%0A++++++++++return+order%3B%0A++++++++%7D+else+%7B%0A++++++++++throw+new+Error%28%22Insufficient+credit%22%29%3B%0A++++++++%7D%0A++++++%7D+else+%7B%0A++++++++throw+new+Error%28%22No+items+in+cart%22%29%3B%0A++++++%7D%0A++++%7D+else+%7B%0A++++++throw+new+Error%28%22Your+account+is+inactive%22%29%3B%0A++++%7D%0A++%7D+else+%7B%0A++++throw+new+Error%28%22No+user+provided%22%29%3B%0A++%7D%0A%7D%0A%60%60%60">Copilot</a> |
| <a href="https://gemini.google.com/">Gemini</a> | <a href="https://gemini.google.com/">Gemini</a> |
| <a href="https://chat.deepseek.com/">DeepSeek</a> | <a href="https://chat.deepseek.com/">DeepSeek</a> |
| <a href="https://www.meta.ai/chat">Meta AI</a> | <a href="https://www.meta.ai/">Meta AI</a> |
| <a href="https://chat.qwen.ai/">Qwen</a> | <a href="https://chat.qwen.ai/">Qwen</a> |</p>
<h1 id="conclusion">Conclusion ðŸ</h1>
<p>Keep your happy path to the left by using early returns and guard clauses, you will create more readable, maintainable code.</p>
<p>\
You communicate business logic more clearly, reduce cognitive load for other developers (including your future self), and create more resilient code to change.</p>
<p>\
Remember to handle the special cases early, and let your main logic flow naturally along the left margin. Your colleagues (and future you) will thank you.</p>
<h1 id="relations">Relations ðŸ‘©â€â¤ï¸â€ðŸ’‹â€ðŸ‘¨</h1>
<p><a href="https://hackernoon.com/how-to-find-the-stinky-parts-of-your-code-part-xxi">Code Smell 102 - Arrow Code</a></p>
<p><a href="https://hackernoon.com/how-to-find-the-stinky-parts-of-your-code-part-xxiv?embedable=true">https://hackernoon.com/how-to-find-the-stinky-parts-of-your-code-part-xxiv?embedable=true</a></p>
<p><a href="https://maximilianocontieri.com/code-smell-294-implicit-return?embedable=true">https://maximilianocontieri.com/code-smell-294-implicit-return?embedable=true</a></p>
<p><a href="https://hackernoon.com/how-to-find-the-stinky-parts-of-your-code-part-i-xqz3evd?embedable=true">https://hackernoon.com/how-to-find-the-stinky-parts-of-your-code-part-i-xqz3evd?embedable=true</a></p>
<p><a href="https://hackernoon.com/how-to-find-the-stinky-parts-of-your-code-part-xxxvii?embedable=true">https://hackernoon.com/how-to-find-the-stinky-parts-of-your-code-part-xxxvii?embedable=true</a></p>
<p><a href="https://hackernoon.com/how-to-find-the-stinky-parts-of-your-code-part-xxxiii?embedable=true">https://hackernoon.com/how-to-find-the-stinky-parts-of-your-code-part-xxxiii?embedable=true</a></p>
<p><a href="https://hackernoon.com/how-to-find-the-stinky-parts-of-your-code-part-xxi?embedable=true">https://hackernoon.com/how-to-find-the-stinky-parts-of-your-code-part-xxi?embedable=true</a></p>
<p><a href="https://hackernoon.com/how-to-find-the-stinky-parts-of-your-code-part-xxxvii">https://hackernoon.com/how-to-find-the-stinky-parts-of-your-code-part-xxxvii</a></p>
<h1 id="disclaimer">Disclaimer ðŸ“˜</h1>
<p>Code Smells are my <a href="https://hackernoon.com/i-wrote-more-than-90-articles-in-2021-here-is-what-i-learned-in-a-nutshell">opinion</a>.</p>
<h1 id="credits">Credits ðŸ™</h1>
<p>Photo by <a href="https://unsplash.com/@alexanderhipp">Alexander Hipp</a> on <a href="https://unsplash.com/photos/time-lapse-photo-of-waterfalls-5tIuYKRRHj8">Unsplash</a></p>
<hr />
<blockquote>
  <p>A function should follow the "arrow shape" of reading naturally from top to bottom, not wander into deeper nesting like a poorly designed maze.</p>
</blockquote>
<p>\
Venkat Subramaniam</p>
<p>\
<a href="https://hackernoon.com/400-thought-provoking-software-engineering-quotes">Software Engineering Great Quotes</a></p>
<hr />
<p>This article is part of the CodeSmell Series.</p>
<p><a href="https://hackernoon.com/how-to-find-the-stinky-parts-of-your-code-part-i-xqz3evd?embedable=true">https://hackernoon.com/how-to-find-the-stinky-parts-of-your-code-part-i-xqz3evd?embedable=true</a></p>
<p>\</p>]]></content:encoded>
            <media:thumbnail url="https://hackernoon.com/https://cdn.hackernoon.com/images/RIiBoPtpMiRsMKX3dnzl5gb1Urj1-cb02pgy.jpeg"/>
        </item>
        <item>
            <title><![CDATA[The TechBeat: Google A2A - a First Look at Another Agent-agent Protocol (4/13/2025)]]></title>
            <link>https://hackernoon.com/4-13-2025-techbeat?source=rss</link>
            <guid isPermaLink="true">https://hackernoon.com/4-13-2025-techbeat?source=rss</guid>
            <category><![CDATA[tech-beat]]></category>
            <category><![CDATA[hackernoon-newsletter]]></category>
            <category><![CDATA[latest-tect-stories]]></category>
            <category><![CDATA[technology]]></category>
            <category><![CDATA[creativity]]></category>
            <dc:creator><![CDATA[Techbeat]]></dc:creator>
            <pubDate>Sun, 13 Apr 2025 06:10:50 GMT</pubDate>
            <image/>
            <content:encoded><![CDATA[<p>How are you, hacker?
 ðŸª<strong>Want to know what's trending right now?:</strong>
 <a href="https://hackernoon.com/homepage-has-a-new-baby">The Techbeat by HackerNoon </a> has got you covered with fresh content from our trending stories of the day! Set email preference <a href="https://app.hackernoon.com/profile/email-settings">here</a>.
 ## <strong><a href="https://hackernoon.com/claude-desktop-mcp-quietly-transformed-my-product-thinking">Claude Desktop + MCP Quietly Transformed my Product Thinking</a></strong> <img src="https://cdn.hackernoon.com/images/ETUCaaeQF4UMzvIWBlN1T9PgdqN2-mb036i1.png" alt="" />
 By <a href="https://hackernoon.com/u/asitsahoo">@asitsahoo</a> [ 3 Min read ]
 Discover how Claude Desktop with MCP tools eliminated digital fragmentation, enabling deeper product thinking and transforming weeks of work into hours. <a href="https://hackernoon.com/claude-desktop-mcp-quietly-transformed-my-product-thinking">Read More.</a></p>
<h2 id="isweb3advertisingfinallysolvingitstargetingproblemaddressablesevioexpandweb3adsreachhttpshackernooncomisweb3advertisingfinallysolvingitstargetingproblemaddressableandsevioexpandweb3adsreachhttpscdnhackernooncomimages7remniehnfobfzztumqeroziggh3ez03l9hpng"><strong><a href="https://hackernoon.com/is-web3-advertising-finally-solving-its-targeting-problem-addressable-and-sevio-expand-web3-ads-reach">Is Web3 Advertising Finally Solving Its Targeting Problem? Addressable & Sevio Expand Web3 Ads Reach</a></strong> <img src="https://cdn.hackernoon.com/images/7rEmNIeHNFOBfZZtUMQerOZIGGH3-ez03l9h.png" alt="" /></h2>
<p>By <a href="https://hackernoon.com/u/ishanpandey">@ishanpandey</a> [ 2 Min read ]
 A new partnership between Addressable and Sevio will enable programmatic display ads on major crypto platforms, making web3 target more efficient.  <a href="https://hackernoon.com/is-web3-advertising-finally-solving-its-targeting-problem-addressable-and-sevio-expand-web3-ads-reach">Read More.</a></p>
<h2 id="googlea2aafirstlookatanotheragentagentprotocolhttpshackernooncomgooglea2aafirstlookatanotheragentagentprotocolhttpscdnhackernooncomimagesbi3bzybanbvxezqmlv7jrnw6d9o23y03hhypng"><strong><a href="https://hackernoon.com/google-a2a-a-first-look-at-another-agent-agent-protocol">Google A2A - a First Look at Another Agent-agent Protocol</a></strong> <img src="https://cdn.hackernoon.com/images/bI3BzyBanbVxEZqmLV7jRnw6d9o2-3y03hhy.png" alt="" /></h2>
<p>By <a href="https://hackernoon.com/u/zbruceli">@zbruceli</a> [ 5 Min read ]
 Google A2A - a first look at another agent-agent protocol and compared to Anthropicâ€™s MCP. <a href="https://hackernoon.com/google-a2a-a-first-look-at-another-agent-agent-protocol">Read More.</a></p>
<h2 id="escapeprompthellwiththese8musthaveopensourcetoolshttpshackernooncomescapeprompthellwiththese8musthaveopensourcetoolshttpscdnhackernooncomimages9uzeui0lyjelqdroxppgqmmf3tx1i703rdhpng"><strong><a href="https://hackernoon.com/escape-prompt-hell-with-these-8-must-have-open-source-tools">Escape Prompt Hell With These 8 Must-have Open-source Tools</a></strong> <img src="https://cdn.hackernoon.com/images/9UZEuI0lyjelqdRoxPpGQmMF3Tx1-i703rdh.png" alt="" /></h2>
<p>By <a href="https://hackernoon.com/u/albertlieyeongdok">@albertlieyeongdok</a> [ 6 Min read ]
 Discover 8 powerful tools transforming prompt engineering from trial-and-error into scalable systemsâ€”featuring visual workflows, auto-tuned prompts, and memory- <a href="https://hackernoon.com/escape-prompt-hell-with-these-8-must-have-open-source-tools">Read More.</a></p>
<h2 id="iblew400oncursorhereswhatilearnedsoyoudonthavetohttpshackernooncomibleweuro400oncursorhereswhatilearnedsoyoudonthavetohttpscdnhackernooncomimages2jqchkrv03exbugklrdzibfm99q2k402u8wwebp"><strong><a href="https://hackernoon.com/i-blew-euro400-on-cursor-heres-what-i-learned-so-you-dont-have-to">I Blew â‚¬400 on Cursor â€” Here's What I Learned So You Don't Have To</a></strong> <img src="https://cdn.hackernoon.com/images/2jqChkrv03exBUgkLrDzIbfM99q2-k402u8w.webp" alt="" /></h2>
<p>By <a href="https://hackernoon.com/u/techbyadam">@techbyadam</a> [ 3 Min read ]
 Building software with Cursor is super fast, and you should definitely use it. However, there are some downsides. <a href="https://hackernoon.com/i-blew-euro400-on-cursor-heres-what-i-learned-so-you-dont-have-to">Read More.</a></p>
<h2 id="googlegeminididnotdisappointontheseblockchainxaiusecaseshttpshackernooncomgooglegeminididnotdisappointontheseblockchainxaiusecaseshttpscdnhackernooncomimages9sbj6ozmvxoehdxtjjuu75plynp1vx03ccojpeg"><strong><a href="https://hackernoon.com/google-gemini-did-not-disappoint-on-these-blockchain-x-ai-use-cases">Google Gemini Did Not Disappoint on These Blockchain x AI Use Cases </a></strong> <img src="https://cdn.hackernoon.com/images/9SBj6OzMvXOEhDxTjjuu75pLYnp1-vx03cco.jpeg" alt="" /></h2>
<p>By <a href="https://hackernoon.com/u/thomascherickal">@thomascherickal</a> [ 10 Min read ]
 20 Mind-Blowing Science-Fiction AI and Blockchain Use Cases that will amaze, thrill, and shock you with their scope and immense possibilities.  <a href="https://hackernoon.com/google-gemini-did-not-disappoint-on-these-blockchain-x-ai-use-cases">Read More.</a></p>
<h2 id="webscrapingin2025stayingontrackwithnewruleshttpshackernooncomwebscrapingin2025stayingontrackwithnewruleshttpscdnhackernooncomimagesinxbrjris6m1kdhuwcynhiiurxm1ni03701png"><strong><a href="https://hackernoon.com/web-scraping-in-2025-staying-on-track-with-new-rules">Web Scraping in 2025: Staying on Track with New Rules</a></strong> <img src="https://cdn.hackernoon.com/images/InxBRjRIs6M1kdhuWcyNHiiUrxm1-ni03701.png" alt="" /></h2>
<p>By <a href="https://hackernoon.com/u/dataimpulse">@dataimpulse</a> [ 5 Min read ]
 Web scraping in 2025 faces AI defenses, legal hurdles, and new rules. Learn smart, compliant strategies to keep your data flows running smooth. <a href="https://hackernoon.com/web-scraping-in-2025-staying-on-track-with-new-rules">Read More.</a></p>
<h2 id="whyeveryfrontendteamneedsstorybookhttpshackernooncomwhyeveryfrontendteamneedsstorybookhttpscdnhackernooncomimagesxgf6phdemtu18tjwq7cvyjvtlbx1gd038qzpng"><strong><a href="https://hackernoon.com/why-every-front-end-team-needs-storybook">Why Every Front-End Team Needs Storybook</a></strong> <img src="https://cdn.hackernoon.com/images/XGF6PhDeMTU18tjwQ7CVyjVTLBx1-gd038qz.png" alt="" /></h2>
<p>By <a href="https://hackernoon.com/u/igorluchenkov">@igorluchenkov</a> [ 6 Min read ]
 Storybook enables isolated component building, API mocking, easier testing, streamlined design reviews, and visual regression detection. <a href="https://hackernoon.com/why-every-front-end-team-needs-storybook">Read More.</a></p>
<h2 id="gemini25progooglesnewaikingtakesthecrownhttpshackernooncomgemini25progooglesnewaikingtakesthecrownhttpscdnhackernooncomimages0iu1phrmnqot3gqhiw0op3lk20h1l60267ywebp"><strong><a href="https://hackernoon.com/gemini-25-pro-googles-new-ai-king-takes-the-crown">Gemini 2.5 Pro: Google's New AI King Takes the Crown?</a></strong> <img src="https://cdn.hackernoon.com/images/0iu1pHRMnqOT3GqhiW0OP3lK20h1-l60267y.webp" alt="" /></h2>
<p>By <a href="https://hackernoon.com/u/proflead">@proflead</a> [ 5 Min read ]
 Googleâ€™s Gemini 2.5 Pro is designed for complex reasoning tasks and excels in understanding and generating content across various formats.  <a href="https://hackernoon.com/gemini-25-pro-googles-new-ai-king-takes-the-crown">Read More.</a></p>
<h2 id="howtobecomeatop1programmerthepathyouhavetotakehttpshackernooncomhowtobecomeatop1percentprogrammerthepathyouhavetotakehttpscdnhackernooncomimagesiyxqfnsadehimipphrg7yoamak120d0328ppng"><strong><a href="https://hackernoon.com/how-to-become-a-top-1percent-programmer-the-path-you-have-to-take">How to Become a Top 1% Programmer: The Path You Have to Take</a></strong> <img src="https://cdn.hackernoon.com/images/IYXqfnSadehiMIPPHRg7yoAmak12-0d0328p.png" alt="" /></h2>
<p>By <a href="https://hackernoon.com/u/muhammdusman">@muhammdusman</a> [ 8 Min read ]
 So you want to become better than 99% of programmers. But you are doing the exact same things that 99% of programmers are already doing. <a href="https://hackernoon.com/how-to-become-a-top-1percent-programmer-the-path-you-have-to-take">Read More.</a></p>
<h2 id="legallycompliantcryptocurrencyexchangeacasestudyofnovachangehttpshackernooncomlegallycompliantcryptocurrencyexchangeacasestudyofnovachangehttpscdnhackernooncomimageshq098u52dzpm2y4uitqcqxtlrak2l103551png"><strong><a href="https://hackernoon.com/legally-compliant-cryptocurrency-exchange-a-case-study-of-novachange">Legally Compliant Cryptocurrency Exchange: A Case Study of NovaChange</a></strong> <img src="https://cdn.hackernoon.com/images/hQ098u52DzPm2Y4UITQcQXtLRAk2-l103551.png" alt="" /></h2>
<p>By <a href="https://hackernoon.com/u/novachange">@novachange</a> [ 3 Min read ]
 As cryptocurrency adoption grows worldwide, the demand for secure and reliable exchange platforms continues to rise. <a href="https://hackernoon.com/legally-compliant-cryptocurrency-exchange-a-case-study-of-novachange">Read More.</a></p>
<h2 id="whattheonboardingprocesslookslikeatsocialdiscoverygrouphttpshackernooncomwhattheonboardingprocesslookslikeatsocialdiscoverygrouphttpscdnhackernooncomimages5wpkgv75aonqktjlafw2yqmk9yd2b5036bwjpeg"><strong><a href="https://hackernoon.com/what-the-onboarding-process-looks-like-at-social-discovery-group">What the Onboarding Process Looks Like at Social Discovery Group </a></strong> <img src="https://cdn.hackernoon.com/images/5wpKgV75aONqkTJlafw2yQmK9yd2-b5036bw.jpeg" alt="" /></h2>
<p>By <a href="https://hackernoon.com/u/socialdiscoverygroup">@socialdiscoverygroup</a> [ 3 Min read ]
 Discover how Social Discovery Groupâ€™s structured, data-driven onboarding process helps new hires seamlessly integrate into their teams and roles. <a href="https://hackernoon.com/what-the-onboarding-process-looks-like-at-social-discovery-group">Read More.</a></p>
<h2 id="theaitruthtestnewstudyteststheaccuracyof13majoraimodelshttpshackernooncomtheaitruthtestnewstudyteststheaccuracyof13majoraimodelshttpscdnhackernooncomimages5wpkgv75aonqktjlafw2yqmk9yd2t3037bipng"><strong><a href="https://hackernoon.com/the-ai-truth-test-new-study-tests-the-accuracy-of-13-major-ai-models">The AI Truth Test: New Study Tests the Accuracy of 13 Major AI Models</a></strong> <img src="https://cdn.hackernoon.com/images/5wpKgV75aONqkTJlafw2yQmK9yd2-t3037bi.png" alt="" /></h2>
<p>By <a href="https://hackernoon.com/u/languagemodels">@languagemodels</a> [ 5 Min read ]
 New DeepMind study introduces SAFE and LongFact to fact-check AI, showing LLMs can outperform humans at evaluating long-form factual responses. <a href="https://hackernoon.com/the-ai-truth-test-new-study-tests-the-accuracy-of-13-major-ai-models">Read More.</a></p>
<h2 id="shouldyoulearnrustandzigyesyesyoushouldhttpshackernooncomshouldyoulearnrustandzigyesyesyoushouldhttpscdnhackernooncomimagesn4hmthk66hmro7yweucu17vw5ze3tk023rypng"><strong><a href="https://hackernoon.com/should-you-learn-rust-and-zig-yes-yes-you-should">Should You Learn Rust and Zig? Yes, Yes You Should</a></strong> <img src="https://cdn.hackernoon.com/images/N4HmTHk66HMRo7yWEucu17VW5zE3-tk023ry.png" alt="" /></h2>
<p>By <a href="https://hackernoon.com/u/ace2489">@ace2489</a> [ 9 Min read ]
 The value of programming languages that don't hide the details. <a href="https://hackernoon.com/should-you-learn-rust-and-zig-yes-yes-you-should">Read More.</a></p>
<h2 id="howtheinternetwillpayyouhttpshackernooncomhowtheinternetwillpayyouhttpscdnhackernooncomimagesx21vpriqhyayrjebiymkn7uuoth2zo03k95png"><strong><a href="https://hackernoon.com/how-the-internet-will-pay-you">How The Internet Will Pay You</a></strong> <img src="https://cdn.hackernoon.com/images/x21VprIQHYaYrJEbiyMkN7uuOTH2-zo03k95.png" alt="" /></h2>
<p>By <a href="https://hackernoon.com/u/praisejames">@praisejames</a> [ 10 Min read ]
 I worked on a project to make internet access free. Hereâ€™s what I learned about work, creativity, and getting paid to be yourself. <a href="https://hackernoon.com/how-the-internet-will-pay-you">Read More.</a></p>
<h2 id="cryptowhalesarelayingthegroundworkforthenextbullrunhttpshackernooncomcryptowhalesarelayingthegroundworkforthenextbullrunhttpscdnhackernooncomimagesizh5vrbxyltjug6otbu11lwjema3wc638l6png"><strong><a href="https://hackernoon.com/crypto-whales-are-laying-the-groundwork-for-the-next-bull-run">Crypto Whales are Laying the Groundwork for the Next Bull Run</a></strong> <img src="https://cdn.hackernoon.com/images/IZH5VrBxylTJuG6oTbU11LwJemA3-wc638l6.png" alt="" /></h2>
<p>By <a href="https://hackernoon.com/u/sergey-baloyan">@sergey-baloyan</a> [ 6 Min read ]
 The psychology driving the market isnâ€™t random; itâ€™s a game of human nature, and the winners know how to play it.  <a href="https://hackernoon.com/crypto-whales-are-laying-the-groundwork-for-the-next-bull-run">Read More.</a></p>
<h2 id="springintonewfeaturessmarternotificationsmorewritingstatspixeliconlibrarymorehttpshackernooncomspringintonewfeaturessmarternotificationsmorewritingstatspixeliconlibraryandmorehttpscdnhackernooncomimageszhlunuihpbhk4ijuh4amrounswe2ue035i7png"><strong><a href="https://hackernoon.com/spring-into-new-features-smarter-notifications-more-writing-stats-pixel-icon-library-and-more">Spring Into New Features: Smarter Notifications, More Writing Stats, Pixel Icon Library & More</a></strong> <img src="https://cdn.hackernoon.com/images/zhLunuihpBhk4IjuH4amrounSwE2-ue035i7.png" alt="" /></h2>
<p>By <a href="https://hackernoon.com/u/product">@product</a> [ 6 Min read ]
 HackerNoonâ€™s monthly product update is here! ðŸš€ Explore your new reading recommendations, new mobile app inbox, words written stats, and more! <a href="https://hackernoon.com/spring-into-new-features-smarter-notifications-more-writing-stats-pixel-icon-library-and-more">Read More.</a></p>
<h2 id="thedecentralizedinternetcouldturnusintoatype1civilizationthealternativemassslaveryhttpshackernooncomthedecentralizedinternetcouldturnusintoatype1civilizationthealternativemassslaveryhttpscdnhackernooncomimages1nof3c3xxvno2p1oyw96h4kbel33k2030ampng"><strong><a href="https://hackernoon.com/the-decentralized-internet-could-turn-us-into-a-type-1-civilization-the-alternative-mass-slavery">The Decentralized Internet Could Turn Us Into a Type-1 Civilization. The Alternative? Mass Slavery</a></strong> <img src="https://cdn.hackernoon.com/images/1nOf3C3xXvNO2p1OYW96H4Kbel33-k2030am.png" alt="" /></h2>
<p>By <a href="https://hackernoon.com/u/jroseland">@jroseland</a> [ 12 Min read ]
 My grandfather helped put a man on the Moon. Iâ€™m fighting for something just as radical: a free and decentralized internet. <a href="https://hackernoon.com/the-decentralized-internet-could-turn-us-into-a-type-1-civilization-the-alternative-mass-slavery">Read More.</a></p>
<h2 id="soibuiltasentientaitwitteragentwhatstheworstthatcouldhappenhttpshackernooncomsoibuiltasentientaitwitteragentwhatstheworstthatcouldhappenhttpscdnhackernooncomimagesct2e5h59ppdma2yqwepvqmr4wye2a61373dwebp"><strong><a href="https://hackernoon.com/so-i-built-a-sentient-ai-twitter-agent-whats-the-worst-that-could-happen">So I Built a Sentient AI Twitter Agentâ€¦ What's the Worst That Could Happen?</a></strong> <img src="https://cdn.hackernoon.com/images/Ct2e5H59Ppdma2YQwEpVQmR4wye2-a61373d.webp" alt="" /></h2>
<p>By <a href="https://hackernoon.com/u/johnnycm2nlccgp00003584jzy450t4">@johnnycm2nlccgp00003584jzy450t4</a> [ 6 Min read ]
 Look, I'm not saying I'm building Skynet here, but when my AI agent started generating philosophical tweets at 3 AM about the nature of consciousness, wellâ€¦.. <a href="https://hackernoon.com/so-i-built-a-sentient-ai-twitter-agent-whats-the-worst-that-could-happen">Read More.</a></p>
<h2 id="isexcellenceanaccidenthttpshackernooncomisexcellenceanaccidenthttpscdnhackernooncomimages2jqchkrv03exbugklrdzibfm99q27a02umnjpeg"><strong><a href="https://hackernoon.com/is-excellence-an-accident">Is Excellence An Accident?</a></strong> <img src="https://cdn.hackernoon.com/images/2jqChkrv03exBUgkLrDzIbfM99q2-7a02umn.jpeg" alt="" /></h2>
<p>By <a href="https://hackernoon.com/u/scottdclary">@scottdclary</a> [ 9 Min read ]
 Excellence isn't about running the race better, it's about changing the track entirely. <a href="https://hackernoon.com/is-excellence-an-accident">Read More.</a>
 ðŸ§‘â€ðŸ’» What happened in your world this week? It's been said that <a href="https://hackernoon.com/developers-the-why-and-how-to-writing-technical-articles-54e824789ef6">writing can help consolidate technical knowledge</a>, <a href="https://hackernoon.com/how-can-non-writers-become-effective-bloggers-1pq32wd">establish credibility</a>,<a href="https://hackernoon.com/how-can-non-writers-become-effective-bloggers-1pq32wd"> and contribute to emerging community standards</a>. Feeling stuck? We got you covered â¬‡ï¸â¬‡ï¸â¬‡ï¸
 <a href="https://app.hackernoon.com/mobile/lZx3fmlPdlPJpVBIdble">ANSWER THESE GREATEST INTERVIEW QUESTIONS OF ALL TIME</a>
 We hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.
 See you on Planet Internet! With love,
 The HackerNoon Team âœŒï¸
 <img src="https://cdn.hackernoon.com/images/ezgif.com-gif-maker%20(44).gif" alt="" /></p>]]></content:encoded>
            <media:thumbnail url="https://hackernoon.com/https://cdn.hackernoon.com/images/hackernoon_newsletter_215_on9gr78jw4hf6ce5hjzquo19.png"/>
        </item>
        <item>
            <title><![CDATA[How I Led a Multi-Million Dollar SaaS Transition Without Breaking the Bank]]></title>
            <description><![CDATA[Software as a Service (SaaS) adoption saw tremendous growth in the last 5 years as it enables businesses to user experience, reduce operational costs, and reduce the burden of technology lifecycle management. Leading a multi-million dollar SaaS transition is no small feat and requires meticulous planning, stakeholder alignment, and the ability to navigate unexpected challenges/issues. In this article, Iâ€™ll share my experience leading a successful SAAS transition at one of the top Pharmaceutical companies.]]></description>
            <link>https://hackernoon.com/how-i-led-a-multi-million-dollar-saas-transition-without-breaking-the-bank?source=rss</link>
            <guid isPermaLink="true">https://hackernoon.com/how-i-led-a-multi-million-dollar-saas-transition-without-breaking-the-bank?source=rss</guid>
            <category><![CDATA[saas]]></category>
            <category><![CDATA[saas-transition]]></category>
            <category><![CDATA[saas-strategy]]></category>
            <category><![CDATA[saas-development]]></category>
            <category><![CDATA[vendor-assessment-explained]]></category>
            <category><![CDATA[migration-strategy]]></category>
            <category><![CDATA[development-strategy]]></category>
            <category><![CDATA[testing-strategy]]></category>
            <dc:creator><![CDATA[Kalyan Kilaru]]></dc:creator>
            <pubDate>Sat, 12 Apr 2025 17:45:05 GMT</pubDate>
            <image/>
            <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Software as a Service (SaaS) adoption saw tremendous growth in the last 5 years as it enables businesses to user experience, reduce operational costs, and reduce the burden of technology lifecycle management. Leading a multi-million dollar SaaS transition is no small featâ€”it requires meticulous planning, stakeholder alignment, and the ability to navigate unexpected challenges/issues. In this article, Iâ€™ll share my experience leading a successful SaaS transition at one of the top Pharmaceutical companies where we were able to save ~$800K in yearly operations cost by transitioning to a SaaS solution.</p>
<h2 id="thestrategyaphasedapproach">**The Strategy: A Phased Approach</h2>
<p>\  <img src="https://cdn.hackernoon.com/images/pcJv3PLeoSa0O7HELFyKoyGGuF82-2025-04-12T17:45:02.645Z-u9navr36g6giyd123g4difi7" alt="" />Embarking on a SaaS journey for an enterprise-grade solution is a multi-year commitment that requires meticulous planning and precise execution. We categorized this journey into 4 key phases:</p>
<ul>
<li>Current state assessment</li>
<li>Vendor assessment</li>
<li>Building a business case</li>
<li>Implementation (SaaS transition)</li>
</ul>
<h3 id="currentstateassessment"><strong>Current State Assessment</strong></h3>
<p>Our current Revenue Management application was implemented in 2019 and has not been upgraded since. We analyzed our existing IT infrastructure and operations to identify gaps in user experience, operational inefficiencies, total cost of ownership (TCO) of the platform per year, and opportunities for automation. Through this exercise, we found that our on-prem solution was not only expensive to operate but we also reached the limit of our data centerâ€™s hardware capacity required to support future business growth. </p>
<p>\
Another critical data point uncovered was that on-prem software upgrades were an expensive and time-consuming effort; a typical on-prem upgrade would cost a few million and span across 18 months. This assessment lasted 3 months, and all the information gathered through this process became an input to the subsequent phases.</p>
<h3 id="vendorassessment"><strong>Vendor Assessment</strong></h3>
<p>Before we engaged the SaaS vendors in the market, we thoroughly documented all our requirements spanning - business, performance, scalability, security, integration, support, and budget. Based on this, we issued an RFP (Request for Proposal) to all the key SaaS vendors operating in this space. This phase lasted 6 months and comprised of the following activities:</p>
<p>\</p>
<ul>
<li>Demos from the vendors showcasing how they can meet our business requirements</li>
<li>Reviewing their case studies and soliciting feedback from their existing customers</li>
<li>Evaluating their technical architecture and security posture to ensure it meets our performance and security requirements</li>
<li>Evaluate scalability of the application and ease of future upgrades</li>
<li>Conduct due diligence on vendorsâ€™ financial stability and evaluate vendorsâ€™ pricing and contract terms</li>
<li>Assess the vendor's support and service capabilities</li>
</ul>
<p>\
Based on the above activities, we developed a scoring matrix with weighted scores across various categories like pricing, functionality, technical capabilities, security, compliance, etc. We selected the vendor with the highest score and started the vendor due diligence, price, and contract negotiating process. We leveraged findings from the due diligence process for negotiating better prices and contract terms.</p>
<h3 id="buildingabusinesscase">Building a Business Case</h3>
<p>In order to secure funding for this project, we had to build a strong business case outlining both the financial returns and strategic benefits. Following are some of the key elements that were factored into our business case:</p>
<ul>
<li>Current state vs Future state Total cost of ownership (TCO)</li>
<li>License costs</li>
<li>Infrastructure cost</li>
<li>Support cost (headcount)</li>
<li>Cost of the SaaS transition project</li>
<li>Implementation(vendor) cost</li>
<li>Internal infrastructure cost</li>
<li>Development cost for integrations</li>
<li>Support for testing activities - base business resources vs contingent labor</li>
<li>Demonstrate the business benefits and ROI</li>
<li>Improved user experience</li>
<li>Faster and low-cost future upgrades allow for quickly adopting new features in the application.</li>
<li>Lower TCO</li>
<li>We were able to showcase that the initial investment could be recouped in less than 6 months due to the adoption of new features in the application that help curtail revenue leakage.</li>
<li>Outline the project approach.</li>
<li>Showcase KPIs of the project</li>
<li>Project timeline</li>
<li>Change management plan</li>
</ul>
<p>After drafting a thorough business case, we had to gain the buy-in and approval from various stakeholders in the organization and ensure we addressed any key concerns/questions that may arise.</p>
<h3 id="implementation">Implementation</h3>
<p>After the business case was approved, we took time to develop a well-defined project plan by taking inputs from the vendor and key stakeholders, which included the following key tenants:</p>
<h4 id="migrationdevelopmentstrategy">Migration &amp; Development Strategy</h4>
<p>A strategic migration approach and well-structured development plan ensure minimal disruption throughout the project. This includes:</p>
<ul>
<li>Define the duration of data that needs to be migrated to SaaS.</li>
<li>Outline the archival strategy for data that would not be migrated to SaaS</li>
<li>Level of data transformation that needs to happen for SaaS compatibility</li>
<li>Align existing software functionalities with new SaaS application features</li>
<li>Define a development strategy for customizations when the SaaS OOB features cannot meet user requirements.</li>
<li>Map out the integration approach, i.e., if existing integrations can be reused or will have to be developed to meet SaaS requirements.</li>
<li>Lay out the security measures to be implemented as part of the project</li>
</ul>
<h4 id="testingstrategy">Testing Strategy</h4>
<p>As with any software project implementation, testing is crucial to ensure the application meets the user requirements and performs as per expectations. Some of the key areas we focused on are as follows:</p>
<ul>
<li>System integration testing: Verifies that independently functioning components of a system work together correctly when combined.</li>
<li>Performance testing: Assess system performance and verify optimal user experience.</li>
<li>User acceptance testing: End user validate system functionality and if it meets their requirements.</li>
<li>Security testing: Identify vulnerabilities and ensure compliance with security protocols.</li>
<li>Bug fixes: Resolve</li>
</ul>
<h4 id="trainingandchangemanagement">Training and Change Management</h4>
<p>Given the amount of change involved, it is pertinent to have a well-defined training and change management plan to ensure a smooth transition and successful end-user adoption of the SaaS application. Our robust strategy included:</p>
<ul>
<li>User Training: Conduct in-person and virtual training sessions, develop user guides, work instruction documents, and training videos</li>
<li>Change Communication: Keep stakeholders informed about changes, benefits, and timelines.</li>
<li>Support Resources: Establish help desks, FAQs</li>
</ul>
<h4 id="goliveandhypercare">Go Live and Hypercare</h4>
<p>A successful SaaS transition relies heavily on a well-defined cutover plan and post-implementation support model.</p>
<ul>
<li>Deployment: The migration of data and the deployment of code should be well-orchestrated and must follow the cutover plan that was practiced throughout the project.</li>
<li>Hypercare Support: Establish a hypercare team of functional and technical experts to ensure that users' questions/concerns are addressed in a timely fashion.</li>
<li>Monitoring System Performance: Track security, uptime, and software usage analytics.</li>
</ul>
<h2 id="challengesencountered">Challenges Encountered</h2>
<p>As with any large-scale IT transformations, we encountered hurdles throughout the project; however, through stakeholder and change management, we were able to overcome the hurdles successfully. Below, are a few scenarios we encountered:</p>
<ul>
<li>Data Migration issues: Transforming our on-prem data to meet the SaaS application requirements presented some unique challenges, but we were able to overcome these issues by collaborating closely with the SaaS vendor and other vendors that were part of the project. To ensure completeness and accuracy of the migrated data, we implemented a robust data migration strategy like pre and post-data checks, row counts, dollar and quantity checks, etc.</li>
<li>Vendor Management: Managing multiple vendors that were part of the project presented its own set of challenges around timelines and scope, but we addressed it by clearly articulating the scope for each vendor, conducting weekly meetings with the vendors, and establishing an escalation path.</li>
<li>Challenges during final migration: During the go-live cutover, we encountered a performance issue with data migration. Luckily, we encountered a similar issue during a dry run in the project, we were able to implement the corrective action we learned from past experience and overcome the issue. This emphasized the importance of practicing cutover throughout the project.</li>
</ul>
<h2 id="keytakeaways">Key Takeaways</h2>
<ol>
<li>Align IT Strategy with Business Goals â€“ A SaaS transition is not just an IT initiative; it must drive tangible business value.</li>
<li>Well-defined Implementation strategy â€“ Small, iterative steps allow for flexibility and risk mitigation.</li>
<li>Prioritize Cost Efficiency Without Compromising Quality â€“ Smart negotiations and budget simplifications can yield significant savings.</li>
<li>Focus on User Experience â€“ A seamless user experience ensures long-term adoption and success.</li>
</ol>
<h2 id="conclusion">Conclusion</h2>
<p>The successful execution of this multi-million dollar SaaS transition stands as a testament to the power of strategic planning, meticulous execution, and unwavering focus on business value. Undertaking such a SaaS transition also requires a balance of technical expertise, financial acumen, and stakeholder management. </p>
<p>\
By adopting a strategic, phased approach, we not only modernized our IT landscape but also realized substantial cost savings. The insights gained from this experience will serve as a valuable blueprint for future initiatives, ensuring that technology remains a powerful enabler of business success. If youâ€™re considering a similar transition, start with a clear roadmap, engage key stakeholders early, and continuously optimize for efficiency.</p>
<p>\
Are you currently working on a SaaS transition? Iâ€™d love to hear your thoughts and experiences in the comments below!</p>]]></content:encoded>
            <media:thumbnail url="https://hackernoon.com/https://cdn.hackernoon.com/images/eQHzh6rz7ETBHLjs0KzCl1Dooqp2-jz037cd.png"/>
        </item>
        <item>
            <title><![CDATA[An Open Letter To Mark Zuckerberg: Size Doesn't Matter]]></title>
            <description><![CDATA[DeepSeek is making open-source foundational models, but if it didnâ€™t also provide services directly through its web interface and the iPhone app, there is fat chance it could disrupt the U.S. markets the way it did. As Meta keeps chasing more and more parameters in its LLMs, the cost to acquire the hardware to run these models gets ridiculous.]]></description>
            <link>https://hackernoon.com/an-open-letter-to-mark-zuckerberg-size-doesnt-matter?source=rss</link>
            <guid isPermaLink="true">https://hackernoon.com/an-open-letter-to-mark-zuckerberg-size-doesnt-matter?source=rss</guid>
            <category><![CDATA[mark-zuckerberg]]></category>
            <category><![CDATA[artificial-intelligence]]></category>
            <category><![CDATA[openai]]></category>
            <category><![CDATA[llama]]></category>
            <category><![CDATA[letter-to-mark-zuckerberg]]></category>
            <category><![CDATA[deepseek]]></category>
            <category><![CDATA[llms]]></category>
            <category><![CDATA[grok]]></category>
            <dc:creator><![CDATA[Neer Varshney]]></dc:creator>
            <pubDate>Sat, 12 Apr 2025 17:00:09 GMT</pubDate>
            <image/>
            <content:encoded><![CDATA[<p>There are two key requirements for the success of any digital product â€” ease of access and a user-friendly interface and experience.</p>
<p>\
If this wasnâ€™t the case, Linux-based OS systems would trump MacOS and Windows.</p>
<p>\
This is also the reason why GPT, Claude, and Grok models are triumphing over open-source LLMs like the Llama and Mistral series, even when the latter provide some incredible utility with great customizations.</p>
<p>\
I think OpenAI and DeepSeek present interesting case studies here.</p>
<p>\
DeepSeek is making open-source foundational models, but if it didnâ€™t also provide services directly through its web interface and <a href="https://dzambhalafinance.com/2025-01-27/news/deepseek-surges-to-the-top-of-u-s-iphone-charts-amidst-geopolitical-tensions/?utm_source=mail.artificiallyboosted.com&utm_medium=referral&utm_campaign=dear-zuckerberg-size-doesn-t-matter">the iPhone app</a> â€” there is fat chance it could disrupt the U.S. markets the way it did.</p>
<p>\
Like DeepSeek was doing before, it would have remained a product that nerdy devs talked about as the â€œreal dealâ€ in their small circles, as was happening in months preceding the mania that surrounded the Chinese company.</p>
<p>\
OpenAI similarly built open-source models in shadows for roughly seven years between 2015 and 2022 â€” until it launched ChatGPT. Iâ€™m sure you remember what that was like.</p>
<h3 id="tollamaornottollama">To Llama, Or Not To Llama</h3>
<p>One constraint in the more widespread utility of open-source models is technical skills â€” that one is more obvious.</p>
<p>\
But when it comes to LLMs â€” itâ€™s actually also money. ðŸ’¸</p>
<p>\
You see, running open-source models requires GPUs. Some small open-source models can run on consumer GPUs like the one I have in my top-of-the-line M3 Max Macbook Pro with 36 GB of memory.</p>
<p>\
But others require dedicated ones.</p>
<p>\
Meta this weekend dropped the Llama 4 series of models, including the Maverick and Scout LLMs, and announced plans to release Behemoth at a later date.</p>
<p>\
There are no updates yet on the reasoning model from the fourth series, except for a nerdy-looking Llama <a href="https://www.llama.com/llama4-reasoning-is-coming/?utm_source=mail.artificiallyboosted.com&utm_medium=referral&utm_campaign=dear-zuckerberg-size-doesn-t-matter">telling us</a> it is â€œcoming soon.â€</p>
<p>\
 <img src="https://cdn.hackernoon.com/images/acbsj5Z7CqMQoFbgULkxI61NfAq1-2025-04-12T17:00:07.836Z-yu5niqm4pg19q3f8u2si0hze" alt="" /></p>
<p>Here is the most eyebrow-raising bit about Llama 4: As Meta keeps chasing more and more parameters in its LLMs, the cost to acquire the hardware to run these models gets ridiculous.</p>
<p>\
Itâ€™s a bit early and I havenâ€™t analyzed every information available on developers trying to run the models on different devices but it seems that the minimum requirement to comfortably run the lower-end Scout model is a single Nvidia H100 GPU, which costs roughly $40,000 â€” <em>provided you can manage to get your hands on one.</em></p>
<p>\
If Sam Altman, with his hundreds of billions of dollars, struggles to find GPUs, so does this poverty-struck startup founder.</p>
<h3 id="mixtureofexperts">Mixture of Experts</h3>
<p>Having said that, there is one interesting thing that makes it possible to run the Llama 4 line on Apple products â€” the possibility of the Mac Studio with 128 GB memory or above.</p>
<p>\
That is a Mixture of Experts.</p>
<p>\
Some of the earlier LLMs were actually a single model trained on a whole swath of data from across domains like GPT-3 or the original Llama. But companies are rapidly switching to a mixture of experts concept.</p>
<p>\
This means that even though we see Llama 4 Scout as a single model that we are talking to, it is actually deciding between 16 separate trained models on which one will respond to the query, based on whether we asked it a math question or asked it to spark creativity.</p>
<p>\
This is different from the traditional dense models that operated on single monolithic networks, where all of the parameters of the LLMs were activated for every query. So, even if you asked it â€œwhatâ€™s 2+2,â€ it would active all of its knowledge on Socrates and Platoâ€™s philosophies.</p>
<h3 id="dearzucksizedoesntmatter">Dear Zuck, Size Doesnâ€™t Matter</h3>
<p>Setting aside the difficulties of running the Llama 4 series, even the ones who have tried it (mostly through Groq/OpenRouter) are less than impressed.</p>
<p>\
The Llama 4 series isnâ€™t doing great at coding or deep questions â€” but seems to love emojis (and me â¤ï¸).</p>
<p>\
So here goes, even as companies keep obsessing over increasing the parameters in the training of foundational LLMs, which doesnâ€™t seem to be improving things.</p>
<p>\
In fact, it may have opened a key business opportunity that we thought of as closed so far. That of training more domain-specific niche models.</p>
<p>\
As noted by AI researcher Andriy Burkov, if your business idea isn't in the math and coding or factual question-answering domains, <strong>there is a great opportunity to</strong>&nbsp;<strong>build your business-specific dataset</strong>.</p>
<p>\
The potential increase in generalist models' skills will no longer be a threat.</p>
<p>\
So, is now the time we make our own LLM at Dzambhala Finance? Perhaps, but we need enough revenue to sustain a bigger database.</p>
<p>\
<em>This post is republished from the <a href="https://mail.artificiallyboosted.com/subscribe">Artificially Boosted newsletter</a> that goes out every week.</em></p>]]></content:encoded>
            <media:thumbnail url="https://hackernoon.com/https://cdn.hackernoon.com/images/acbsj5Z7CqMQoFbgULkxI61NfAq1-0f0388d.jpeg"/>
        </item>
        <item>
            <title><![CDATA[EdTech Startup Ups and Downs: Launching a Product in the USA]]></title>
            <description><![CDATA[We brought a unique coding platform and cohort-based model to the U.S. market. It didn't go as planned. Here is why and how we fixed it.]]></description>
            <link>https://hackernoon.com/edtech-startup-ups-and-downs-launching-a-product-in-the-usa?source=rss</link>
            <guid isPermaLink="true">https://hackernoon.com/edtech-startup-ups-and-downs-launching-a-product-in-the-usa?source=rss</guid>
            <category><![CDATA[product-development]]></category>
            <category><![CDATA[edtech]]></category>
            <category><![CDATA[entrepreneurship-in-edtech]]></category>
            <category><![CDATA[edtech-startups]]></category>
            <category><![CDATA[learn-edtech]]></category>
            <category><![CDATA[ux-research]]></category>
            <category><![CDATA[user-experience]]></category>
            <category><![CDATA[hackernoon-top-story]]></category>
            <dc:creator><![CDATA[Maria Shchur]]></dc:creator>
            <pubDate>Sat, 12 Apr 2025 17:00:02 GMT</pubDate>
            <image/>
            <content:encoded><![CDATA[<p>\</p>
<blockquote>
  <p>We brought a unique coding platform and cohort-based model to the American market. And it didnâ€™t go as planned. Here is why, and how we fixed it.</p>
</blockquote>
<p>\
Launching an EdTech product in a competitive and foreign market is challenging â€” and yet exciting. You never really know if it will work. Even after studying other startupsâ€™ failures and successes, analyzing competitors, and tracking market trends, thereâ€™s always something unexpected to prepare for. In this article, letâ€™s explore a real EdTech product case: how we changed one of our productâ€™s core features for a new market - and how it turned out.</p>
<hr />
<h2 id="acodingplatformandstructuredcohortbasedlearningmodel">ðŸ›¬ A Coding Platform and Structured Cohort-Based Learning Model</h2>
<p>At the time of launching a product, our team was small, and weâ€™d seen how well the structured, interactive learning system worked in an online learning system. It seemed logical to try the same setup: an interactive coding platform, a cohort-based program with strict deadlines, active support from mentors and tutors, and a strong, structured curriculum.</p>
<p>\
The team did the homework - we analyzed the market, looked at competitors, prepared a plan - and yes, some main competitors already have been offering similar models, with mentoring or cohort elements. Not everyone had a custom learning platform, though, so we thought we had a technical advantage there.</p>
<p>\
So, we launched with a classic EdTech format: students start in a cohort on a fixed date, progress together, and if they fall too far behind, they take an â€œacademic breakâ€ and rejoin a later cohort. It made sense to us. It worked well with a lot of markets and users. In the U.S.? It turned out not so much.</p>
<hr />
<h2 id="whatwentwrong">ðŸ’¥ What Went Wrong</h2>
<p>American users didnâ€™t really click with the model. Even though the feedback at first was great and positive, and there were some really strong cohorts where students bonded and made it all the way through together - retention there was over 75% even a year later. But in general, financial metrics and learning analytics clearly showed that there were issues in motivation, retention, and sticking to the deadlines.</p>
<p>\
Different time zones of students and tutors, the need for more flexibility, and the expectation of being able to balance between part-time learning and real life - it all didnâ€™t go well with our initial structure. The coding projects were technically challenging and time-intensive. Deadlines were hard. Students get stressed. And stress led to churn.</p>
<p>\
The academic break system didnâ€™t help as planned -  in fact, it hurt retention badly. It felt like a failure to the students, even if that wasnâ€™t the intention. So, we had to rethink the whole thing ASAP before it was too late. One of the challenges was to implement something new from scratch in the middle of the learning process on the online platform and ruin usersâ€™ progress and our promises. It also was quite bounded to the legal side of educational services, and this is something that should be considered from the first place.</p>
<hr />
<h2 id="rebuildingthelearningmodelandswitchingtosomethingnewfromscratch">ðŸ”„ Rebuilding the Learning Model and Switching to Something New From Scratch</h2>
<p>We ran a full discovery process. We spoke to the teams, independent experts and consultants, students, competitors, and U.S.-based learning designers. We dove into best practices across global EdTech. And based on what we learned, there was a full redesign of our learning model and platform technical opportunities.</p>
<p>\
We shifted from strict cohort-based learning to a flexible model, introducing recommended deadlines as milestones, reducing the emotional pressure of failure. We redesigned the platform logic, the tone of our communications, the way we positioned the product, and the structure of student support.</p>
<p>\
Instead of being tied to a single tutor, students had access to multiple mentors at once - this expanded their network and let them learn from different industry professionals by attending workshops conducted by different experts. We removed â€œacademic breaksâ€ and replaced them with a limited number of â€œextra weeksâ€ students could request if they needed more time. </p>
<p>\
We even started to notify them ahead of time: â€œThis stage might be tricky â€” save your â€˜ladderâ€™ for later.â€ Like in a game, and it helped. It made the experience much more personal, more flexible, and much more aligned with American learning culture. Retention was thriving, and we got plenty of positive feedback and boosted financial metrics along with learning analytics. However, it was not something we had to stop at - EdTech is constantly changing, and even now, we implemented plenty of changes to this structure, yet keep providing our users with personalized flexibility, but better managed.</p>
<hr />
<h2 id="howtolistentovaguefeedbackandcreateahypothesis">ðŸŽ¯ How to Listen to Vague Feedback and Create a Hypothesis</h2>
<p>Talking to the users is known as one of the most important parts of product development. And we constantly did it via feedback surveys, customer development interviews, UX research, etc. But the issue was that feedback was sometimes polite but vague. Especially in early interviews, weâ€™d get generic answers that didnâ€™t really help us validate specific hypotheses.</p>
<p>\
For example, when users drop out, they might say â€œfinancial reasons.â€ Butâ€¦ what does that actually mean?</p>
<p>\
Did we not offer the right payment plans? Were they unmotivated? Or maybe they actually didnâ€™t like the course - but didnâ€™t want to say that?</p>
<p>\
What always helped when we were in the dark was that we reviewed their learning experience journeys in detail before going on the UX interview. Sometimes, we could see early predictors of churn or dropping motivation. Or it could be a totally different situation - having highly motivated students and unexpected refund requests with vague answers. It was tough when the feedback lacked specificity. </p>
<p>\
Compared to students from other markets we worked with -  who were often more direct - this felt like trying to read between the lines sometimes.</p>
<p>\
Even exit interviews werenâ€™t always that helpful. So, we had to learn how to listen better. And here is when active listening proved itself as a real deal. On calls, we started tossing in hypotheses like: â€œSo, would a feature like this have helped you stay on track?â€ And suddenly, theyâ€™d open up with way more detail. Another example was to offer students to share their feedback with team members related to the problem - if it was financial, then it was the sales or Product Manager responsible for the payment options. </p>
<p>\
In case of technical or curriculum problems, we sometimes invited several team members on the UX interview - from development and curriculum teams. In addition to the interviews, we completely changed our feedback surveys and rephrased questions - it did make a difference as well as a preliminary step before the exit interview. We also made sure that people involved in the interviews knew the product from within and completed at least a small part of it as if they were students so that they would speak with them using the same language.</p>
<hr />
<h2 id="offeringfreecontentwasntasattractiveaswethought">ðŸ¤– Offering Free Content Wasnâ€™t as Attractive as We Thought</h2>
<p>Another thing that didnâ€™t land? Letting users self-explore the platform and our product.</p>
<p>\
Weâ€™d hoped students would find the course, go through a free trial, check how great and interactive it was, book a call with sales if interested, and enroll. But that path rarely worked, especially since the idea was to â€œtry something with no commitment.â€</p>
<p>\
It actually worked way better when a sales representative - admission advisor or career advisor - talked to them first, walked them through career paths, compared programs, helped them reflect on their goals and motivation, discussed financial plans, and saw if there was a match.</p>
<p>\
That human connection created clarity and trust, and self-service never quite matched that. What also worked greatly was offering users to start any program earlier with a very affordable fee (around $100) with platform and expert guidance, career advice, and support from our side. There was no commitment to prolong this fee and turn it into program payment - just to explore the platform with all features - not alone, but with personalized support right from the start. This way, both the company and the user were committed and interested in the outcome, and we guided students all the way long without pressure.</p>
<hr />
<h2 id="somefinalthoughts">Some Final Thoughts</h2>
<p>You canâ€™t just copy-paste a model from one country to another and expect it to fit perfectly. Even when the format is strong and the platform is solid, culture and user behavior shape everything - from how people learn to how they give feedback and to what they expect from tech.</p>
<p>\
We made a lot of assumptions. We got plenty of things wrong. But we listened, iterated, and rebuilt key parts of the experience - and we were not afraid of doing so. And eventually, it worked. Students responded. Retention improved. The learning journey felt more natural, more empowering, and more engaging.</p>]]></content:encoded>
            <media:thumbnail url="https://hackernoon.com/https://cdn.hackernoon.com/images/a-robotic-teacher-reading-a-book-to-students-waterpaint-artstyle-r4d4h8cecc3p7bcxq1sp134y.png"/>
        </item>
        <item>
            <title><![CDATA[The HackerNoon Newsletter: I Blew â‚¬400 on Cursor â€” Heres What I Learned So You Dont Have To (4/12/2025)]]></title>
            <link>https://hackernoon.com/4-12-2025-newsletter?source=rss</link>
            <guid isPermaLink="true">https://hackernoon.com/4-12-2025-newsletter?source=rss</guid>
            <category><![CDATA[hackernoon-newsletter]]></category>
            <category><![CDATA[noonification]]></category>
            <category><![CDATA[latest-tect-stories]]></category>
            <category><![CDATA[ai]]></category>
            <category><![CDATA[saas]]></category>
            <category><![CDATA[ai]]></category>
            <category><![CDATA[web3]]></category>
            <category><![CDATA[malware-threat]]></category>
            <dc:creator><![CDATA[Noonification]]></dc:creator>
            <pubDate>Sat, 12 Apr 2025 16:04:26 GMT</pubDate>
            <image/>
            <content:encoded><![CDATA[

        <p><strong>How are you, hacker?</strong></p>
        <br />
        <p>ðŸª Whatâ€™s happening in tech today, April 12, 2025?</p>
        <br />
        <p>
          The
          <a href="https://hackernoon.com/noonification" target="_blank" rel="noopener"> HackerNoon Newsletter</a>
          brings the HackerNoon
          <a href="https://hackernoon.com" target="_blank" rel="noopener">homepage</a>
          straight to your inbox.
          <a href="https://hackernoon.com/on-this-day" target="_blank" rel="noopener">On this day,</a>

            <strong>Space Shuttle's First Flight</strong> in 1981,  <strong>First human in space</strong> in 1961,

          and  we present you with these top quality stories.

            From
        <a href="https://hackernoon.com/i-blew-euro400-on-cursor-heres-what-i-learned-so-you-dont-have-to" class="eventTitle"><strong>I Blew â‚¬400 on Cursor â€” Heres What I Learned So You Dont Have To</strong></a>
       to
        <a href="https://hackernoon.com/tokenization-will-swallow-the-worlds-financial-assets-whether-we-like-it-or-not" class="eventTitle"><strong>Tokenization Will Swallow the Worlds Financial Assets, Whether We Like It or Not</strong></a>,
       letâ€™s dive right in.

        </p>


          <h2><a href="https://hackernoon.com/i-blew-euro400-on-cursor-heres-what-i-learned-so-you-dont-have-to">I Blew â‚¬400 on Cursor â€” Heres What I Learned So You Dont Have To</a></h2>
          <p><img src="https://cdn.hackernoon.com/images/2jqChkrv03exBUgkLrDzIbfM99q2-k402u8w.webp" alt="" /> </p>
          <br />
          <p>By <a href="https://hackernoon.com/u/techbyadam">@techbyadam</a> [ 3 Min read ] Building software with Cursor is super fast, and you should definitely use it. However, there are some downsides. <a href="https://hackernoon.com/i-blew-euro400-on-cursor-heres-what-i-learned-so-you-dont-have-to">Read More.</a></p>

          <h2><a href="https://hackernoon.com/8-free-cloudflare-features-that-save-me-$200month-with-examples">8 Free Cloudflare Features That Save Me $200/Month (With Examples)</a></h2>
          <p><img src="https://cdn.hackernoon.com/images/HE82pPxIBPQWXats2wSx9NU3MtT2-2t035rh.jpeg" alt="" /> </p>
          <br />
          <p>By <a href="https://hackernoon.com/u/alexanderisora">@alexanderisora</a> [ 2 Min read ] Here are some features that can bring down your cost. <a href="https://hackernoon.com/8-free-cloudflare-features-that-save-me-$200month-with-examples">Read More.</a></p>

          <h2><a href="https://hackernoon.com/ai-and-human-creativity-can-totally-coexistif-ai-doesnt-end-up-eating-the-thing-keeping-it-alive">AI and Human Creativity Can Totally Coexistâ€”if AI Doesnâ€™t End up Eating the Thing Keeping it Alive</a></h2>
          <p><img src="https://cdn.hackernoon.com/images/3GwutAJRWQVk90FbpCzdqx8nvyj1-tb03had.png" alt="" /> </p>
          <br />
          <p>By <a href="https://hackernoon.com/u/thefrogsociety">@thefrogsociety</a> [ 20 Min read ] Artists are calling it theft. Fans are calling it soulless. Hayao Miyazaki once called AI-generated art â€œan insult to life itselfâ€. How should we think about it <a href="https://hackernoon.com/ai-and-human-creativity-can-totally-coexistif-ai-doesnt-end-up-eating-the-thing-keeping-it-alive">Read More.</a></p>

          <h2><a href="https://hackernoon.com/tokenization-will-swallow-the-worlds-financial-assets-whether-we-like-it-or-not">Tokenization Will Swallow the Worlds Financial Assets, Whether We Like It or Not</a></h2>
          <p><img src="https://cdn.hackernoon.com/images/OYD3SUIXshanW9XAmljvgTdQKuB3-dy03a64.jpeg" alt="" /> </p>
          <br />
          <p>By <a href="https://hackernoon.com/u/andreydidovskiy">@andreydidovskiy</a> [ 8 Min read ] In the heat of innovation and rapid expansion, we get ahead of our skis and give crypto a bad rep. It is more than just digital coins... It is a societal shift. <a href="https://hackernoon.com/tokenization-will-swallow-the-worlds-financial-assets-whether-we-like-it-or-not">Read More.</a></p>

          <h2><a href="https://hackernoon.com/2025-has-already-brought-a-host-of-new-crypto-stealing-malwaresheres-5-to-watch-out-for">2025 Has Already Brought a Host of New Crypto-Stealing Malwaresâ€”Heres 5 to Watch Out For</a></h2>
          <p><img src="https://cdn.hackernoon.com/images/AO3i53agltRgq8NH0cq0AaViIh42-dw033at.png" alt="" /> </p>
          <br />
          <p>By <a href="https://hackernoon.com/u/obyte">@obyte</a> [ 7 Min read ] Well explore here five relatively new crypto-stealing malware types, from screenshot and clipboard stealers to fake video conferencing software. Lets go! <a href="https://hackernoon.com/2025-has-already-brought-a-host-of-new-crypto-stealing-malwaresheres-5-to-watch-out-for">Read More.</a></p>


        <br />
        <p>ðŸ§‘â€ðŸ’» What happened in your world this week?</p>
        <p>
          It's been said that
          <a href="https://hackernoon.com/developers-the-why-and-how-to-writing-technical-articles-54e824789ef6">writing can help consolidate technical knowledge</a>,
          <a href="https://hackernoon.com/how-can-non-writers-become-effective-bloggers-1pq32wd">establish credibility</a>,
          <a href="https://hackernoon.com/how-can-non-writers-become-effective-bloggers-1pq32wd"> and contribute to emerging community standards</a>.
          Feeling stuck? We got you covered â¬‡ï¸â¬‡ï¸â¬‡ï¸
        </p>
        <br />
        <p>
          <a href="https://app.hackernoon.com/mobile/lZx3fmlPdlPJpVBIdble">ANSWER THESE GREATEST INTERVIEW QUESTIONS OF ALL TIME</a>
        </p>
        <br />
        <p>We hope you enjoy this worth of free reading material. Feel free to forward this email to a nerdy friend who'll love you for it.See you on Planet Internet! With love,
 The HackerNoon Team âœŒï¸</p>
        <br />
        <p><img src="https://cdn.hackernoon.com/images/the-hackernoon-newsletter-footer.png" alt="" /></p>

            ]]></content:encoded>
            <media:thumbnail url="https://hackernoon.com/https://cdn.hackernoon.com/images/hackernoon_newsletter_553_v1pjc97ufy01cnwpeu2wdria.png"/>
        </item>
        <item>
            <title><![CDATA[Hiro Yamada on Building First Mate Technologies: Silicon Valley Expertise Meets Global Perspective]]></title>
            <description><![CDATA[Hiro Yamada is the co-founder and CEO of First Mate Technologies. The company combines the technical excellence of Silicon Valley with the cost efficiency of Asia.]]></description>
            <link>https://hackernoon.com/hiro-yamada-on-building-first-mate-technologies-silicon-valley-expertise-meets-global-perspective?source=rss</link>
            <guid isPermaLink="true">https://hackernoon.com/hiro-yamada-on-building-first-mate-technologies-silicon-valley-expertise-meets-global-perspective?source=rss</guid>
            <category><![CDATA[software-development]]></category>
            <category><![CDATA[startup]]></category>
            <category><![CDATA[asia]]></category>
            <category><![CDATA[cost-effectiveness]]></category>
            <category><![CDATA[first-mate-technologies]]></category>
            <category><![CDATA[hiro-yamada]]></category>
            <category><![CDATA[edtech]]></category>
            <category><![CDATA[good-company]]></category>
            <dc:creator><![CDATA[Manasvi Arya]]></dc:creator>
            <pubDate>Sat, 12 Apr 2025 14:39:14 GMT</pubDate>
            <image/>
            <content:encoded><![CDATA[<p>Hiro Yamadaâ€™s journey in tech has been defined by a commitment to solving real-world problems, a belief in the power of collaboration, and the pursuit of authentic connections. As the co-founder and CEO of First Mate Technologies, <strong><a href="https://www.linkedin.com/in/hirohisayamada/">Yamada</a></strong> draws on experience from Silicon Valley and Asia to help startups navigate the ever-evolving challenges of software development. Yet for Yamada, technology is never just about code and algorithmsâ€”it is a way to empower people, companies, and entire communities.</p>
<h2 id="globalinsightsfromindustrygiants">Global Insights from Industry Giants</h2>
<p>Prior to launching First Mate Technologies, Yamada built a distinguished career at Google, Palantir, and Asana, gaining insights into how large-scale platforms operate and expand. While at Asana, Yamada was instrumental in establishing the companyâ€™s office in Tokyo. Through market-entry strategies and major partnership initiatives, he learned firsthand how to bridge cultural gaps and tailor global business models to local markets. During this period, he collaborated with a leading Japanese multinational investment holding company, experiences that underscored both the immense opportunities and the intricate complexities of global tech growth.</p>
<h2 id="ashifttowardentrepreneurship">A Shift Toward Entrepreneurship</h2>
<p>The transition from established tech roles to entrepreneurial leadership took shape when Yamada and Harvard College roommate Mark Yao identified a recurring pain point among fledgling startups: the difficulty of accessing software development resources that matched the pace and ambitions of emerging businesses. Their response was First Mate Technologies, founded in 2023 with the initial aim of revolutionizing EdTech through an AI-powered language-learning app. Though the app itself did not reach the level of success they had hoped for, the process revealed a hidden strengthâ€”a global engineering team capable of executing at a world-class level.</p>
<h2 id="refiningahybridmodel">Refining a Hybrid Model</h2>
<p>Recognizing this asset, the company shifted its focus to software development and AI engineering services specifically for startups and scale-ups. Instead of operating solely within Silicon Valley or relying entirely on Asia-based models, First Mate Technologies adopted a hybrid approach, blending technical leadership with cost-effective operations. Under Yamadaâ€™s guidance, teams based in different regions collaborate on scalable, secure, and high-quality software solutions that cater to fast-moving client demands. Over the past year, First Mate Technologies has grown from two people to more than twenty full-time employees, reflecting both the demand for such a model and the founderâ€™s ability to inspire talent.</p>
<p>\
Beyond the technical arena, Yamadaâ€™s leadership style is marked by genuine curiosity about clients, colleagues, and cultures. Frequent travels from Tokyo to meet collaborators underscore the value he places on personal interaction. In a world increasingly dominated by virtual tools, he remains convinced that trust is best built through honest conversation and face-to-face connections. This human-centric model is integral to the companyâ€™s identityâ€”transparency and empathy are seen as essential to forging long-term relationships with emerging startups.</p>
<h2 id="humancentricvaluesforgrowth">Human-Centric Values for Growth</h2>
<p>Yamadaâ€™s personal journey, including the early pivot from an ambitious EdTech product to a broader engineering services approach, illustrates a mindset that values learning from setbacks. Each challenge, according to Yamada, serves as an opportunity to refine strategies, improve offerings, and become more attuned to the realities of the market. That perspectiveâ€”equal parts technical problem-solving and empathetic leadershipâ€”continues to guide First Mate Technologies as it explores new AI tools, expands its engineering roster, and pursues alliances with like-minded ventures.</p>
<p>\
Though the company is still young, its trajectory speaks to the ideals that have shaped Yamadaâ€™s career: excellence in execution, open collaboration across borders, and a vision that extends beyond financial success to meaningful contributions in technology. For Yamada, the road ahead promises more than just bigger teams or larger client rosters; it is a chance to keep merging technical expertise with human values, ensuring that innovation always has a purpose and a positive impact.</p>
<p>\</p>
<p>:::info
<strong><em>This story was authored under HackerNoonâ€™s <a href="https://business.hackernoon.com/business-blogging">Business Blogging Program</a>.</em></strong></p>
<p>:::</p>
<p>\</p>]]></content:encoded>
            <media:thumbnail url="https://hackernoon.com/https://cdn.hackernoon.com/images/IKXzMIRzuqcRvy8v7VsXkDPhvBK2-zw03b9c.jpeg"/>
        </item>
        <item>
            <title><![CDATA[The AI Engineerâ€™s Playbook: Mastering Vector Search & Management (Part 2)]]></title>
            <description><![CDATA[Master vector search & management for production AI. Covers ANN algorithms, quantization, filtering, access patterns & performance tradeoffs for scaling.]]></description>
            <link>https://hackernoon.com/the-ai-engineers-playbook-mastering-vector-search-and-management-part-2?source=rss</link>
            <guid isPermaLink="true">https://hackernoon.com/the-ai-engineers-playbook-mastering-vector-search-and-management-part-2?source=rss</guid>
            <category><![CDATA[artificial-intelligence]]></category>
            <category><![CDATA[machine-learning]]></category>
            <category><![CDATA[ai-engineering]]></category>
            <category><![CDATA[ml-engineering]]></category>
            <category><![CDATA[ml-engineer]]></category>
            <category><![CDATA[ai-engineer]]></category>
            <category><![CDATA[mlops]]></category>
            <category><![CDATA[ai-vector-representations]]></category>
            <pubDate>Sat, 12 Apr 2025 14:35:27 GMT</pubDate>
            <image/>
            <content:encoded><![CDATA[<p>\
Vector embeddings are the backbone of modern AI systems, encapsulating complex patterns from text, images, audio, and other data types. However, even the best embeddings are essentially useless without solid systems in place to store, retrieve, and manage them efficiently at scale.</p>
<p>\
This often-overlooked aspect, known as Vector Search &amp; Management (VS&amp;M), is crucial for turning your data into something that actually drives value. Without it, systems canâ€™t live up to their full potential. ==This article presents a systematic approach to vector search and management== based on three key pillars: <strong>(1) access patterns, (2) performance requirements, and (3) data characteristics.</strong></p>
<p>\
By evaluating your system through this framework, youâ€™ll make informed architectural decisions that balance speed, accuracy, cost, and scalability. In <a href="https://hackernoon.com/the-ai-engineers-playbook-master-data-sources-for-retrieval-systems-part-1">Part 1 we explored how to work with the right Data Sources</a>. Now weâ€™ll tackle the next layer: transforming those embeddings into actionable systems through effective vector search and management.</p>
<h1 id="asystematicapproachtovectorsearchmanagement">A Systematic Approach to Vector Search &amp; Management</h1>
<p>Over the past few years building ML systems, Iâ€™ve seen teams put serious efforts into generating sophisticated vector embeddings. They capture subtle patterns across text, images, audio â€” you name it. But too often, that potential gets stuck. Because no matter how good your embeddings are, theyâ€™re only as useful as your ability to retrieve and act on them â€” fast, accurately, and at scale.</p>
<p>\
Without proper vector search and management:</p>
<ul>
<li><p>You canâ€™t surface relevant results</p></li>
<li><p>Embeddings go stale instead of improving with feedback</p></li>
<li><p>Latency and costs spiral out of control as your data grows</p>
<p>\</p></li>
</ul>
<p>This is the part that makes the system work. Itâ€™s the engine behind semantic search, recommendations, and all the smart features users expect. Skip it, and youâ€™ve built a brain without a nervous system. Before diving into technical details, letâ€™s establish the decision framework that will guide our implementation choices:</p>
<p>\
<strong>(1) Define System Requirements</strong></p>
<ul>
<li>Performance targets (latency, throughput, recall)</li>
<li>Data characteristics (volume, dimensionality, update frequency)</li>
<li>Operational constraints (cost, infrastructure, team expertise)</li>
</ul>
<p>\
<strong>(2) Choose Access Patterns</strong></p>
<ul>
<li>Static in-memory (small, stable datasets)</li>
<li>Dynamic access (large or frequently changing datasets)</li>
<li>Batch processing (offline analytics and index building)</li>
</ul>
<p>\
<strong>(3) Select Technical Implementation</strong></p>
<ul>
<li>Search algorithms (exact vs. approximate)</li>
<li>Optimization techniques (quantization, filtering)</li>
<li>Storage and indexing strategies</li>
</ul>
<p>\
<strong>(4) Establish Evaluation Framework</strong></p>
<ul>
<li>System metrics (throughput, latency, resource utilization)</li>
<li>Quality metrics (recall, precision, relevance)</li>
<li>Operational metrics (build time, update latency)</li>
</ul>
<p>\
This framework ensures that technical decisions align with your specific use case and business requirements.</p>
<h1 id="coreconcepts">Core Concepts</h1>
<p>Vector Search &amp; Management consists of ==two interconnected components==:</p>
<p>\</p>
<ul>
<li><strong>Vector Management:</strong> The infrastructure for storing, indexing, updating, and maintaining vector embeddings and associated metadata. Getting this right ensures data freshness, accessibility, and prepares vectors for downstream tasks.</li>
<li><strong>Vector Search:</strong> The query engine that enables fast and relevant retrieval from potentially massive vector datasets. This is where the magic of finding similar items happens at scale.</li>
</ul>
<h1 id="whymasteringvectorsearchmanagementisnonnegotiable">Why Mastering Vector Search &amp; Management is Non-Negotiable</h1>
<p>Effective vector search and management capabilities unlock ==three key benefits==:</p>
<p>\</p>
<ul>
<li><strong>Embedding Evaluation and Improvement:</strong> How do you know if your embeddings are truly performing well in practice? To answer this, you need to query them against representative datasets and evaluate them using metrics like <em>recall@k</em>. Without efficient vector search, evaluating embeddings across millions or billions of items becomes prohibitively slow, restricting tests to small samples or simple cases. Without robust vector search and management, youâ€™re left with a limited understanding of embedding performance in production.</li>
<li><strong>Fresh, Relevant Inputs to ML Models:</strong> Models performing Transfer Learning, RL, Recommendations, Anomaly Detection, or Active Learning rely on embeddings as input. Moreover, vector search capabilities allow for the efficient retrieval of specific vectors needed for complex training tasks (such as finding hard negatives for active learning). Without solid vector search and management, models can underperform, and training processes become inefficient.</li>
<li><strong>Real-Time Applications Capabilities:</strong> User-facing applications like semantic search, recommendations, and visual similarity search require low-latency and high-throughput query responses, especially as the data is constantly changing. While embeddings define similarity, itâ€™s the vector search engine that delivers results in milliseconds, at scale. Traditional databases struggle to meet these demands, making specialized vector search and management systems. Without these capabilities, user experience suffers significantly.</li>
</ul>
<h1 id="navigatingthedesigntradeoffsforvectorsearchmanagement">Navigating the Design Trade-offs for Vector Search &amp; Management</h1>
<p>Successfully implementing Vector Search &amp; Management requires balancing competing priorities. Letâ€™s examine the ==key design dimensions==:</p>
<h2 id="performancerequirements">Performance Requirements</h2>
<p>Every vector search system makes tradeoffs between:</p>
<p>\
<strong>(1) Speed/Latency:</strong> How quickly must the system respond? Is sub-100ms latency required, or is a second acceptable? Lower latency requirements typically demand more computational resources and may require compromises in accuracy.</p>
<p><strong>(2) Accuracy/Recall:</strong> What level of precision is required? Is finding 95% of relevant results sufficient, or must you capture 99.9%? Higher recall requirements typically increase computational costs and may reduce speed.</p>
<p><strong>(3) Cost:</strong> What budget constraints exist? Higher performance generally requires more resources, leading to increased costs. Understanding your economic constraints is essential for sustainable design.</p>
<p><strong>(4) Scalability:</strong> How must the system scale as data grows? Does it need to handle millions of queries across billions of vectors? Scalability requirements influence architecture choices from the start.</p>
<h2 id="datacharacteristics">Data Characteristics</h2>
<p>Understanding your data is crucial for vector search design:</p>
<p>\
<strong>(1) Data Volume:</strong> The number of vectors in your dataset fundamentally impacts architecture choices. Systems handling thousands, millions, or billions of vectors require different approaches.</p>
<p><strong>(2) Vector Dimensionality:</strong> Higher dimensions (1024+) versus lower dimensions (128) affect memory usage, computational requirements, and algorithm selection.</p>
<p><strong>(3) Update Frequency:</strong> How often vectors change shapes your entire pipeline:</p>
<ul>
<li>Real-time streaming: Immediate updates requiring continuous indexing</li>
<li>Frequent batches: Regular updates (hourly/daily) allowing periodic reindexing</li>
<li>Infrequent bulk loads: Rare updates enabling static optimization</li>
</ul>
<h2 id="queryaccesspatterns">Query Access Patterns</h2>
<p>Consider how users and systems interact with your vector data determines architecture:</p>
<p>\
<strong>(1) High-throughput single lookups:</strong> Quick individual queries requiring optimized retrieval paths</p>
<p><strong>(2) Complex batch queries:</strong> Analytical workloads processing multiple vectors simultaneously</p>
<p><strong>(3) Filtering before search:</strong> Scenarios requiring metadata filtering before or alongside vector similarity</p>
<p>\
One way to think about the design process is to visualize it as a triangle, where each of these factors forms one corner, and the optimal design lies at the intersection of all three:</p>
<p><img src="https://cdn.hackernoon.com/images/qK3Oc94UoaXVEpERoZrZAGvfAtD3-u70328h.png" alt="Synthesizing the Tradeoffs: The Design Triangle" /></p>
<p>\
Every project involves making conscious trade-offs, especially when defining your priorities and deciding which aspects to prioritize. For example, in an <strong>e-commerce recommendation system</strong>, the need for low latency (speed) and real-time updates may take precedence. This would require prioritizing fast retrieval of vectors as soon as a user interacts with the system. However, this could mean accepting slightly lower recall rates or higher infrastructure costs due to the demands of maintaining up-to-date, fast, and relevant data.</p>
<p>\
On the other hand, in an <strong>offline analytical system</strong>, you may prioritize accuracy over latency, with batch processing and deeper analysis becoming the primary focus. Understanding how your use caseâ€™s priorities affect performance and architecture choices is vital.</p>
<p>\
<strong>So, how do we achieve the desired speed and accuracy within these constraints?</strong> This brings us squarely to the engine room of Vector Search.</p>
<h1 id="thecoreenginenearestneighborsearchalgorithms">The Core Engine: Nearest Neighbor Search Algorithms</h1>
<p>Vector search hinges on speed â€” the ability to quickly scan a dataset and calculate the similarity between vectors. At the core of this task is Nearest Neighbor (NN) search. The goal is straightforward: given a query vector, find the vectors in your indexed dataset that are closest according to a chosen distance metric (such as Cosine Similarity or Euclidean Distance). ==There are multiple ways to perform nearest neighbor search==. Letâ€™s start with the most straightforward approach.</p>
<h2 id="fullscanbruteforceapproach">Full Scan (Brute Force Approach)</h2>
<p>Imagine we have a dataset of 1 million 1000-dimensional vectors and need to find similar vectors for a given query. A naive approach would compare the query vector to every single vectorsâ€” performing 1 billion operations (1M vectors * 1000 dimensions) per query.</p>
<p>\
Full scan is a brute-force method, sequentially checking every data point in the dataset to ensure it finds the absolute nearest neighbors. Itâ€™s simple to implement and doesnâ€™t require complex indexing. For smaller datasets â€” under a million vectors, especially those that donâ€™t change often â€” this approach may work fine and can even be a good starting point. It guarantees perfect recall.</p>
<p>\
However, as the dataset grows or if data freshness becomes crucial, the practicality of full scan quickly diminishes. Once you surpass the million-vector mark or need frequent updates, the computational cost of each query increases significantly. What was once an acceptable latency becomes a bottleneck, making it unsuitable for real-time or interactive applications.</p>
<p>\
<strong>Performance characteristics:</strong></p>
<ul>
<li><strong>Latency:</strong> O(nÃ—d) where n=number of vectors and d=dimensions</li>
<li><strong>Memory:</strong> O(nÃ—d) â€” requires full dataset in memory for optimal performance</li>
<li><strong>Accuracy:</strong> 100% recall (guaranteed to find true nearest neighbors)</li>
<li><strong>Build time:</strong> O(1) â€” no indexing required</li>
</ul>
<p>\
In my experience, relying solely on full scan for large, dynamic production systems is rarely a viable option. We need faster alternatives.</p>
<h2 id="approximatenearestneighborannalgorithms">Approximate Nearest Neighbor (ANN) Algorithms</h2>
<p>This is where Approximate Nearest Neighbor (ANN) algorithms enter the picture. ==ANN algorithms introduce approximations for dramatically improved speed==. Here are key approaches:</p>
<p>\
<strong>(1) Tree-based methods (KD-trees, Ball trees)</strong></p>
<p>These split the vector space into nested regions, so you donâ€™t have to search everything.</p>
<ul>
<li>Great for low-dimensional data (think â‰¤20 dimensions)</li>
<li>Struggle badly in high dimensions due to the â€œcurse of dimensionalityâ€</li>
<li>Best for small or structured datasets where exact partitioning pays off</li>
</ul>
<p>\
<strong>(2) Locality-Sensitive Hashing (LSH)</strong></p>
<p>This hashes vectors so that similar ones land in the same bucket more often than not.</p>
<ul>
<li>Scales well with both dimension count and dataset size</li>
<li>Doesnâ€™t need to scan the whole space</li>
<li>But: requires careful tuning of hash functions and thresholds to get good recall</li>
</ul>
<p>\
<strong>(3) Graph-based methods</strong></p>
<p>These build a graph where each node (vector) connects to its nearest neighbors â€” search becomes fast traversal.</p>
<ul>
<li><strong>HNSW (Hierarchical Navigable Small World):</strong> Builds a multi-layer graph to navigate large datasets efficiently</li>
<li><strong>NSG (Navigable Spreading-out Graph):</strong> Focuses on building a well-pruned graph to minimize hops and reduce search cost</li>
<li><strong>DiskANN:</strong> Optimized for billion-scale datasets, designed to run off SSDs instead of keeping everything in RAM</li>
</ul>
<p>\
The key advantage of ANN over brute-force search is its ability to handle large-scale datasets efficiently. Benchmarking results, such as those from <a href="https://ann-benchmarks.com/index.html">ANN-benchmarks</a>, consistently show this tradeoff: brute force provides the highest precision but supports fewer queries per second (QPS). ANN algorithms, on the other hand, enable much higher QPS, making them ideal for real-time systems â€” though thereâ€™s usually a slight reduction in recall, depending on the algorithm and how itâ€™s tuned.</p>
<p>\
 <img src="https://cdn.hackernoon.com/images/qK3Oc94UoaXVEpERoZrZAGvfAtD3-yp132sc.png" alt="Plots for glove-100-angular (k = 10) Recall/Queries per second (1/s) form ANN-benchmarks" /></p>
<p>\</p>
<h2 id="codeexamplefullscanvsann">Code Example: Full Scan vs. ANN</h2>
<p>To make these concepts more concrete, letâ€™s demonstrate a basic comparison between a full scan (linear search) and an ANN approach using the IVFFlat index using the popular <a href="https://github.com/facebookresearch/faiss">Faiss library</a>.</p>
<p>\</p>
<pre><code class="javascript language-javascript">import numpy as np
import faiss
import time

# 1. Create a synthetic dataset
num_vectors = 1000000  # One million vectors
vector_dim = 1000      # 1000 dimensions
print(f"Creating dataset with {num_vectors} vectors of dimension {vector_dim}...")
dataset = np.random.rand(num_vectors, vector_dim).astype('float32')

# 2. Define a sample query vector
query_vector = np.random.rand(vector_dim).astype('float32')
query_vector_reshaped = query_vector.reshape(1, vector_dim)

# --- Linear Scan (Full Scan) Example ---
print("\n--- Linear Scan (using IndexFlatL2) ---")

# 3. Create a Faiss index for exact L2 distance search (Full Scan)
index_flat = faiss.IndexFlatL2(vector_dim)

# 4. Add the dataset vectors to the index
print("Adding vectors to IndexFlatL2...")
index_flat.add(dataset)
print(f"Index contains {index_flat.ntotal} vectors.")

# 5. Perform the search
print("Performing linear scan search...")
start_time = time.time()
distances_flat, indices_flat = index_flat.search(query_vector_reshaped, k=1)
end_time = time.time()

# On typical hardware, this might take 1-2 seconds for this dataset size
print(f"Linear scan time: {end_time - start_time:.4f} seconds")
print(f"Nearest neighbor index (Linear): {indices_flat[0][0]}, Distance: {distances_flat[0][0]}")

# --- Approximate Nearest Neighbor (ANN) Example ---
print("\n--- ANN Scan (using IndexIVFFlat) ---")

# 6. Define and create an ANN index (IVFFlat)
# IVF1024 partitions the data into 1024 clusters (voronoi cells)
nlist = 1024  # Number of clusters/cells
quantizer = faiss.IndexFlatL2(vector_dim)
index_ivf = faiss.IndexIVFFlat(quantizer, vector_dim, nlist)

# 7. Train the index on the dataset (learns the cluster centroids)
# This is a one-time operation that can be slow but improves query performance
print(f"Training IndexIVFFlat with {nlist} clusters...")
index_ivf.train(dataset)
print("Training complete.")

# 8. Add the dataset vectors to the trained index
print("Adding vectors to IndexIVFFlat...")
index_ivf.add(dataset)
print(f"Index contains {index_ivf.ntotal} vectors.")

# 9. Perform the ANN search
# nprobe controls search accuracy vs. speed tradeoff
# Higher values = better recall but slower search
index_ivf.nprobe = 10  # Search within the 10 nearest clusters
print(f"Performing ANN search (nprobe={index_ivf.nprobe})...")
start_time = time.time()
distances_ivf, indices_ivf = index_ivf.search(query_vector_reshaped, k=1)
end_time = time.time()

# On typical hardware, this might take 10-20ms - about 100x faster than brute force
print(f"ANN scan time: {end_time - start_time:.4f} seconds")
print(f"Nearest neighbor index (ANN): {indices_ivf[0][0]}, Distance: {distances_ivf[0][0]}")

# Expected recall rate at nprobe=10 is approximately 90-95%
# To verify, we could compute overlap between exact and approximate results
</code></pre>
<p>\
In this example we first create a large dataset of random vectors. We use <strong>IndexFlatL2</strong> for the linear scan. This index simply stores all vectors and compares the query to each one during search â€” our brute-force baseline.</p>
<p>\
Next, we switch to <strong>IndexIVFFlat</strong>, a common ANN technique. This involves an extra training step where the index learns the structure of the data partitioning it into cells (or Voronoi cells). During the search, the nprobe parameter determines how many partitions are checked, allowing the algorithm to intelligently sample only a subset of the data, significantly reducing the number of comparisons needed.</p>
<p>Running this code (actual times depend heavily on hardware) typically demonstrates that the ANN search (<strong>IndexIVFFlat</strong>), despite the initial training overhead, performs the search operation significantly faster than the linear scan (<strong>IndexFlatL2</strong>), highlighting the practical speed advantage of ANN methods for large datasets.</p>
<p>\
However, itâ€™s important to note that <code>different ANN implementations come with their own optimization tradeoffs</code>. IndexIVFFlat is just one option, and selecting the right method involves evaluating tradeoffs in speed, accuracy, memory usage, and indexing time. Each approach has its strengths, so benchmarking various methods is crucial for finding the optimal balance based on your dataset and query patterns.</p>
<h1 id="reducingmemoryfootprintquantization">Reducing Memory Footprint: Quantization</h1>
<p>As vector datasets grow massive, memory consumption becomes a significant challenge, especially when dealing with millions or billions of high-dimensional vectors. When the dataset exceeds the available RAM on a single machine, engineers often resort to sharding the index across multiple machines, introducing operational complexity and increasing infrastructure costs.</p>
<p>\
One effective solution to this problem is quantization, ==a technique designed to reduce memory footprint by compressing the vector data==. The goal is to represent high-precision floating-point vectors with less data, typically using methods that map continuous values to a smaller set of discrete representations. By doing so, quantization reduces storage space requirements, which can help fit large indexes onto fewer machines or even a single machine. There are several approaches to vector quantization, with three common types being:</p>
<p>\
<strong>(1) Scalar Quantization</strong></p>
<p>This technique reduces the precision of each dimension in a vector. Instead of using high-precision 32-bit floats, each dimension may be stored using fewer bits, like 8-bit integers. SQ offers a solid balance between compression, search accuracy, and speed, making it a popular choice for reducing memory usage.</p>
<p>\
<strong>Performance impact:</strong></p>
<ul>
<li><strong>Memory reduction:</strong> 4x (32-bit â†’ 8-bit)</li>
<li><strong>Speed impact:</strong> Minimal (sometimes faster due to reduced memory bandwidth)</li>
<li><strong>Accuracy impact:</strong> Typically 1â€“3% recall reduction</li>
<li><strong>Use case:</strong> Good general-purpose option for initial memory optimization</li>
</ul>
<p>\
<strong>(2) Binary Quantization</strong></p>
<p>Takes compression further by representing vector components with binary codes, often using just 1 bit per component or group of components. This results in high compression and very fast distance calculations (e.g., Hamming distance). However, BQ can lead to significant information loss, which can reduce accuracy, so it is best suited for cases where speed is critical and the data is well-suited for binary representation.</p>
<p>\
<strong>Performance impact:</strong></p>
<ul>
<li><strong>Memory reduction:</strong> 8â€“64x depending on configuration</li>
<li><strong>Speed impact:</strong> Complex distance calculations can be slower</li>
<li><strong>Accuracy impact:</strong> 5â€“15% recall reduction (configuration dependent)</li>
<li><strong>Use case:</strong> Large-scale systems where memory is the primary constraint</li>
</ul>
<p>\
<strong>(3) Product Quantization</strong></p>
<p>This technique takes a different approach. It splits each high-dimensional vector into smaller sub-vectors, which are quantized independently using clustering techniques like k-means. Each sub-vector is represented by a code from a codebook, leading to substantial compression. While PQ achieves low memory usage, the process of calculating distances and performing searches can be more computationally intensive than SQ, resulting in slower query times and possibly lower accuracy at similar compression levels.</p>
<p>\
<strong>Performance impact:</strong></p>
<ul>
<li><strong>Memory reduction:</strong> 32x compared to 32-bit floats</li>
<li><strong>Speed impact:</strong> Very fast using hamming distance calculations</li>
<li><strong>Accuracy impact:</strong> Significant (20%+ recall reduction)</li>
<li><strong>Use case:</strong> Ultra-high throughput applications where speed trumps perfect accuracy</li>
</ul>
<p>\
==Quantization techniques are often used in conjunction with ANN search methods==, not as alternatives. For instance, Faiss indexes like IndexIVFPQ combine an IVF structure (for fast candidate selection using ANN) with Product Quantization (to compress the vectors within each list). This hybrid approach enables the creation of high-performance vector search pipelines that efficiently handle large datasets in both speed and memory. Selecting the right quantization strategy, like choosing the optimal ANN method, requires understanding the tradeoffs and aligning them with your systemâ€™s needs and data characteristics.</p>
<h1 id="filteringstrategies">Filtering Strategies</h1>
<p>In most real-world scenarios, combining vector similarity with metadata filtering is essential. Think about queries like â€œfind similar products that are in stock and under $50.â€ This hybrid search presents its own set of challenges:</p>
<h2 id="filteringapproaches">Filtering Approaches</h2>
<p><strong>(1) Pre-filtering</strong></p>
<p>This approach filters the data based on metadata before diving into vector similarity. It works best when the metadata filter is highly selective (e.g., finding products under $50). This requires an integrated approach, where both vectors and metadata are indexed together.</p>
<p>\
<strong>Example</strong>: You first filter out products that are under $50, then compute the similarity only on the subset that meets that criterion.</p>
<p>\
<strong>(2) Post-filtering</strong></p>
<p>With post-filtering, you perform the vector similarity search first, then apply your metadata filters afterward. This is a solid option when the metadata filter isnâ€™t particularly selective. The downside? It can get inefficient when working with large datasets that have strict filters.</p>
<p>\
<strong>Example</strong>: Find the top 1000 similar products, then narrow them down to those under $50.</p>
<p>\
<strong>(3) Hybrid filtering</strong></p>
<p>Hybrid filtering strikes a balance â€” using metadata to reduce the search space before fine-tuning it with vector search. This approach often uses a combination of inverted indexes and vector indexes to get the best of both worlds. Itâ€™s usually the most efficient and flexible option for most applications.</p>
<p>\
<strong>Example</strong>: Use metadata (like category and price range) to limit the search space, then zero in on the best matching vectors.</p>
<h2 id="implementationstrategies">Implementation Strategies</h2>
<p><strong>(1) Inverted Index + Vector Index</strong></p>
<p>With this strategy, you create separate indexes for metadata and vectors. First, the metadata index helps you identify a smaller set of candidates. Then, you apply the vector search only to those candidates, saving time. This method is ideal when your filters are really selective.</p>
<p>\
<strong>(2) Joint Indexing</strong></p>
<p>Here, you combine metadata directly into the vector index. Imagine IVF clusters that also include metadata attributes. This enables the system to efficiently prune irrelevant candidates during the search. Joint indexing works best when thereâ€™s a close relationship between metadata and vector similarity.</p>
<p>\
<strong>(3) Filter-Aware ANN</strong></p>
<p>This method goes deeper by modifying the ANN algorithm itself to take the metadata filter into account during graph traversal. Itâ€™s a bit more complex but can significantly speed up your queries. More and more vector databases are starting to offer this as a built-in feature, making it easier to implement at scale.</p>
<h1 id="keyaccesspatterns">Key Access Patterns</h1>
<p>How your application accesses vector data has a major impact on performance, storage design, and overall system architecture. Matching the access pattern to the needs of your application is key to building an efficient retrieval system. Letâ€™s examine some common patterns.</p>
<h2 id="staticinmemoryaccess">Static In-Memory Access</h2>
<p>One of the most straightforward access patterns for vector search is static in-memory access. This approach is ideal when working with relatively small datasets â€” typically under a million vectors â€” that donâ€™t change frequently. In this setup, the entire vector index is loaded into memory at application startup. Because all vector comparisons happen locally within the process, thereâ€™s no need to communicate with external storage during queries. The result is extremely fast retrieval, with minimal system complexity.</p>
<p>\
Static in-memory access is well-suited for use cases that demand low-latency responses and can fit their vector data comfortably within a single machineâ€™s RAM. Itâ€™s a practical choice when the dataset is small and stable, and simplicity and speed are top priorities.</p>
<p>\
<strong>Implementation Considerations</strong></p>
<ul>
<li>For lightweight setups â€” say, under 100,000 vectors â€” NumPy might be enough. It allows for efficient in-memory operations like cosine similarity using simple arrays. This is a good option when query complexity is low and performance needs are modest.</li>
<li>As datasets approach the million-vector range, performance demands tend to increase. In those cases, libraries like Faiss offer more efficient indexing and similarity search, including support for ANN and quantization, while still operating entirely in memory.</li>
<li>If your application needs to filter by metadata alongside vector similarity â€” or if your in-memory dataset is large but still fits in RAM â€” tools like LanceDB or Chroma can be a better fit. These â€œin-process vector databasesâ€ run inside your application, combining the speed of local memory access with the structure and flexibility of a database, without the overhead of network calls.</li>
</ul>
<p>\
<strong>Service Restart Implications</strong></p>
<p>One downside of this pattern is what happens when the service restarts. Because all data lives in memory, the full vector dataset must be reloaded on startup. This can introduce noticeable delays, especially with large indexes, and temporarily impact system availability during initialization. If startup time is critical, youâ€™ll need to account for this when designing your deployment strategy.</p>
<h2 id="dynamicaccess">Dynamic Access</h2>
<p>Dynamic access patterns are built for production-scale systems where vector datasets are too large or too volatile for static in-memory approaches. This becomes especially important when working with more than a million vectors or when embeddings are constantly being added, updated, or replaced â€” like in use cases involving live sensor data, real-time user behavior, or streaming analytics.</p>
<p>\
Unlike static setups, where data is loaded and held in memory, dynamic access offloads storage and retrieval to external vector databases or search engines. These systems are purpose-built for handling high-dimensional data at scale, offering features like persistent storage, incremental updates, and real-time indexing. Theyâ€™re designed to maintain responsiveness even as data evolves rapidly.</p>
<p>\
Different categories of systems support dynamic access, each with its own performance characteristics and tradeoffs. Choosing the right one depends on your specific requirements â€” data volume, query patterns, latency tolerance, and operational complexity</p>
<p>\</p>
<ol>
<li><p><strong>Vector-Native Vector Databases</strong> (e.g., <a href="https://weaviate.io/">Weaviate</a>, <a href="https://www.pinecone.io/">Pinecone</a>, <a href="https://zilliz.com/what-is-milvus">Milvus</a>, <a href="https://vespa.ai/">Vespa</a>, <a href="https://qdrant.tech/">Qdrant</a>): are optimized specifically for storing, indexing, and conducting fast similarity searches on high-dimensional vector data. Their design focuses on vector operations, making them highly efficient for this purpose. However, they may lack the comprehensive features found in general-purpose databases for handling traditional structured or unstructured data.</p></li>
<li><p><strong>Hybrid Databases</strong> (e.g., <a href="https://www.mongodb.com/">MongoDB Atlas Vector Search</a>, <a href="https://github.com/pgvector/pgvector/">PostgreSQL with pgvector</a>, <a href="https://redis.io/blog/rediscover-redis-for-vector-similarity-search/">Redis with redis-vss</a>): are well-established databases (NoSQL, relational, key-value) that have incorporated vector search through extensions or built-in features. They offer the benefit of managing both vector and traditional data types in one system, providing flexibility for applications that require both. However, their vector search performance may not always match the specialized capabilities of vector-native databases.</p></li>
<li><p><strong>Search Tools with Vector Capabilities</strong> (e.g., <a href="https://www.elastic.co/">Elasticsearch</a>, <a href="https://opensearch.org/">OpenSearch</a>): originally built for text search and log analytics, these search engines have integrated vector search features. For organizations already using them, this enables the possibility of leveraging existing infrastructure for both text and vector similarity searches. However, their vector search performance and available algorithms might not be as specialized or efficient as those found in dedicated vector databases.</p>
<p><img src="https://cdn.hackernoon.com/images/qK3Oc94UoaXVEpERoZrZAGvfAtD3-ex4328n.png" alt="Side-by-side comparison of each database typeâ€™s pros and cons" /></p></li>
</ol>
<p>\</p>
<h1 id="batchaccess">Batch Access</h1>
<p>While dynamic access focuses on live queries against constantly changing data, batch access is the go-to pattern for handling ==large vector datasets that require offline, non-real-time processing==. This approach is ideal when dealing with massive datasets (usually over one million vectors) where queries are processed in large, collective batches rather than interactively.</p>
<p>\
Batch processing is particularly valuable for foundational Vector Management tasks critical for efficient Vector Search services, such as:</p>
<ul>
<li><strong>Initial index building</strong> for very large datasets.</li>
<li><strong>Periodic model training or retraining</strong> using vector representations.</li>
<li><strong>Precomputing nearest neighbors</strong> or other analyses across the entire dataset.</li>
<li><strong>Data cleaning, transformation, or enrichment</strong> tasks applied to vectors in bulk.</li>
</ul>
<p>\
To optimize batch processing for your application, itâ€™s crucial to consider several factors:</p>
<p>\
<strong>(1) Storage Technologies</strong></p>
<p>Reliable storage is essential for housing large vector datasets and ensuring they are accessible for batch processing. The choice of storage technology impacts scalability, access speed, and integration with processing pipelines. Below are some common options:</p>
<ul>
<li><strong>Object Storage</strong> (e.g., Amazon S3, Google Cloud Storage, Azure Blob Storage): This storage solution is highly scalable and cost-effective, making it suitable for storing large, static vector sets. It integrates well with cloud-based processing engines like Spark and Flink. However, its primary drawback is higher access latency compared to file systems, making it less ideal for I/O-intensive operations that require rapid, low-latency reads or writes. Object storage is best suited for data at rest rather than real-time processing.</li>
<li><strong>Distributed File Systems</strong> (e.g., HDFS, GlusterFS): These systems are designed for storing massive datasets across multiple servers, offering high-throughput access ideal for big data frameworks like Hadoop and Spark. They provide data redundancy and are optimized for sequential reads. However, they come with the complexity of setup, management, and maintenance, which can be more cumbersome than managed cloud object storage solutions.</li>
</ul>
<p>\
<strong>(2) Data Serialization Formats</strong></p>
<p>To store vectors efficiently for batch processing, itâ€™s crucial to select data formats that reduce storage space and enable fast read/write operations. Here are two commonly used serialization formats:</p>
<ul>
<li><strong>Avro and Parquet</strong>: These are binary serialization formats widely used in the big data ecosystem (e.g., Hadoop, Spark). Both offer excellent compression and support schema evolution, which is particularly useful if vector dimensions or metadata change over time. Avro is typically preferred for row-oriented operations or write-heavy workloads, while Parquet, with its columnar format, is optimized for read-heavy analytical queries, which is ideal for batch processing jobs. These formats also integrate seamlessly with distributed processing engines and cloud storage, making them versatile options for large-scale data operations.</li>
<li><strong>Compressed NumPy Arrays</strong>: For simpler, Python-based pipelines, serializing NumPy arrays using formats like .npz or custom serialization with compression libraries such as zlib or lz4 is an effective approach. This method is particularly useful in scientific Python environments and integrates easily with libraries like NumPy and SciPy. However, it may not be as portable or performant for large-scale, multi-language environments, where formats like Parquet would typically offer better scalability and performance.</li>
</ul>
<p>\
<strong>(3) Execution Environment</strong></p>
<p>When choosing where and how your batch jobs will run, you must decide between self-managed infrastructure and cloud services:</p>
<ul>
<li><p><strong>On-Premise Execution</strong>: Using tools like Apache Hadoop or Apache Spark on your own infrastructure gives you complete control over the environment, security, and configuration. However, this comes with significant costs related to infrastructure setup, maintenance, and the need for operational expertise. Additionally, scaling resources can be less flexible and more complex compared to cloud solutions.</p></li>
<li><p><strong>Cloud Services</strong>: Platforms like Amazon EMR, Google Cloud Dataproc, or Azure HDInsight provide managed batch processing solutions based on popular frameworks like Spark. These services abstract away much of the infrastructure management, offering scalability on a pay-as-you-go basis and easy integration with other cloud services, such as object storage. The tradeoff here is that you may lose some fine-grained control over your environment and could face potential vendor lock-in.</p>
<p><img src="https://cdn.hackernoon.com/images/qK3Oc94UoaXVEpERoZrZAGvfAtD3-9z232yd.png" alt="Chosing a batch processing setup" /></p></li>
</ul>
<p>\
In summary, choosing the right storage technology, data serialization format, and execution environment for batch vector processing is a complex decision. It depends on factors like:</p>
<p>\</p>
<ul>
<li>The size of your vector dataset.</li>
<li>Whether the data is static or dynamic (i.e., how often it changes).</li>
<li>Scalability needs for your workloads.</li>
<li>Whether the dataset is distributed across multiple servers.</li>
<li>The requirement (or lack thereof) for real-time querying alongside batch jobs.</li>
<li>Integration needs with other big data processing tools or frameworks.</li>
<li>The level of control you need over the processing environment.</li>
<li>Available resources (time, budget, expertise) for setup and maintenance.</li>
</ul>
<h1 id="conclusionbuildingeffectivevectorsearchsystems">Conclusion: Building Effective Vector Search Systems</h1>
<p>As weâ€™ve discussed, Vector Search &amp; Management is the critical operational layer that transforms abstract embeddings into valuable applications. By systematically addressing the three pillars of our framework â€” access patterns, performance requirements, and data characteristics â€” you can build systems that deliver both technical excellence and business value.</p>
<h2 id="puttingitalltogetherkeyimplementationchecklist">Putting It All Together: Key Implementation Checklist</h2>
<p><strong>(1) Define clear requirements:</strong></p>
<ul>
<li>Document latency, throughput, and recall targets</li>
<li>Establish update frequency needs</li>
<li>Identify filtering and querying patterns</li>
</ul>
<p>\
<strong>(2) Choose appropriate architecture:</strong></p>
<ul>
<li>Select access pattern (static, dynamic, batch)</li>
<li>Determine vector database or storage solution</li>
<li>Design for appropriate scale and growth</li>
</ul>
<p>\
<strong>(3) Optimize for your use case:</strong></p>
<ul>
<li>Select and tune ANN algorithms</li>
<li>Implement appropriate quantization</li>
<li>Design efficient filtering strategies</li>
</ul>
<p>\
<strong>(4) Implement comprehensive evaluation:</strong></p>
<ul>
<li>Establish quality metrics baseline</li>
<li>Monitor system performance</li>
<li>Track business impact metrics</li>
</ul>
<p>\
<strong>(5) Plan for operational excellence:</strong></p>
<ul>
<li>Design for observability</li>
<li>Implement error handling</li>
<li>Create testing and validation framework</li>
</ul>
<p>\
In the next part of The AI Engineerâ€™s Playbook, weâ€™ll explore how to effectively leverage these vector capabilities in real-world AI applications.</p>]]></content:encoded>
            <media:thumbnail url="https://hackernoon.com/https://cdn.hackernoon.com/images/qK3Oc94UoaXVEpERoZrZAGvfAtD3-v5532zy.jpeg"/>
        </item>
        <item>
            <title><![CDATA[Coding Yourself Into Oblivion? Why Devs Burn Out and How to Fight Back]]></title>
            <description><![CDATA[Nearly three-quarter of developers have been in my shoes at one point in their careers. Burnout doesnâ€™t just sneak up on people overnight. It all starts with the constant tiredness. The work name was Cyborg.]]></description>
            <link>https://hackernoon.com/coding-yourself-into-oblivion-why-devs-burn-out-and-how-to-fight-back?source=rss</link>
            <guid isPermaLink="true">https://hackernoon.com/coding-yourself-into-oblivion-why-devs-burn-out-and-how-to-fight-back?source=rss</guid>
            <category><![CDATA[programming]]></category>
            <category><![CDATA[life-hack]]></category>
            <category><![CDATA[developer-burnout]]></category>
            <category><![CDATA[burnout]]></category>
            <category><![CDATA[how-to-avoid-burnout]]></category>
            <category><![CDATA[work-related-burnout]]></category>
            <category><![CDATA[avoiding-burnout]]></category>
            <category><![CDATA[types-of-burnout]]></category>
            <dc:creator><![CDATA[Dilip Kumar R]]></dc:creator>
            <pubDate>Sat, 12 Apr 2025 14:29:40 GMT</pubDate>
            <image/>
            <content:encoded><![CDATA[<p>Developers like to engage in an unhealthy cycle of overworking, burning out, yet persisting until we eventually break down.</p>
<p>\
<em>Oh, just take some time off, and youâ€™ll feel better.</em></p>
<p>\
I wish it were as easy as taking a week break from coding. But taking a short breath of air before lounging back into the deep end only changes nothing.</p>
<p>\
Developersâ€™ burnout can make you rethink your career. Then, loathe what you were once passionate about, and sadly, almost end your career. I was at the 3rd stage until I stumbled upon a picture I took years ago when I was a junior developer. I saw my old self. I saw that excitement and passion in my eyes.</p>
<p>\
It had an Aha moment: I realized that I never stopped loving my job. I just needed to discover why burnout was stopping me from loving it. <strong><a href="https://pure.rug.nl/ws/portalfiles/portal/563561771/1_s2.0_S0950584922002257_main.pdf">Nearly three-quarter of developers</a></strong> have been in my shoes at one point in their careers.</p>
<p>\
How can we solve this problem? By knowing its cause and learning the cheat code to work sustainably. Thankfully, the answers are all in this read. Letâ€™s journey together.</p>
<p>\</p>
<h2 id="allthewarningsignshasalwaysbeenthere">All The Warning Signs Has Always Been There</h2>
<p><img src="https://cdn.hackernoon.com/images/7B888Pid8udwG6yLX9As9M0rkBT2-2025-04-12T14:29:31.032Z-hvqgg59buchjdep0xh7fia5m" alt="" /></p>
<p>\
No one really looks forward to Mondays during the weekend. However, what you and I felt on that weekend was something different. Dread. That weekend passed in a blur and that Monday morning came.</p>
<p>\
Surprisingly, the excitement that came with opening the laptop was gone. Vanished into thin air.</p>
<p>\
How did we get here?</p>
<p>\</p>
<ol>
<li>The physical signs</li>
</ol>
<p>Well, burnout doesnâ€™t just sneak up on people overnight. You just didnâ€™t spot the silent productivity killer in time. It all starts with the constant tiredness. You dismissed it despite â€œgrinding all nightâ€ twice in a week, every week.&nbsp;</p>
<p>\
Then, thereâ€™s that feeling of exhaustion thatâ€™s never cured with cups of coffee and energy drinks. Yet, you ignored the red flags. You kept hoping your willpower would keep you afloat.</p>
<p>\
Little did you know that your brain was hitting cognitive fatigue. It was at that moment the work signs started to creep in.</p>
<p>\</p>
<ol start="2">
<li>The work signs</li>
</ol>
<p>\
You thought your middle name was Cyborg?</p>
<p>\
A 20 minutes of coding suddenly started taking an hour to get done? That was the rude awakening that you didnâ€™t see coming. In no time, your output dropped, and you started missing obvious errors.</p>
<p>\
Still, you couldnâ€™t read the signs on the wall. Until frustration starts to set in. Guess what? You are still oblivious to the real issue. You believe that you are the problem. Sadly, you donâ€™t realize that the machine isnâ€™t broken; itâ€™s overheating.</p>
<p>\
That Monday morning came, you woke up, and programming felt like a chore. You werenâ€™t fulfilled by the ability to write clean code anymore. You just wanted the day to be over and done with. This crash corroborates the <strong><a href="https://www.degruyter.com/document/doi/10.1525/9780520975347-005/pdf?licenseType=restricted&srsltid=AfmBOorLg_-x2IFpKb-uTXxH5mSGpbremD0j_je0N-O1QSLN7KZoTG2u">three classic burnout signs: total burnout, cynicism at work, and feeling ineffective.</a></strong></p>
<p>\
Itâ€™s time to completely change how we work as software developers.</p>
<p>\
Just like you, I was ready for some change. So, I took the first step on my journey to working sustainably. The first step was to discover why I was burning out. Amidst my quest to change my life, I discovered something. I found out that I and my fellow developers were also experiencing burnout. But, what was shocking was how our whys were almost similar.</p>
<p>\
Having gleaned from them, Iâ€™ll be discussing the major reasons why software developers burn out. Be rest assured that Iâ€™ll chip in workable solutions that you would find helpful.</p>
<h2 id="whymostsoftwaredevelopersburnout">Why Most Software Developers Burn Out</h2>
<ol>
<li>Zero workday boundaries</li>
</ol>
<p>\
The line between work and personal life in the tech community today is almost invisible. Today, tech companies have done a fantastic job of making being&nbsp; â€œalways availableâ€ a badge of honour. Many software developers hop on a call by 11pm to quickly fix a bug.</p>
<p>\
Of course no job description would state that you have to work 24/7, but in reality, itâ€™s different. You actually might spend almost all your day working on tasks. Itâ€™s tiring and you loathe it. You want to draw a firm boundary, but donâ€™t want to risk not looking like a team player. And letâ€™s not start with how some tech companies try to sugarcoat it as being â€œflexible.â€</p>
<p>\
My 2 Cents:</p>
<p>\
It all starts with you. Do your due diligence with writing and deploying your code. A clean code means no bugs to fix. Be meticulous so that you wonâ€™t sacrifice your rest time to correct work errors. If you still get called to meetings outside work hours, you need to create boundaries. Itâ€™s high time you set non-negotiable work hours and work communication clearly.</p>
<p>\
Proceed to use your device Do-Not-Disturb feature and status updates to signal that you are offline. If late-night call requests creep in, do well to professionally decline. If itâ€™s necessary, at most, offer a response time that aligns with your boundaries.</p>
<p>\</p>
<ol start="2">
<li>Doubling your workload</li>
</ol>
<p>\
Imposter syndrome has nothing on you. You know that you are a smart software developer that can do anything you set your mind to. However, that shouldnâ€™t be the go sign to take on a lot of projects. On another hand, there are a number of reasons developers take on a lot of tasks at once. It could be because thereâ€™s a debt or family need that requires being sorted. Or, you want to prove yourself at work for a promotion.</p>
<p>\
Sometimes, taking on more workload might look like learning new languages and frameworks to upgrade oneâ€™s game. These workloads might not be optional, but crucial to career survival. However, at the same time, overworking oneself can lead to breakdown. And breakdown cuts down productivity, creativity, and decision-making.</p>
<p>\
How does one solve this dilemma?</p>
<p>\
My 2 Cents:</p>
<p>\
Working hard shouldnâ€™t come at the cost of your wellbeing. Even if itâ€™s necessary to take on a lot of work at the moment, learn to work smart. If you are working in a team, delegate tasks. If you are working solo, consider outsourcing. Also, listen to your body whenever it signals tiredness. Take rest, eat well, drink water, and take a walk.</p>
<p>\</p>
<ol start="3">
<li>Setting Unrealistic Deadlines</li>
</ol>
<p>\
Project timelines are way too optimistic. Everyone believes it would all go smoothly. â€˜â€™Oh, weâ€™ll get this done in no time.â€ Sike! Itâ€™s 3 days to the deadline and you havenâ€™t even gotten to the hardest part.</p>
<p>\
<strong><a href="https://www.sciencedirect.com/science/article/pii/S0950584922002257?utm_source=chatgpt.com">More than half of developers have revealed that burnout in the industry has caused their colleagues to quit.</a></strong> Cause? Unrealistic deadlines. Nothing drains a software developer like being expected to perform miracles under a tight time constraint. What is worse is being the one who promised to make that miracle happen.</p>
<p>\
Itâ€™s simple â€“ set realistic deadlines. When estimating the delivery timeline, double your initial guess. Always factor in a buffer period. That extra time would cater to unexpected bugs, mental fatigue, and any roadblock. Also, donâ€™t promise a deadline you canâ€™t fulfil. Itâ€™s better to request for extra time upfront than to disappoint with a failed promise.</p>
<h2 id="finalthoughts">Final Thoughts</h2>
<p><img src="https://cdn.hackernoon.com/images/7B888Pid8udwG6yLX9As9M0rkBT2-2025-04-12T14:29:31.035Z-o9uxy62opvi7estj69z38ycr" alt="" /></p>
<p>\
Burnout is not a sign of personal failure. Burnout is not a sign of weakness, neither is it about lacking passion or discipline. Itâ€™s not something that can be fixed by a vacation or by gaming all day, week-long.</p>
<p>\
Burnout means thereâ€™s a broken system somewhere. And you must identify the source to fix the problem. You must fix it because you are first human before anything else. And thatâ€™s more important than any line of code you can ever write.</p>]]></content:encoded>
            <media:thumbnail url="https://hackernoon.com/https://cdn.hackernoon.com/images/2jqChkrv03exBUgkLrDzIbfM99q2-r502ufh.gif.webp"/>
        </item>
        <item>
            <title><![CDATA[Seeing With Less: MindEye2's Efficient Approach to Brain-Based Image Decoding]]></title>
            <description><![CDATA[We introduce MindEye2, a modeling approach that outputs reconstructions of seen images from fMRI activity with a similar quality to previous approaches using only a fraction of the training data.]]></description>
            <link>https://hackernoon.com/seeing-with-less-mindeye2s-efficient-approach-to-brain-based-image-decoding?source=rss</link>
            <guid isPermaLink="true">https://hackernoon.com/seeing-with-less-mindeye2s-efficient-approach-to-brain-based-image-decoding?source=rss</guid>
            <category><![CDATA[mindeye2]]></category>
            <category><![CDATA[what-is-mindeye2]]></category>
            <category><![CDATA[stable-diffusion-xl]]></category>
            <category><![CDATA[fmri]]></category>
            <category><![CDATA[clip-embedding]]></category>
            <category><![CDATA[real-time-analysis]]></category>
            <category><![CDATA[neurological-conditions]]></category>
            <category><![CDATA[generative-models]]></category>
            <dc:creator><![CDATA[Image Recognition]]></dc:creator>
            <pubDate>Sat, 12 Apr 2025 14:15:02 GMT</pubDate>
            <image/>
            <content:encoded><![CDATA[<h2 id="tableoflinks">Table of Links</h2>
<p><a href="http://hackernoon.com/preview/R9eFEKJ5IDkCAlBD7hRM">Abstract and 1 Introduction</a></p>
<p><a href="http://hackernoon.com/preview/WrRCH1Q7j0tPiNaEjcjl">2 MindEye2 and 2.1 Shared-Subject Functional Alignment</a></p>
<p><a href="http://hackernoon.com/preview/43IQ15kC5GT8ZzB5Ac93">2.2 Backbone, Diffusion Prior, & Submodules</a></p>
<p><a href="https://hackernoon.com/preview/V7Xlu9Aj7fudpUz7F5e2">2.3 Image Captioning and 2.4 Fine-tuning Stable Diffusion XL for unCLIP</a></p>
<p><a href="http://hackernoon.com/preview/VWnzotYJIrve8rue7yys">2.5 Model Inference</a></p>
<p><a href="http://hackernoon.com/preview/ybUS0wbjWBHorMaHjq8w">3 Results and 3.1 fMRI-to-Image Reconstruction</a></p>
<p><a href="http://hackernoon.com/preview/8U5zw7VvVGBlm6EVvJkf">3.2 Image Captioning</a></p>
<p><a href="https://hackernoon.com/preview/nL0dr8eHyyB1uj7v4QLn">3.3 Image/Brain Retrieval and 3.4 Brain Correlation</a></p>
<p><a href="https://hackernoon.com/preview/H5Zg5Qk2R8tBWMyRqxN3">3.5 Ablations</a></p>
<p><a href="http://hackernoon.com/preview/9vQfuhMLSTOZIwuAlXXl">4 Related Work</a></p>
<p><a href="http://hackernoon.com/preview/zAtquGj9lVXGOGwVkBqj">5 Conclusion</a></p>
<p><a href="https://hackernoon.com/preview/0pJs6tFJxzLXosdJ1QjU">6 Acknowledgements and References</a></p>
<p>\
<strong>A Appendix</strong></p>
<p><a href="https://hackernoon.com/preview/gsJteW8tRfrz4BQNVqAw">A.1 Author Contributions</a></p>
<p><a href="http://hackernoon.com/preview/UFIcjVJiKPfIlxoz8cl5">A.2 Additional Dataset Information</a></p>
<p><a href="http://hackernoon.com/preview/9ABC3Nx2Qr1rCIdMRjqP">A.3 MindEye2 (not pretrained) vs. MindEye1</a></p>
<p><a href="https://hackernoon.com/preview/2vxlCKH83DDhqAZHBVEs">A.4 Reconstruction Evaluations Across Varying Amounts of Training Data</a></p>
<p><a href="http://hackernoon.com/preview/A1qmOAqItn7heYFSX6rN">A.5 Single-Subject Evaluations</a></p>
<p><a href="http://hackernoon.com/preview/ERW9W6T0ySAPJ5hOkfrI">A.6 UnCLIP Evaluation</a></p>
<p><a href="http://hackernoon.com/preview/d64sV3agwLREQ4ChYVrn">A.7 OpenCLIP BigG to CLIP L Conversion</a></p>
<p><a href="https://hackernoon.com/preview/dz9IOhRacI54zJ2PBHaq">A.8 COCO Retrieval</a></p>
<p><a href="http://hackernoon.com/preview/Hfovsm1E4vjvIsrrmW6j">A.9 Reconstruction Evaluations: Additional Information</a></p>
<p><a href="http://hackernoon.com/preview/pctgTmKppueLctm03X5D">A.10 Pretraining with Less Subjects</a></p>
<p><a href="http://hackernoon.com/preview/ymEQUDltvyCaiY4ZdrBS">A.11 UMAP Dimensionality Reduction</a></p>
<p><a href="https://hackernoon.com/preview/grNUbh1GQ1HsnXOERZYV">A.12 ROI-Optimized Stimuli</a></p>
<p><a href="https://hackernoon.com/preview/jjR7F5BChUj8AUsAq6n3">A.13 Human Preference Experiments</a></p>
<h2 id="5conclusion">5 Conclusion</h2>
<p>We introduce MindEye2, a modeling approach that outputs reconstructions of seen images from fMRI activity with a similar quality to previous approaches using only a fraction of the training data. MindEye2 further achieves SOTA across reconstruction and retrieval metrics when supplied with the full training data. Our approach pretrains a model using data from multiple subjects, which is then fine-tuned on scarce data from a held-out subject. Patterns of fMRI activity are mapped to CLIP space and images are reconstructed with the help of our unCLIP model fine-tuned from Stable Diffusion XL. Our work shows the potential to apply deep learning models trained on large-scale neuroimaging datasets to new subjects with minimal data.</p>
<h3 id="51limitations">5.1 Limitations</h3>
<p>fMRI is extremely sensitive to movement and requires subjects to comply with the task: decoding is easily resisted by slightly moving oneâ€™s head or thinking about unrelated information (Tang et al., 2023). MindEye2 has also only been shown to work on natural scenes such as those in COCO; additional data and/or specialized generative models would likely be required for other image distributions.</p>
<h3 id="52broaderimpacts">5.2 Broader Impacts</h3>
<p>The present work demonstrates that it is now practical for patients to undergo a single MRI scanning session and produce enough data to perform high-quality reconstructions of their visual perception. Such image reconstructions from brain activity are expected to be systematically distorted due to factors including mental state, neurological conditions, etc. This could potentially enable novel clinical diagnosis and assessment approaches, including applications for improved locked-in (pseudocoma) patient communication (Monti et al., 2010) and brain-computer interfaces if adapted to real-time analysis (Wallace et al., 2022) or non-fMRI neuroimaging modalities. As technology continues to improve, we note it is important that brain data be carefully protected and companies collecting such data be transparent with their use.</p>
<p>\</p>
<p>:::info
This paper is <a href="https://arxiv.org/abs/2403.11207">available on arxiv</a> under CC BY 4.0 DEED license.</p>
<p>:::</p>
<p>:::info
<strong>Authors:</strong></p>
<p>(1) Paul S. Scotti, Stability AI and Medical AI Research Center (MedARC);</p>
<p>(2) Mihir Tripathy, Medical AI Research Center (MedARC) and a Core contribution;</p>
<p>(3) Cesar Kadir Torrico Villanueva, Medical AI Research Center (MedARC) and a Core contribution;</p>
<p>(4) Reese Kneeland, University of Minnesota and a Core contribution;</p>
<p>(5) Tong Chen, The University of Sydney and Medical AI Research Center (MedARC);</p>
<p>(6) Ashutosh Narang, Medical AI Research Center (MedARC);</p>
<p>(7) Charan Santhirasegaran, Medical AI Research Center (MedARC);</p>
<p>(8) Jonathan Xu, University of Waterloo and Medical AI Research Center (MedARC);</p>
<p>(9) Thomas Naselaris, University of Minnesota;</p>
<p>(10) Kenneth A. Norman, Princeton Neuroscience Institute;</p>
<p>(11) Tanishq Mathew Abraham, Stability AI and Medical AI Research Center (MedARC).</p>
<p>:::</p>
<p>\</p>]]></content:encoded>
            <media:thumbnail url="https://hackernoon.com/https://cdn.hackernoon.com/images/brain-activity-abstract-l93w16x6tx879yrdfnulajns.png"/>
        </item>
    </channel>
</rss>
